{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imported\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import torch.nn as nn\n",
    "\n",
    "# file path\n",
    "file_path=\"E:\\\\AAA\\\\nlp\\\\AA_my_poem_generator\\\\songci\\\\data.json\"\n",
    "voc_path=\"E:\\\\AAA\\\\nlp\\\\AA_my_poem_generator\\\\voc\\\\\"\n",
    "model_path=\"E:\\\\AAA\\\\nlp\\\\AA_my_poem_generator\\\\checkpoints_songci\\\\sc\"\n",
    "\n",
    "#poem selecting\n",
    "min_len=10\n",
    "max_len=200\n",
    "\n",
    "\n",
    "# embedding setting\n",
    "word2id = {}  # 字典转换，汉字转化为相应的index\n",
    "id2word = {}  # index转换回汉字\n",
    "\n",
    "# training setting\n",
    "lr = 0.001\n",
    "epoch = 20  # 训练整套数据的次数\n",
    "embedding_dim = 128  # 词向量的维度\n",
    "hidden_dim = 256 # 隐层的维度\n",
    "batch_size = 128  # 批处理的量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(voc_path+\"word2id.json\") as f0:\n",
    "    word2id=json.load(f0)\n",
    "with open(voc_path+\"id2word.json\") as f1:\n",
    "    id2word=json.load(f1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'坼': 0, '卉': 1, '堵': 2, '尫': 3, '如': 4, 'ō': 5, '郡': 6, '匝': 7, '业': 8, '制': 9, '玲': 10, '厓': 11, '蓖': 12, '藿': 13, '砂': 14, '帘': 15, '旒': 16, '飓': 17, '玺': 18, '众': 19, '盈': 20, '钥': 21, '蛰': 22, '拐': 23, '枨': 24, '为': 25, '撒': 26, '鹊': 27, '鳞': 28, '男': 29, '垆': 30, '怪': 31, '溥': 32, '佗': 33, '叙': 34, '雁': 35, '荐': 36, '豺': 37, '独': 38, '沔': 39, '炮': 40, '彀': 41, '菸': 42, '清': 43, '俊': 44, '柴': 45, '奏': 46, '查': 47, '身': 48, '门': 49, '妫': 50, '围': 51, '仔': 52, '鼓': 53, '枳': 54, '１': 55, '翠': 56, '搂': 57, '美': 58, '菅': 59, '缤': 60, '坝': 61, '苟': 62, '阐': 63, '锝': 64, '灼': 65, '带': 66, '砻': 67, '箜': 68, '赴': 69, '推': 70, '倚': 71, '冶': 72, '伎': 73, '浅': 74, '台': 75, '窥': 76, '酌': 77, '毁': 78, '猫': 79, '缉': 80, '谷': 81, '莽': 82, '舍': 83, '裳': 84, '殆': 85, '怆': 86, '嫩': 87, '辁': 88, '凿': 89, '纭': 90, '竺': 91, '坟': 92, '潺': 93, '记': 94, '淑': 95, '挂': 96, '算': 97, '粤': 98, '蒙': 99, '鄱': 100, '让': 101, '啄': 102, '黟': 103, '闰': 104, '轻': 105, '媾': 106, '集': 107, '泾': 108, '蝤': 109, '蛜': 110, '腐': 111, '镝': 112, '籴': 113, '初': 114, '鹦': 115, '礴': 116, '网': 117, '打': 118, '胃': 119, '渡': 120, '滁': 121, '辆': 122, '利': 123, '柿': 124, '碇': 125, '掖': 126, '菌': 127, '鹗': 128, '树': 129, '璜': 130, '壑': 131, '史': 132, '缭': 133, '徂': 134, '荟': 135, '任': 136, '瘠': 137, '述': 138, '彰': 139, '挑': 140, '虺': 141, '琵': 142, '击': 143, '修': 144, '娟': 145, '汊': 146, '犊': 147, '京': 148, '骓': 149, '砖': 150, '宜': 151, '嵯': 152, '螗': 153, '昭': 154, '骞': 155, '溢': 156, '咏': 157, '潆': 158, '鸾': 159, '厢': 160, '赎': 161, '簌': 162, '订': 163, '贩': 164, '脸': 165, '蜉': 166, '綦': 167, '窠': 168, '辖': 169, '瘗': 170, '臆': 171, '覆': 172, '驿': 173, '诺': 174, '原': 175, '慢': 176, '快': 177, '眸': 178, '列': 179, '奚': 180, '窅': 181, '闳': 182, '岗': 183, '就': 184, '适': 185, '蜓': 186, '晕': 187, '隼': 188, '榔': 189, '耶': 190, '褊': 191, '华': 192, '蔌': 193, '嗳': 194, '馐': 195, '髀': 196, '凤': 197, '爨': 198, '舒': 199, '禹': 200, '池': 201, '怡': 202, '蒇': 203, '撷': 204, '荻': 205, '聪': 206, 'ン': 207, '鞿': 208, '珉': 209, '黉': 210, '轭': 211, '乎': 212, '俚': 213, '泳': 214, '尊': 215, '仍': 216, '黔': 217, '猴': 218, '谪': 219, '户': 220, '农': 221, '恢': 222, '馡': 223, '骝': 224, '醐': 225, '钞': 226, 'Α': 227, '镰': 228, '椰': 229, '咱': 230, '虎': 231, '檎': 232, '淙': 233, '镪': 234, '晗': 235, '沣': 236, '幂': 237, '蛾': 238, '恤': 239, '霾': 240, '恝': 241, '膻': 242, '钉': 243, '斑': 244, '羁': 245, '戮': 246, '颇': 247, '钧': 248, '汗': 249, '觑': 250, '菊': 251, '圻': 252, '递': 253, '睽': 254, '弃': 255, '堠': 256, '虬': 257, '苌': 258, '瑚': 259, '极': 260, '闪': 261, '腾': 262, '郁': 263, '缪': 264, '扳': 265, '目': 266, '璃': 267, '挚': 268, '荚': 269, '颐': 270, '缀': 271, '鞍': 272, '敖': 273, '谋': 274, '剩': 275, '阊': 276, '儿': 277, '店': 278, '骀': 279, '罡': 280, '勘': 281, '侔': 282, '愁': 283, '仕': 284, '伦': 285, '黯': 286, '牧': 287, '坪': 288, '跎': 289, '惬': 290, '狐': 291, '魄': 292, '澡': 293, '蜘': 294, '浯': 295, '缔': 296, '粮': 297, '句': 298, '瞥': 299, '栀': 300, '虚': 301, '噤': 302, '滞': 303, '拚': 304, '癯': 305, '魁': 306, '是': 307, '鲐': 308, '涕': 309, '胖': 310, '枪': 311, '铗': 312, '隈': 313, '官': 314, '渺': 315, '稷': 316, '沲': 317, '胯': 318, '谊': 319, '迎': 320, '人': 321, '琮': 322, '渌': 323, '祀': 324, '尽': 325, '抱': 326, '囊': 327, '甬': 328, '咭': 329, '缦': 330, '翳': 331, '榄': 332, '茄': 333, '铺': 334, '睢': 335, '暗': 336, '争': 337, '嗷': 338, '尧': 339, '泄': 340, '宸': 341, '储': 342, '敏': 343, '钓': 344, '锥': 345, '镟': 346, '辫': 347, '埃': 348, '垤': 349, '眺': 350, '歇': 351, '遂': 352, '捣': 353, '麒': 354, '彪': 355, '巳': 356, '孰': 357, '杨': 358, '誉': 359, '动': 360, '庠': 361, '孩': 362, '敢': 363, '牲': 364, '鏖': 365, '芳': 366, '综': 367, '殚': 368, '苔': 369, '菏': 370, '阗': 371, '祸': 372, '绉': 373, '戆': 374, '楮': 375, '杖': 376, '绨': 377, '授': 378, '晓': 379, '暮': 380, '屈': 381, '拓': 382, '哦': 383, '觐': 384, '兼': 385, '棒': 386, '懂': 387, '十': 388, '怀': 389, '茧': 390, '艮': 391, '镛': 392, '簿': 393, '毕': 394, '徽': 395, '湛': 396, '汩': 397, '涛': 398, '朽': 399, '衷': 400, '免': 401, '枸': 402, '幽': 403, '蒋': 404, '裨': 405, '抨': 406, '刃': 407, '辉': 408, '蒸': 409, '颤': 410, '量': 411, '吃': 412, '顷': 413, 'ㄓ': 414, '蘖': 415, '轨': 416, '攻': 417, '庚': 418, '墓': 419, '趄': 420, '容': 421, '其': 422, '匕': 423, '盲': 424, '赀': 425, '娈': 426, '灶': 427, '绔': 428, '麽': 429, '蚍': 430, '哲': 431, '窗': 432, '甥': 433, '庄': 434, '加': 435, '。': 436, '噬': 437, '嘹': 438, '沐': 439, '株': 440, '羽': 441, '霰': 442, '榘': 443, '樯': 444, '瞪': 445, '埠': 446, '唤': 447, '擤': 448, '解': 449, '颓': 450, '淹': 451, '俦': 452, '芟': 453, '<': 454, '萎': 455, '畔': 456, '瓶': 457, '乌': 458, '脏': 459, '孛': 460, '蓄': 461, '髓': 462, '罪': 463, '党': 464, '昆': 465, '夜': 466, '涴': 467, '笑': 468, '疴': 469, '咨': 470, '黜': 471, '濯': 472, '酾': 473, '皖': 474, '笋': 475, '臊': 476, '诬': 477, '肺': 478, '耸': 479, '仗': 480, '压': 481, '蠡': 482, '芡': 483, '旋': 484, '掾': 485, '诵': 486, '蓓': 487, '褶': 488, '溪': 489, '煊': 490, '孽': 491, '课': 492, '侈': 493, '构': 494, '虾': 495, '抽': 496, '必': 497, '磷': 498, '帜': 499, '箪': 500, '罂': 501, '塾': 502, '辇': 503, '摇': 504, '涧': 505, '承': 506, '襞': 507, '欠': 508, '圆': 509, '敝': 510, '靖': 511, '污': 512, '湖': 513, '舡': 514, '楣': 515, '蝉': 516, '穹': 517, '菔': 518, '醍': 519, '煮': 520, '黎': 521, '追': 522, '藩': 523, '墀': 524, '蘅': 525, '穷': 526, '强': 527, '的': 528, '绰': 529, '涓': 530, '叶': 531, '饥': 532, '汴': 533, '媂': 534, '监': 535, '莸': 536, '埙': 537, '潸': 538, '桑': 539, '纽': 540, '觌': 541, '噎': 542, '绒': 543, '艨': 544, '梯': 545, '舫': 546, '闸': 547, '悦': 548, '块': 549, '剧': 550, '咳': 551, '炫': 552, '赠': 553, '虢': 554, '净': 555, '绾': 556, '钌': 557, '仲': 558, '绷': 559, '口': 560, '潦': 561, '小': 562, '青': 563, '散': 564, '拄': 565, '窝': 566, '螺': 567, '获': 568, '蓼': 569, '窨': 570, '逑': 571, '迟': 572, '媪': 573, '眉': 574, '颍': 575, '遐': 576, '倮': 577, '怃': 578, '斡': 579, '湍': 580, '峥': 581, '笄': 582, '忝': 583, '笃': 584, '樱': 585, '匀': 586, '侄': 587, '帛': 588, '彦': 589, '饿': 590, '八': 591, '嘶': 592, '成': 593, '入': 594, '遗': 595, '蚊': 596, '碱': 597, '即': 598, '括': 599, '谶': 600, '醑': 601, '济': 602, '溺': 603, '竿': 604, '科': 605, '遭': 606, '希': 607, '觅': 608, '套': 609, '颧': 610, '狙': 611, '诅': 612, '迭': 613, '臻': 614, '骋': 615, '享': 616, '掷': 617, '镇': 618, '赤': 619, '後': 620, '壳': 621, '才': 622, '旰': 623, '覃': 624, '藏': 625, '癸': 626, '郫': 627, '绂': 628, '莅': 629, '蜩': 630, '胧': 631, '每': 632, '撤': 633, '筌': 634, '缰': 635, '础': 636, '姆': 637, 'ぢ': 638, '西': 639, '睦': 640, '儡': 641, '巍': 642, '登': 643, '浪': 644, '渊': 645, '糯': 646, '踮': 647, '俘': 648, '著': 649, '隧': 650, '委': 651, '币': 652, '闯': 653, '蜡': 654, '铩': 655, '龊': 656, '昨': 657, '硎': 658, '绸': 659, '赝': 660, '峻': 661, '绁': 662, '凸': 663, 'и': 664, '扇': 665, '祥': 666, '颢': 667, '帮': 668, '隅': 669, '努': 670, '曙': 671, '都': 672, '蔫': 673, '凫': 674, '豳': 675, '栉': 676, '碗': 677, '氵': 678, '叛': 679, '哙': 680, '絮': 681, '禽': 682, '屋': 683, '揠': 684, '缗': 685, '坯': 686, '女': 687, '膺': 688, '雄': 689, '辣': 690, '崧': 691, '幕': 692, '舔': 693, '恓': 694, '惨': 695, '谤': 696, '叮': 697, '薛': 698, '纂': 699, '稠': 700, '椟': 701, '笞': 702, '筑': 703, '绘': 704, '阵': 705, '鹜': 706, '服': 707, '訇': 708, '回': 709, '姗': 710, '蛹': 711, '金': 712, '茫': 713, '姚': 714, '敷': 715, '斫': 716, '忠': 717, '宗': 718, '瞑': 719, '恺': 720, '悴': 721, '褓': 722, '郇': 723, '媲': 724, '释': 725, '兢': 726, '翰': 727, '洼': 728, '鄣': 729, '曛': 730, '骼': 731, '迷': 732, '淋': 733, '呼': 734, '枰': 735, '淀': 736, '滨': 737, '封': 738, '嶂': 739, '水': 740, '匏': 741, '屣': 742, '喘': 743, '慷': 744, '流': 745, '璁': 746, '轺': 747, '鲒': 748, '磐': 749, '笺': 750, '骥': 751, '引': 752, '溟': 753, '光': 754, '芯': 755, '哨': 756, '耜': 757, '帱': 758, '夙': 759, '融': 760, '曝': 761, '诲': 762, '葺': 763, '奈': 764, '挫': 765, '摸': 766, '枻': 767, '桥': 768, '畅': 769, '娣': 770, '沟': 771, '鹘': 772, '餐': 773, '鳜': 774, '衽': 775, '恐': 776, '诞': 777, '摩': 778, '缱': 779, '邸': 780, '卧': 781, '悃': 782, '识': 783, '攸': 784, '欢': 785, '淘': 786, '僵': 787, '颖': 788, '烨': 789, '便': 790, '供': 791, '横': 792, '脐': 793, '吠': 794, '妲': 795, '牙': 796, '愠': 797, '邪': 798, '躔': 799, '栏': 800, '柑': 801, '粕': 802, '排': 803, '啮': 804, '畿': 805, '期': 806, '窟': 807, '怼': 808, '酡': 809, '舴': 810, '烂': 811, '谬': 812, '挺': 813, '跋': 814, '觋': 815, '盏': 816, '宽': 817, '褪': 818, '煤': 819, '阼': 820, '揭': 821, '钩': 822, '扶': 823, '祯': 824, '枝': 825, '央': 826, '笥': 827, '刺': 828, '垒': 829, 'Н': 830, '梅': 831, '多': 832, '墨': 833, '嫌': 834, '楚': 835, '准': 836, '呷': 837, '晦': 838, '笕': 839, '歙': 840, '绩': 841, '仓': 842, '游': 843, '糖': 844, '呀': 845, '藁': 846, '菡': 847, '跄': 848, '维': 849, '狻': 850, '头': 851, '燕': 852, '谗': 853, '怵': 854, '閟': 855, '隽': 856, '祈': 857, '援': 858, '文': 859, '逗': 860, '寒': 861, '芸': 862, '淆': 863, '盼': 864, '赉': 865, '堰': 866, '’': 867, '缈': 868, '贶': 869, '蚋': 870, '骷': 871, '啸': 872, '祟': 873, '罗': 874, '瓦': 875, '敬': 876, '籁': 877, '面': 878, '剖': 879, '峋': 880, '翦': 881, '刊': 882, '鹆': 883, '混': 884, '鞑': 885, '矗': 886, '董': 887, '玑': 888, '诸': 889, '丹': 890, '钟': 891, '刻': 892, '则': 893, '幻': 894, '闼': 895, '毋': 896, '摆': 897, '救': 898, '圭': 899, '囷': 900, '瞩': 901, '霉': 902, '曰': 903, '炎': 904, '纩': 905, '艹': 906, '瓞': 907, '捍': 908, '寮': 909, '涪': 910, '哳': 911, '改': 912, '浊': 913, '柰': 914, '跫': 915, '肤': 916, '缢': 917, '纤': 918, '睚': 919, '_': 920, '衙': 921, '至': 922, '躇': 923, '酴': 924, '殉': 925, '嫣': 926, '觖': 927, '琨': 928, '滟': 929, '瘳': 930, '岂': 931, '泗': 932, '觥': 933, '败': 934, '孝': 935, '豕': 936, '捱': 937, '韦': 938, '犍': 939, '河': 940, '突': 941, '豆': 942, '绫': 943, '秘': 944, '旷': 945, '⒛': 946, '喏': 947, '寿': 948, '训': 949, '珥': 950, '膳': 951, '滴': 952, '魍': 953, '猱': 954, '猜': 955, '睐': 956, 'б': 957, '璞': 958, '绞': 959, '汐': 960, '问': 961, '醮': 962, '乳': 963, '柳': 964, '时': 965, '隘': 966, '霅': 967, '卓': 968, '更': 969, '洗': 970, '丫': 971, '甜': 972, '操': 973, '发': 974, '协': 975, '丁': 976, '私': 977, '易': 978, '袁': 979, '攘': 980, '檄': 981, '国': 982, '愕': 983, '凡': 984, '螭': 985, '殇': 986, '法': 987, '迢': 988, '宇': 989, '桨': 990, '亵': 991, '赂': 992, '柱': 993, '陋': 994, '巷': 995, '自': 996, '毯': 997, 'ｓ': 998, '抒': 999, '礼': 1000, '娥': 1001, '岐': 1002, '鹕': 1003, '案': 1004, '祚': 1005, '菩': 1006, '丽': 1007, '邦': 1008, '拢': 1009, '同': 1010, '谥': 1011, '榭': 1012, '畲': 1013, '臂': 1014, '纾': 1015, '兵': 1016, '转': 1017, '鹏': 1018, '腌': 1019, '鸯': 1020, '秕': 1021, '圯': 1022, '痼': 1023, '俨': 1024, '鲸': 1025, '绚': 1026, '产': 1027, '什': 1028, '杪': 1029, '指': 1030, '珀': 1031, '撰': 1032, '零': 1033, '悬': 1034, '卣': 1035, '蕙': 1036, '滇': 1037, '盖': 1038, '考': 1039, '尻': 1040, '锤': 1041, '床': 1042, '盐': 1043, '髯': 1044, '却': 1045, '宛': 1046, '攒': 1047, '凑': 1048, '橼': 1049, '贺': 1050, '愉': 1051, '税': 1052, '寸': 1053, '重': 1054, '梁': 1055, '蛩': 1056, '霆': 1057, '材': 1058, '责': 1059, '梳': 1060, '莆': 1061, '坠': 1062, '妓': 1063, '阅': 1064, '运': 1065, '港': 1066, '壬': 1067, '软': 1068, '逍': 1069, '軿': 1070, '绵': 1071, '磕': 1072, '饼': 1073, '郧': 1074, '杭': 1075, '撩': 1076, '茗': 1077, '嵇': 1078, '仃': 1079, '麹': 1080, '生': 1081, '劳': 1082, '筲': 1083, '榼': 1084, '樟': 1085, '又': 1086, '溯': 1087, '肌': 1088, '阜': 1089, '谭': 1090, '棹': 1091, '逝': 1092, '辔': 1093, '隔': 1094, '恂': 1095, '皱': 1096, '罾': 1097, '榷': 1098, '挨': 1099, '疑': 1100, '灭': 1101, '着': 1102, '狮': 1103, '秫': 1104, '夹': 1105, '迸': 1106, '赆': 1107, '定': 1108, '獭': 1109, '拉': 1110, '张': 1111, '冱': 1112, '纸': 1113, '忘': 1114, '会': 1115, '芜': 1116, '忡': 1117, '赊': 1118, '甍': 1119, '照': 1120, '窭': 1121, '晃': 1122, '垅': 1123, '侬': 1124, '苒': 1125, '第': 1126, '莪': 1127, '贳': 1128, '拆': 1129, '魔': 1130, '高': 1131, '阔': 1132, '稍': 1133, '麟': 1134, '谄': 1135, '捧': 1136, '选': 1137, '膜': 1138, '演': 1139, '艾': 1140, '冼': 1141, '柞': 1142, '踬': 1143, '君': 1144, '预': 1145, '辜': 1146, '琤': 1147, '簖': 1148, '唆': 1149, '娱': 1150, '劾': 1151, '劈': 1152, '鬲': 1153, '燧': 1154, '界': 1155, '烧': 1156, '曼': 1157, '红': 1158, 'は': 1159, 'づ': 1160, '饷': 1161, '冗': 1162, '绊': 1163, '速': 1164, '蟀': 1165, '草': 1166, '沪': 1167, '尺': 1168, '嫔': 1169, '【': 1170, '谆': 1171, '鳖': 1172, '茵': 1173, '咎': 1174, '札': 1175, '黛': 1176, '哭': 1177, '吕': 1178, '萏': 1179, '坐': 1180, '匈': 1181, '饶': 1182, '甄': 1183, '屑': 1184, '塞': 1185, '簸': 1186, '蕃': 1187, '睾': 1188, '哇': 1189, '冢': 1190, '谨': 1191, '山': 1192, '兆': 1193, '分': 1194, '奖': 1195, 'ㄇ': 1196, '说': 1197, '遄': 1198, '鹩': 1199, '罅': 1200, '逊': 1201, '呢': 1202, '汲': 1203, '蜻': 1204, '讨': 1205, '妤': 1206, '纯': 1207, '食': 1208, '扃': 1209, '绝': 1210, '具': 1211, '非': 1212, '斧': 1213, '毅': 1214, '豚': 1215, '恨': 1216, '钤': 1217, '螓': 1218, '觜': 1219, '移': 1220, '驻': 1221, '练': 1222, '粥': 1223, '耄': 1224, '吝': 1225, '奸': 1226, '遛': 1227, '廛': 1228, '鍧': 1229, '遇': 1230, '仪': 1231, '垂': 1232, '旱': 1233, '爽': 1234, '稼': 1235, '佛': 1236, '萦': 1237, '槔': 1238, '证': 1239, '行': 1240, '契': 1241, '袭': 1242, '婺': 1243, '蜊': 1244, '鸦': 1245, '之': 1246, '沥': 1247, '辘': 1248, '烬': 1249, '庑': 1250, '倒': 1251, '罕': 1252, '放': 1253, '区': 1254, '暾': 1255, '摺': 1256, '眨': 1257, '枕': 1258, '植': 1259, '苞': 1260, '镖': 1261, '世': 1262, '望': 1263, '窖': 1264, '逼': 1265, '弦': 1266, '堑': 1267, '赡': 1268, '哑': 1269, '侪': 1270, '还': 1271, '频': 1272, '销': 1273, '粜': 1274, '蔼': 1275, '撑': 1276, '蠢': 1277, '赵': 1278, '骈': 1279, '炽': 1280, '物': 1281, '落': 1282, '签': 1283, '郗': 1284, '忪': 1285, '唳': 1286, '吻': 1287, '廉': 1288, '猥': 1289, '脑': 1290, '活': 1291, '麴': 1292, '影': 1293, '蟆': 1294, '梗': 1295, '舻': 1296, '寥': 1297, '忙': 1298, '鍪': 1299, '娼': 1300, '梢': 1301, '珮': 1302, '抡': 1303, '荦': 1304, '搬': 1305, '箫': 1306, '姐': 1307, '湘': 1308, '新': 1309, '拿': 1310, '僻': 1311, '圉': 1312, '孟': 1313, '嵬': 1314, '驾': 1315, '拊': 1316, '采': 1317, '藕': 1318, '恳': 1319, '气': 1320, '晁': 1321, '槟': 1322, '熟': 1323, '逆': 1324, '矢': 1325, '嗟': 1326, '驱': 1327, '跷': 1328, '翥': 1329, '帚': 1330, '肯': 1331, '牍': 1332, '属': 1333, '昙': 1334, '黑': 1335, '蜣': 1336, '枇': 1337, '焕': 1338, '翻': 1339, '龙': 1340, '纷': 1341, '浼': 1342, '峡': 1343, '偬': 1344, '嘘': 1345, '坎': 1346, '娓': 1347, '颦': 1348, '杂': 1349, '枣': 1350, '飒': 1351, '楸': 1352, '按': 1353, '揣': 1354, '拥': 1355, '缑': 1356, '醿': 1357, '许': 1358, '瓢': 1359, '！': 1360, '啤': 1361, '漂': 1362, '荫': 1363, '矜': 1364, '窦': 1365, '映': 1366, '怏': 1367, '缶': 1368, '铿': 1369, '樾': 1370, '拶': 1371, '将': 1372, '禾': 1373, '颔': 1374, '挛': 1375, '邈': 1376, '峒': 1377, '崛': 1378, '那': 1379, '髭': 1380, '蒺': 1381, '郎': 1382, '祉': 1383, '怨': 1384, '莎': 1385, '蓠': 1386, '砑': 1387, '忏': 1388, '翊': 1389, '雾': 1390, '汝': 1391, '填': 1392, '焰': 1393, '冥': 1394, '蒂': 1395, '棚': 1396, '涅': 1397, '名': 1398, '催': 1399, '逅': 1400, '意': 1401, '宓': 1402, '件': 1403, '司': 1404, '腰': 1405, '襦': 1406, '彭': 1407, '惧': 1408, '悰': 1409, '珈': 1410, '实': 1411, '玳': 1412, '滑': 1413, '嘱': 1414, '射': 1415, '杏': 1416, '菘': 1417, '谀': 1418, '廓': 1419, '粟': 1420, '瑟': 1421, '警': 1422, '扫': 1423, '鹳': 1424, '揆': 1425, '岷': 1426, '得': 1427, '栾': 1428, '缯': 1429, '曲': 1430, '办': 1431, '韫': 1432, '秧': 1433, '配': 1434, '透': 1435, '吭': 1436, '妙': 1437, '蓂': 1438, '颅': 1439, '苕': 1440, '奄': 1441, '拍': 1442, '悒': 1443, '崆': 1444, '塘': 1445, '泖': 1446, '锺': 1447, '颊': 1448, '欸': 1449, '彻': 1450, '咄': 1451, '风': 1452, '宙': 1453, '闒': 1454, '整': 1455, '抗': 1456, '他': 1457, '券': 1458, '贽': 1459, '诰': 1460, '玩': 1461, '哀': 1462, '富': 1463, '愆': 1464, '罘': 1465, '涨': 1466, '沼': 1467, '猪': 1468, '珩': 1469, '暴': 1470, '瞰': 1471, '德': 1472, '蹄': 1473, '墙': 1474, '颗': 1475, '嵌': 1476, '淤': 1477, '耀': 1478, '矩': 1479, '猿': 1480, '哝': 1481, '闺': 1482, '璈': 1483, '值': 1484, '大': 1485, '燥': 1486, '扰': 1487, '虱': 1488, '蚌': 1489, '恁': 1490, '芗': 1491, '酬': 1492, '激': 1493, '玷': 1494, '押': 1495, '琊': 1496, '圜': 1497, '铜': 1498, '翮': 1499, '沅': 1500, '碟': 1501, '岁': 1502, '鸠': 1503, '肝': 1504, '浆': 1505, '巡': 1506, '蔽': 1507, '荏': 1508, '逾': 1509, '驹': 1510, '贫': 1511, '嵩': 1512, '斐': 1513, '鸡': 1514, '荒': 1515, '昔': 1516, '萌': 1517, '筇': 1518, '鹞': 1519, '卺': 1520, '际': 1521, '机': 1522, '戎': 1523, '亩': 1524, '翘': 1525, '它': 1526, '罔': 1527, '泱': 1528, '陷': 1529, '蛑': 1530, '蟪': 1531, '腻': 1532, '袷': 1533, '锁': 1534, '咽': 1535, '儒': 1536, '芦': 1537, '钵': 1538, '音': 1539, '瘦': 1540, '灵': 1541, '殷': 1542, '幔': 1543, '滔': 1544, '爰': 1545, '守': 1546, '祓': 1547, '樻': 1548, '柚': 1549, '杜': 1550, '单': 1551, '碛': 1552, '巩': 1553, '芬': 1554, '俜': 1555, '鬖': 1556, '忻': 1557, '肉': 1558, '减': 1559, '柝': 1560, '喋': 1561, '蔺': 1562, '喻': 1563, '学': 1564, '裘': 1565, '靳': 1566, '衿': 1567, 'ぇ': 1568, '假': 1569, '沙': 1570, '炉': 1571, '娄': 1572, '隰': 1573, '皆': 1574, '祆': 1575, '糈': 1576, '蚕': 1577, '谳': 1578, '何': 1579, '瓣': 1580, '觇': 1581, '骨': 1582, '栅': 1583, '织': 1584, '栋': 1585, '肴': 1586, '槽': 1587, '挤': 1588, '诧': 1589, '钜': 1590, '掺': 1591, '埏': 1592, '挝': 1593, '衡': 1594, '髫': 1595, '膈': 1596, '薇': 1597, '跖': 1598, '牡': 1599, '婷': 1600, '馆': 1601, '淼': 1602, '僽': 1603, '桡': 1604, '街': 1605, '拦': 1606, '奁': 1607, '坊': 1608, '项': 1609, '谡': 1610, '抄': 1611, '芎': 1612, '队': 1613, '凭': 1614, '继': 1615, '甚': 1616, '袈': 1617, '留': 1618, '掉': 1619, '唼': 1620, '鸪': 1621, '绋': 1622, '战': 1623, '庙': 1624, '滤': 1625, '臭': 1626, '匙': 1627, '辨': 1628, '戡': 1629, '桄': 1630, '锼': 1631, '掐': 1632, '驴': 1633, '篘': 1634, '嘉': 1635, '冬': 1636, '佑': 1637, '观': 1638, '昼': 1639, '聆': 1640, '蛟': 1641, '倦': 1642, '虻': 1643, '疲': 1644, '煅': 1645, '籍': 1646, 'め': 1647, '绕': 1648, '涯': 1649, '崃': 1650, '脱': 1651, '鳏': 1652, '窃': 1653, '觞': 1654, '洄': 1655, '洒': 1656, '悫': 1657, '琐': 1658, '啜': 1659, '懦': 1660, '江': 1661, '姨': 1662, '薮': 1663, '脓': 1664, '布': 1665, '爇': 1666, '斯': 1667, '儋': 1668, '荥': 1669, '席': 1670, '凶': 1671, '择': 1672, '堤': 1673, '屠': 1674, '抢': 1675, '凋': 1676, '帕': 1677, '颟': 1678, '婿': 1679, '步': 1680, '俭': 1681, '厄': 1682, '蓟': 1683, '例': 1684, '魑': 1685, '晖': 1686, '丙': 1687, '靡': 1688, '命': 1689, '衍': 1690, '虿': 1691, '傅': 1692, '远': 1693, '庭': 1694, '颃': 1695, '财': 1696, '琅': 1697, '尝': 1698, '广': 1699, '佣': 1700, '冲': 1701, '醭': 1702, 'ㄛ': 1703, '撕': 1704, '事': 1705, '襄': 1706, '垄': 1707, '瞌': 1708, '踵': 1709, '澈': 1710, '翼': 1711, '辎': 1712, '增': 1713, '径': 1714, '裁': 1715, '烁': 1716, '叱': 1717, '帖': 1718, '螟': 1719, '奢': 1720, '笏': 1721, '橐': 1722, '靠': 1723, '徊': 1724, '畹': 1725, '╆': 1726, '憧': 1727, '亲': 1728, '穴': 1729, '耘': 1730, '偕': 1731, '囝': 1732, '讳': 1733, '沉': 1734, '镐': 1735, '本': 1736, '肄': 1737, '搓': 1738, '充': 1739, '苴': 1740, '瞳': 1741, '额': 1742, '沾': 1743, '肪': 1744, '蓍': 1745, '葬': 1746, '汉': 1747, '盟': 1748, '赍': 1749, '茂': 1750, '刀': 1751, '勾': 1752, '逃': 1753, '反': 1754, '熏': 1755, '趱': 1756, '蒯': 1757, '茸': 1758, '惮': 1759, '驮': 1760, '钺': 1761, '忌': 1762, '澳': 1763, '竦': 1764, '囚': 1765, '伞': 1766, '几': 1767, '淅': 1768, '皓': 1769, '七': 1770, '屏': 1771, '牢': 1772, '觫': 1773, '噪': 1774, '侑': 1775, '赘': 1776, '智': 1777, '飨': 1778, '露': 1779, 'β': 1780, '术': 1781, '豁': 1782, '岭': 1783, '靴': 1784, '佥': 1785, '蛉': 1786, '斟': 1787, '憩': 1788, '符': 1789, '洎': 1790, '麓': 1791, '砚': 1792, '嗣': 1793, '崔': 1794, '捉': 1795, '栊': 1796, '蹁': 1797, '粘': 1798, '瞬': 1799, '腑': 1800, '感': 1801, '逡': 1802, '菜': 1803, '屯': 1804, '唯': 1805, '嵘': 1806, '舁': 1807, '羞': 1808, '乙': 1809, '昱': 1810, '斝': 1811, '驼': 1812, '拒': 1813, '祛': 1814, '沸': 1815, '篁': 1816, '皴': 1817, '涔': 1818, '皂': 1819, '袍': 1820, '淖': 1821, '补': 1822, '尸': 1823, '嗓': 1824, '鸷': 1825, '索': 1826, '拱': 1827, '涡': 1828, '幺': 1829, '殢': 1830, '色': 1831, '玻': 1832, '碾': 1833, '饮': 1834, '鳅': 1835, '迪': 1836, '惑': 1837, '毖': 1838, '蕞': 1839, '莹': 1840, '刚': 1841, '涿': 1842, '收': 1843, '匆': 1844, '炝': 1845, '节': 1846, '於': 1847, '赭': 1848, '乾': 1849, '锋': 1850, '睿': 1851, '讽': 1852, '汤': 1853, '们': 1854, '慊': 1855, '粳': 1856, '投': 1857, '硕': 1858, '陬': 1859, '{': 1860, '缟': 1861, '亿': 1862, '绢': 1863, '缇': 1864, '蝛': 1865, '劫': 1866, '杼': 1867, '泛': 1868, '庾': 1869, '玎': 1870, '叉': 1871, '确': 1872, '旺': 1873, '鲠': 1874, '磁': 1875, '阒': 1876, '程': 1877, '冠': 1878, '邕': 1879, '鵊': 1880, '吊': 1881, '脊': 1882, '嗾': 1883, '烛': 1884, '式': 1885, '版': 1886, '慵': 1887, '千': 1888, '婴': 1889, '予': 1890, '龌': 1891, '驭': 1892, '电': 1893, '冻': 1894, '龟': 1895, '艺': 1896, '搦': 1897, '淳': 1898, '暖': 1899, '玖': 1900, '舄': 1901, '锚': 1902, '吒': 1903, '铃': 1904, '薜': 1905, '仰': 1906, '嚼': 1907, '血': 1908, '圮': 1909, '线': 1910, '角': 1911, '粉': 1912, '斜': 1913, '举': 1914, '峤': 1915, '素': 1916, '读': 1917, '皋': 1918, '戢': 1919, '滹': 1920, '熄': 1921, '有': 1922, '北': 1923, '陂': 1924, '田': 1925, '笳': 1926, '沫': 1927, '绻': 1928, '趁': 1929, '苜': 1930, '浴': 1931, '圈': 1932, '堕': 1933, '啻': 1934, '妩': 1935, '曹': 1936, '力': 1937, '擞': 1938, '现': 1939, '味': 1940, '割': 1941, '虔': 1942, '想': 1943, '狸': 1944, '酸': 1945, '徙': 1946, '随': 1947, '纫': 1948, '诛': 1949, '昴': 1950, '欹': 1951, '培': 1952, '牌': 1953, '芄': 1954, '檬': 1955, '叵': 1956, '纶': 1957, '卵': 1958, '乱': 1959, '刍': 1960, '狡': 1961, '渝': 1962, '逸': 1963, '糕': 1964, '峙': 1965, '型': 1966, '汞': 1967, '传': 1968, '保': 1969, '芾': 1970, '淡': 1971, '踟': 1972, '纬': 1973, '疟': 1974, '鳝': 1975, '般': 1976, '宅': 1977, '敦': 1978, '胆': 1979, '眼': 1980, '亨': 1981, '殖': 1982, '宿': 1983, '耨': 1984, '杞': 1985, '镬': 1986, '束': 1987, '飘': 1988, '秋': 1989, '雕': 1990, '摊': 1991, '鲭': 1992, '贾': 1993, '谯': 1994, '励': 1995, '鲛': 1996, '窈': 1997, '阖': 1998, '姿': 1999, '罢': 2000, '亡': 2001, '据': 2002, '砢': 2003, '戍': 2004, '扈': 2005, '愍': 2006, '叩': 2007, '谅': 2008, '肇': 2009, '漾': 2010, '壹': 2011, '脍': 2012, '较': 2013, '遵': 2014, '慑': 2015, '坻': 2016, '阑': 2017, '喁': 2018, '荼': 2019, '途': 2020, '弓': 2021, '州': 2022, '匠': 2023, '呻': 2024, '韭': 2025, '堞': 2026, '仿': 2027, '贝': 2028, '喂': 2029, '妪': 2030, '诘': 2031, '渠': 2032, '图': 2033, '晔': 2034, '崭': 2035, '育': 2036, '濑': 2037, '嘲': 2038, '请': 2039, '娲': 2040, '牺': 2041, '雷': 2042, '瓷': 2043, '贱': 2044, '帐': 2045, '潼': 2046, '眠': 2047, '荣': 2048, '榛': 2049, '盾': 2050, 'ホ': 2051, '走': 2052, '尔': 2053, '穗': 2054, '酿': 2055, '麋': 2056, '堪': 2057, '处': 2058, '息': 2059, '显': 2060, '荇': 2061, '涉': 2062, '蜇': 2063, '琼': 2064, '慕': 2065, '蕲': 2066, '洋': 2067, '鄙': 2068, '蔗': 2069, '：': 2070, '刈': 2071, '嚲': 2072, '粗': 2073, '鼾': 2074, '嚣': 2075, '桂': 2076, '嵫': 2077, '躅': 2078, '冕': 2079, '诉': 2080, '衲': 2081, '珠': 2082, '笼': 2083, '…': 2084, '赏': 2085, '晌': 2086, '梭': 2087, '捏': 2088, '方': 2089, '泵': 2090, '你': 2091, '砍': 2092, '吟': 2093, '泷': 2094, '虑': 2095, '惘': 2096, '仑': 2097, '藤': 2098, '锯': 2099, '律': 2100, '赫': 2101, '租': 2102, '鸱': 2103, '类': 2104, '濂': 2105, '泼': 2106, '蝙': 2107, '谏': 2108, '迈': 2109, '婢': 2110, '伴': 2111, '器': 2112, '职': 2113, '眦': 2114, '娉': 2115, '俾': 2116, '防': 2117, '嫫': 2118, '盘': 2119, '廿': 2120, '酩': 2121, '伊': 2122, 'ㄏ': 2123, '雳': 2124, '溘': 2125, '役': 2126, '谱': 2127, '椽': 2128, '讶': 2129, '申': 2130, '苗': 2131, '瑙': 2132, '征': 2133, '亸': 2134, '妻': 2135, '妒': 2136, '寨': 2137, '赦': 2138, '隐': 2139, '楞': 2140, '再': 2141, '潢': 2142, '势': 2143, '珊': 2144, '弥': 2145, '塑': 2146, '潘': 2147, '迨': 2148, '攫': 2149, '咚': 2150, '裂': 2151, '些': 2152, '姻': 2153, '妾': 2154, '描': 2155, '枫': 2156, '蓉': 2157, '缩': 2158, '一': 2159, '形': 2160, '手': 2161, '砺': 2162, '蚓': 2163, '诗': 2164, '呶': 2165, '林': 2166, '欲': 2167, '鬟': 2168, '沮': 2169, '阍': 2170, '榕': 2171, '暌': 2172, '耔': 2173, '巑': 2174, '铤': 2175, '陇': 2176, '贬': 2177, '副': 2178, '研': 2179, '溉': 2180, '云': 2181, '苓': 2182, '蒜': 2183, '逶': 2184, '缆': 2185, '暂': 2186, '轼': 2187, '提': 2188, '垣': 2189, '彝': 2190, '挟': 2191, '派': 2192, '骚': 2193, '鬣': 2194, '篇': 2195, '舅': 2196, '栽': 2197, '甘': 2198, '獗': 2199, '洪': 2200, '价': 2201, '斓': 2202, '猷': 2203, '窕': 2204, '甲': 2205, '浇': 2206, '该': 2207, '磋': 2208, '孚': 2209, '悲': 2210, '槲': 2211, '桐': 2212, '使': 2213, '蔻': 2214, '茎': 2215, '夔': 2216, '鹧': 2217, '亢': 2218, '吹': 2219, '穆': 2220, '瑞': 2221, '橱': 2222, '犀': 2223, '岑': 2224, '蝗': 2225, '纛': 2226, '娇': 2227, '葆': 2228, '缵': 2229, '雒': 2230, '庖': 2231, '执': 2232, '舶': 2233, '院': 2234, '绐': 2235, '浙': 2236, '宝': 2237, '欧': 2238, '剜': 2239, '且': 2240, '雏': 2241, '共': 2242, '拟': 2243, '真': 2244, '窍': 2245, '姑': 2246, '良': 2247, '蒿': 2248, '祷': 2249, '病': 2250, '痎': 2251, '缝': 2252, '螂': 2253, '熨': 2254, '鲫': 2255, '兰': 2256, '检': 2257, '判': 2258, '县': 2259, '孳': 2260, '腔': 2261, '岚': 2262, '煜': 2263, '悟': 2264, '弘': 2265, '棉': 2266, '瞒': 2267, '剿': 2268, '琪': 2269, '撸': 2270, '袢': 2271, '棘': 2272, '晴': 2273, '胭': 2274, '滕': 2275, '８': 2276, '楷': 2277, '糜': 2278, '嫡': 2279, '兖': 2280, '徭': 2281, '锉': 2282, '另': 2283, '荡': 2284, '霪': 2285, '羿': 2286, '络': 2287, '湄': 2288, '伧': 2289, '泽': 2290, '轰': 2291, '愚': 2292, '禳': 2293, '邓': 2294, '浒': 2295, '罩': 2296, '蒌': 2297, '涂': 2298, '孪': 2299, '褰': 2300, '逐': 2301, '贡': 2302, '掘': 2303, '媛': 2304, '羸': 2305, '寞': 2306, '骑': 2307, '薰': 2308, '能': 2309, '燠': 2310, '霖': 2311, '湓': 2312, '疏': 2313, '泻': 2314, '焚': 2315, '避': 2316, '厨': 2317, '筮': 2318, '旌': 2319, '袖': 2320, '爝': 2321, '背': 2322, '措': 2323, '壁': 2324, '髡': 2325, '轴': 2326, '坦': 2327, '螳': 2328, '丸': 2329, '蹋': 2330, '狼': 2331, '侥': 2332, '哗': 2333, '揩': 2334, '佯': 2335, '曩': 2336, '旭': 2337, '鼐': 2338, '藻': 2339, '室': 2340, '帏': 2341, '悉': 2342, '班': 2343, '颛': 2344, '烙': 2345, '葑': 2346, '莱': 2347, '因': 2348, '消': 2349, '彗': 2350, '祢': 2351, '匪': 2352, '锵': 2353, '各': 2354, '庶': 2355, '哂': 2356, '槛': 2357, '袋': 2358, '缲': 2359, '闩': 2360, '揾': 2361, '铢': 2362, '裔': 2363, '剑': 2364, '裹': 2365, '旗': 2366, '巽': 2367, '揉': 2368, '仙': 2369, '鳃': 2370, '陵': 2371, '叨': 2372, '求': 2373, '辱': 2374, '栳': 2375, '辏': 2376, '蝴': 2377, '无': 2378, '跻': 2379, '濛': 2380, '奎': 2381, '焦': 2382, '招': 2383, '孕': 2384, '瀣': 2385, '谰': 2386, '晞': 2387, '颂': 2388, '否': 2389, '赖': 2390, '谇': 2391, '厚': 2392, '轩': 2393, '退': 2394, '肋': 2395, '近': 2396, '携': 2397, '闾': 2398, '买': 2399, '完': 2400, '昌': 2401, '对': 2402, '嘻': 2403, '芥': 2404, '松': 2405, 'そ': 2406, '挲': 2407, '妄': 2408, '二': 2409, '捞': 2410, '笾': 2411, '主': 2412, '彷': 2413, '歌': 2414, '黠': 2415, '枞': 2416, '由': 2417, '/': 2418, '窄': 2419, '祭': 2420, '伥': 2421, '裛': 2422, '壮': 2423, '犁': 2424, '侯': 2425, '搐': 2426, '荤': 2427, '溃': 2428, '很': 2429, '嫠': 2430, '堆': 2431, '悭': 2432, '鹤': 2433, '骰': 2434, '狱': 2435, '嚏': 2436, '淦': 2437, '慨': 2438, '妇': 2439, '惭': 2440, '枭': 2441, '狗': 2442, '葳': 2443, '荔': 2444, '幼': 2445, '纠': 2446, '鹰': 2447, '骘': 2448, '临': 2449, '府': 2450, '蝣': 2451, '总': 2452, '碎': 2453, '裴': 2454, '弛': 2455, '泯': 2456, '捕': 2457, '煞': 2458, '茯': 2459, '三': 2460, '崑': 2461, '薤': 2462, '烈': 2463, '尉': 2464, '稔': 2465, '姮': 2466, '娶': 2467, '讫': 2468, '刷': 2469, '颁': 2470, '晤': 2471, '接': 2472, '偈': 2473, '轵': 2474, '愿': 2475, '侦': 2476, '曷': 2477, '蛴': 2478, '§': 2479, '爬': 2480, '疚': 2481, '祖': 2482, '芒': 2483, '檐': 2484, '毂': 2485, '切': 2486, '谌': 2487, '烹': 2488, '挽': 2489, '瓮': 2490, '茇': 2491, '款': 2492, '虏': 2493, '椠': 2494, '志': 2495, '坷': 2496, '罴': 2497, '０': 2498, '搭': 2499, '廪': 2500, '塍': 2501, '赓': 2502, '蟠': 2503, '炭': 2504, '殄': 2505, '热': 2506, '纪': 2507, '录': 2508, '旻': 2509, '茉': 2510, '刮': 2511, '球': 2512, '罨': 2513, '奋': 2514, '髻': 2515, '王': 2516, '诜': 2517, '嗄': 2518, '氛': 2519, '辂': 2520, '溆': 2521, '厥': 2522, '浸': 2523, '曳': 2524, '噫': 2525, '称': 2526, '岱': 2527, '萃': 2528, '根': 2529, '隍': 2530, '闷': 2531, '凰': 2532, '没': 2533, '荭': 2534, '咤': 2535, '饧': 2536, '蛐': 2537, '忉': 2538, '戏': 2539, '琛': 2540, '妍': 2541, '涌': 2542, '撅': 2543, '弭': 2544, '铙': 2545, '痴': 2546, '惶': 2547, '听': 2548, 'け': 2549, '卜': 2550, '设': 2551, '控': 2552, '羝': 2553, '夕': 2554, '俯': 2555, '娃': 2556, '诮': 2557, '晏': 2558, '镡': 2559, '蓝': 2560, '陡': 2561, '桓': 2562, '燔': 2563, '艳': 2564, '舰': 2565, '缡': 2566, '茹': 2567, '耍': 2568, '舌': 2569, '懆': 2570, '杓': 2571, '召': 2572, '渑': 2573, '恰': 2574, '擅': 2575, '播': 2576, '椿': 2577, '杳': 2578, '夫': 2579, '泓': 2580, '捶': 2581, '全': 2582, '矶': 2583, '若': 2584, '迩': 2585, '开': 2586, '裾': 2587, '壅': 2588, '疾': 2589, '辞': 2590, '篚': 2591, '馑': 2592, '衬': 2593, '铉': 2594, '陈': 2595, '艘': 2596, '曦': 2597, '珍': 2598, '厮': 2599, '费': 2600, '韶': 2601, '书': 2602, '玄': 2603, '拖': 2604, '俄': 2605, '僚': 2606, '蕾': 2607, '计': 2608, '侵': 2609, '咀': 2610, '品': 2611, '茕': 2612, '欷': 2613, '后': 2614, '隋': 2615, '胡': 2616, '觚': 2617, '武': 2618, '五': 2619, '幸': 2620, '亟': 2621, '霭': 2622, '聃': 2623, '玉': 2624, '葩': 2625, '畸': 2626, '檠': 2627, '麈': 2628, '长': 2629, '槭': 2630, '吓': 2631, '谢': 2632, '衩': 2633, '鲍': 2634, '密': 2635, 'Ｖ': 2636, '寝': 2637, '屐': 2638, '架': 2639, '狩': 2640, '诈': 2641, '茔': 2642, '灯': 2643, '暧': 2644, '太': 2645, '亘': 2646, '倜': 2647, '翅': 2648, '龚': 2649, '给': 2650, '沂': 2651, '夏': 2652, '宣': 2653, '诀': 2654, '阃': 2655, '孱': 2656, '璧': 2657, '蟹': 2658, '玫': 2659, '浔': 2660, '底': 2661, '浏': 2662, '揎': 2663, '栩': 2664, '稽': 2665, '亮': 2666, '赋': 2667, 'ㄉ': 2668, '霓': 2669, '辟': 2670, '巾': 2671, '卩': 2672, '骏': 2673, '性': 2674, '躲': 2675, '戬': 2676, '辐': 2677, '旆': 2678, '毙': 2679, '牒': 2680, '昃': 2681, '失': 2682, '状': 2683, '昵': 2684, '脂': 2685, '兑': 2686, '⑵': 2687, '楠': 2688, '待': 2689, '鼍': 2690, '严': 2691, '皈': 2692, '咛': 2693, '紫': 2694, '狎': 2695, '尿': 2696, '陀': 2697, '鸽': 2698, '干': 2699, '蔡': 2700, '镠': 2701, '濡': 2702, '簪': 2703, '言': 2704, '迓': 2705, '握': 2706, '芰': 2707, '延': 2708, '腊': 2709, '讷': 2710, '枢': 2711, '樨': 2712, '吞': 2713, '逖': 2714, '拙': 2715, '矍': 2716, '郑': 2717, '桩': 2718, '绿': 2719, '抵': 2720, '蜀': 2721, '《': 2722, '忖': 2723, '猝': 2724, '豹': 2725, '嶙': 2726, '偻': 2727, '创': 2728, '倏': 2729, '啖': 2730, '奉': 2731, '酒': 2732, '犹': 2733, '痒': 2734, '塔': 2735, '狞': 2736, '匿': 2737, 'ピ': 2738, '悠': 2739, '啅': 2740, '跟': 2741, '胜': 2742, '弊': 2743, '垛': 2744, '缘': 2745, '瘿': 2746, 'х': 2747, '黍': 2748, '渍': 2749, '瀑': 2750, '溜': 2751, '阻': 2752, '萱': 2753, '豪': 2754, '矮': 2755, '硗': 2756, '澹': 2757, '甑': 2758, '浑': 2759, '沿': 2760, '}': 2761, '郄': 2762, '飞': 2763, '遨': 2764, '葡': 2765, '恒': 2766, '煎': 2767, '遽': 2768, '嘛': 2769, '崤': 2770, '掌': 2771, '泫': 2772, '啼': 2773, '扛': 2774, '骡': 2775, '娆': 2776, '陶': 2777, '皇': 2778, '公': 2779, '宥': 2780, '橙': 2781, '资': 2782, '墟': 2783, '醺': 2784, '经': 2785, '蒉': 2786, '脾': 2787, '普': 2788, '筠': 2789, '疮': 2790, '数': 2791, '住': 2792, '离': 2793, '胲': 2794, '蓑': 2795, '篷': 2796, '淇': 2797, '域': 2798, '轧': 2799, '瘵': 2800, '.': 2801, '置': 2802, '蹇': 2803, '湾': 2804, '辄': 2805, '历': 2806, '洞': 2807, '橹': 2808, '归': 2809, '雌': 2810, '椹': 2811, '遏': 2812, '务': 2813, '棠': 2814, '傍': 2815, '圹': 2816, '直': 2817, '苎': 2818, '幄': 2819, '摅': 2820, '簟': 2821, '翩': 2822, '倬': 2823, '龠': 2824, '赛': 2825, '蹑': 2826, '付': 2827, '伯': 2828, '遥': 2829, '针': 2830, '徨': 2831, '帻': 2832, '孀': 2833, '锦': 2834, '诩': 2835, '侣': 2836, '蛆': 2837, '条': 2838, '獐': 2839, '靶': 2840, '划': 2841, '胁': 2842, '掀': 2843, '平': 2844, '蠹': 2845, '部': 2846, '钻': 2847, '笛': 2848, '盍': 2849, '倩': 2850, '受': 2851, '濉': 2852, '摄': 2853, '涸': 2854, '繇': 2855, '骂': 2856, '而': 2857, '莘': 2858, '缅': 2859, '秩': 2860, '灿': 2861, '箝': 2862, '郝': 2863, '恕': 2864, '绠': 2865, '缺': 2866, '点': 2867, '挈': 2868, '栎': 2869, '银': 2870, '耳': 2871, '峦': 2872, '语': 2873, '谍': 2874, '谑': 2875, '隶': 2876, '累': 2877, '毗': 2878, '究': 2879, '矫': 2880, '鲑': 2881, '爹': 2882, '庞': 2883, '死': 2884, '猩': 2885, '毓': 2886, '并': 2887, '圣': 2888, '醅': 2889, '略': 2890, '脆': 2891, '疃': 2892, '抖': 2893, '楯': 2894, '溶': 2895, 'ち': 2896, '朔': 2897, '漓': 2898, '咙': 2899, '莲': 2900, '旨': 2901, '狭': 2902, '除': 2903, '印': 2904, '朋': 2905, '瞻': 2906, '乃': 2907, '蛛': 2908, '依': 2909, '萤': 2910, '匣': 2911, '鞭': 2912, '在': 2913, '脯': 2914, '未': 2915, '险': 2916, '渭': 2917, '刑': 2918, '邵': 2919, '漪': 2920, '迅': 2921, '海': 2922, '茁': 2923, '好': 2924, '蠖': 2925, '阡': 2926, '虫': 2927, '轾': 2928, '黻': 2929, '群': 2930, '徵': 2931, '逞': 2932, '扑': 2933, '醒': 2934, '裙': 2935, '看': 2936, '要': 2937, '踢': 2938, '兀': 2939, '歆': 2940, '日': 2941, '蓬': 2942, '窘': 2943, '馋': 2944, '氏': 2945, '汰': 2946, '相': 2947, '粼': 2948, '履': 2949, '莩': 2950, '恙': 2951, '颡': 2952, '葱': 2953, '滂': 2954, '最': 2955, '繁': 2956, '榱': 2957, '眈': 2958, '批': 2959, '摧': 2960, '黄': 2961, '蜚': 2962, '醵': 2963, '了': 2964, '蚩': 2965, '姹': 2966, '爻': 2967, '漕': 2968, '棕': 2969, '锓': 2970, '嗜': 2971, '洽': 2972, '篙': 2973, '灸': 2974, '猖': 2975, '嵚': 2976, '觳': 2977, '坡': 2978, '南': 2979, '乏': 2980, '晋': 2981, '典': 2982, '降': 2983, '襟': 2984, '姬': 2985, '舣': 2986, '通': 2987, '乇': 2988, '涣': 2989, '翎': 2990, '谁': 2991, '困': 2992, '厕': 2993, '桉': 2994, '阕': 2995, '轸': 2996, '急': 2997, '闭': 2998, '擂': 2999, '治': 3000, '郐': 3001, '>': 3002, '锸': 3003, '常': 3004, '肢': 3005, '馒': 3006, '娅': 3007, '低': 3008, '熳': 3009, '渔': 3010, '牛': 3011, '嵛': 3012, '震': 3013, '液': 3014, '箍': 3015, '赚': 3016, '戛': 3017, '宏': 3018, '奶': 3019, '佞': 3020, '声': 3021, '寄': 3022, '环': 3023, '嗽': 3024, '位': 3025, '盂': 3026, '嘏': 3027, '呖': 3028, '卒': 3029, '楼': 3030, '搀': 3031, '村': 3032, '藉': 3033, '鼎': 3034, '戴': 3035, '恹': 3036, '窜': 3037, '药': 3038, '侮': 3039, '辽': 3040, '瞠': 3041, '毵': 3042, '鲇': 3043, '彩': 3044, '番': 3045, '断': 3046, '袤': 3047, '觉': 3048, '也': 3049, 'ò': 3050, '戒': 3051, '佼': 3052, '婉': 3053, '笔': 3054, '簇': 3055, '愣': 3056, '皑': 3057, '泣': 3058, '畏': 3059, '奠': 3060, '来': 3061, '暝': 3062, '飧': 3063, '谙': 3064, '潜': 3065, '饯': 3066, '奂': 3067, '晚': 3068, '纡': 3069, '宦': 3070, '黼': 3071, '崦': 3072, '硬': 3073, '客': 3074, '抟': 3075, '谴': 3076, '阁': 3077, '鉴': 3078, '缴': 3079, '贼': 3080, '屿': 3081, '裯': 3082, '郏': 3083, '宰': 3084, '蕉': 3085, '懵': 3086, '月': 3087, '专': 3088, '绦': 3089, '损': 3090, '毛': 3091, '情': 3092, '谓': 3093, '惜': 3094, '竟': 3095, '古': 3096, '辰': 3097, '左': 3098, '潞': 3099, '蚨': 3100, '缬': 3101, '醋': 3102, '棰': 3103, '评': 3104, '稚': 3105, '诏': 3106, '衫': 3107, '獠': 3108, '忔': 3109, '腕': 3110, '箬': 3111, '届': 3112, '端': 3113, '甓': 3114, '姥': 3115, '寅': 3116, '娩': 3117, '傲': 3118, '箭': 3119, '蜿': 3120, '圃': 3121, '宕': 3122, '题': 3123, '眵': 3124, '妹': 3125, '藓': 3126, '蹂': 3127, '级': 3128, '狄': 3129, '篌': 3130, '萄': 3131, '优': 3132, '燎': 3133, '粱': 3134, '率': 3135, '罹': 3136, '疵': 3137, '毡': 3138, '霁': 3139, '怿': 3140, '害': 3141, '癖': 3142, '键': 3143, '蝼': 3144, '验': 3145, '垠': 3146, '秃': 3147, '轲': 3148, '蔷': 3149, '臾': 3150, '酷': 3151, '馀': 3152, '芩': 3153, '咋': 3154, '硫': 3155, '傀': 3156, '铨': 3157, '肚': 3158, '鬯': 3159, '墉': 3160, '瓴': 3161, '遴': 3162, '鲈': 3163, '蛞': 3164, '嗅': 3165, '参': 3166, '贯': 3167, '弼': 3168, '锅': 3169, '睬': 3170, '字': 3171, '囤': 3172, '芝': 3173, '备': 3174, '啾': 3175, '桅': 3176, '蟋': 3177, '先': 3178, '杷': 3179, '俳': 3180, '哉': 3181, '叫': 3182, '丝': 3183, '译': 3184, '盛': 3185, '误': 3186, '厘': 3187, '讼': 3188, '莞': 3189, '诣': 3190, '阿': 3191, '己': 3192, '柙': 3193, '砾': 3194, '宁': 3195, '裤': 3196, '筝': 3197, '撋': 3198, '耆': 3199, '剡': 3200, '貉': 3201, '乍': 3202, '傩': 3203, '督': 3204, '白': 3205, '琥': 3206, '骐': 3207, '厉': 3208, '玕': 3209, '纨': 3210, '歼': 3211, '送': 3212, '壕': 3213, '汹': 3214, '嵋': 3215, '迦': 3216, '信': 3217, '内': 3218, '佐': 3219, '鞅': 3220, '兕': 3221, '孤': 3222, '晨': 3223, '妊': 3224, '异': 3225, '诡': 3226, '耒': 3227, '章': 3228, '嘈': 3229, '策': 3230, '始': 3231, '惹': 3232, '俑': 3233, '苑': 3234, '齐': 3235, '团': 3236, '鹅': 3237, '惚': 3238, '阱': 3239, '眢': 3240, '酊': 3241, '苏': 3242, '菰': 3243, '肖': 3244, '悌': 3245, '奴': 3246, '愧': 3247, '审': 3248, '兔': 3249, '存': 3250, '均': 3251, '微': 3252, '跏': 3253, 'с': 3254, '鹂': 3255, '岸': 3256, '妖': 3257, '过': 3258, '藜': 3259, '】': 3260, '铠': 3261, '恃': 3262, '雠': 3263, '哄': 3264, '缁': 3265, '踊': 3266, '炳': 3267, '缫': 3268, '啧': 3269, '撼': 3270, '眩': 3271, '滚': 3272, '帽': 3273, '搜': 3274, '莓': 3275, '进': 3276, '瑶': 3277, '惰': 3278, '浓': 3279, '巴': 3280, '扣': 3281, '杵': 3282, '破': 3283, '鸩': 3284, '逻': 3285, '做': 3286, '琶': 3287, '桤': 3288, '旁': 3289, '雪': 3290, '嶷': 3291, '稀': 3292, '羔': 3293, '源': 3294, '诹': 3295, '博': 3296, '肱': 3297, '懒': 3298, '蟾': 3299, '阆': 3300, '觯': 3301, '璐': 3302, '缚': 3303, '鲤': 3304, '袒': 3305, '铄': 3306, '杰': 3307, '徼': 3308, '揽': 3309, '擎': 3310, '编': 3311, '序': 3312, '钲': 3313, '汾': 3314, '酪': 3315, '瘢': 3316, '氓': 3317, '升': 3318, '陛': 3319, '躬': 3320, '深': 3321, '探': 3322, '瓠': 3323, '绥': 3324, '伫': 3325, '饭': 3326, '导': 3327, '阙': 3328, '顺': 3329, '邗': 3330, '春': 3331, '恋': 3332, '漆': 3333, '尖': 3334, '琬': 3335, '饩': 3336, '隙': 3337, '蘧': 3338, '野': 3339, '荠': 3340, '螃': 3341, '士': 3342, '嗤': 3343, '脔': 3344, '郭': 3345, '帅': 3346, '樵': 3347, '铁': 3348, '璨': 3349, '跛': 3350, '颈': 3351, '渗': 3352, '谐': 3353, '踪': 3354, '菲': 3355, '糟': 3356, '漭': 3357, '鲜': 3358, '憨': 3359, '帷': 3360, '痨': 3361, '彤': 3362, '翱': 3363, '欺': 3364, '碧': 3365, '卷': 3366, '檀': 3367, '邑': 3368, '艇': 3369, '躐': 3370, '瑛': 3371, '往': 3372, '聘': 3373, '邂': 3374, '匮': 3375, '呈': 3376, '锷': 3377, '熠': 3378, '龄': 3379, '孜': 3380, '擘': 3381, '东': 3382, '词': 3383, '馥': 3384, '皤': 3385, '鞯': 3386, '哥': 3387, '谟': 3388, '抹': 3389, '满': 3390, '瞢': 3391, '鲆': 3392, '温': 3393, '呦': 3394, '葵': 3395, '鼯': 3396, '潋': 3397, '泡': 3398, '茜': 3399, '寻': 3400, '譬': 3401, '睨': 3402, '约': 3403, '麝': 3404, '猊': 3405, '个': 3406, '跗': 3407, '鼻': 3408, '绪': 3409, '支': 3410, '桁': 3411, '涎': 3412, '箱': 3413, '帆': 3414, '刳': 3415, '翌': 3416, '别': 3417, '忿': 3418, '鲲': 3419, '澎': 3420, '簦': 3421, '缃': 3422, '砉': 3423, '致': 3424, '陲': 3425, '腹': 3426, '促': 3427, '难': 3428, '驺': 3429, '令': 3430, '＿': 3431, '胸': 3432, '忱': 3433, '僦': 3434, '氤': 3435, '铛': 3436, '惆': 3437, '苍': 3438, '止': 3439, '潭': 3440, '兽': 3441, '库': 3442, '拾': 3443, '秾': 3444, '雎': 3445, '蹒': 3446, '甸': 3447, '旃': 3448, '迄': 3449, '淰': 3450, '需': 3451, '岳': 3452, '态': 3453, '讯': 3454, '乘': 3455, '货': 3456, '恼': 3457, '鄞': 3458, '琰': 3459, '范': 3460, '夥': 3461, '耽': 3462, '辩': 3463, '俎': 3464, '睹': 3465, '折': 3466, '秉': 3467, '韬': 3468, '怒': 3469, '酏': 3470, '羯': 3471, '吮': 3472, '桷': 3473, '吐': 3474, '掣': 3475, '洮': 3476, '谩': 3477, '甫': 3478, '麦': 3479, '杯': 3480, '丛': 3481, '齑': 3482, '枉': 3483, '俺': 3484, '腴': 3485, '饪': 3486, '鲙': 3487, '羌': 3488, '鹁': 3489, '啁': 3490, '埒': 3491, '沛': 3492, '页': 3493, '罄': 3494, '瀛': 3495, '诨': 3496, '旄': 3497, '衮': 3498, '丿': 3499, '知': 3500, '粢': 3501, '惟': 3502, '蝶': 3503, '料': 3504, '睡': 3505, '尚': 3506, '氐': 3507, '恩': 3508, '惯': 3509, '遮': 3510, '笈': 3511, '莫': 3512, '终': 3513, '祜': 3514, '爵': 3515, '墅': 3516, '姓': 3517, '屹': 3518, '沌': 3519, '僝': 3520, '颜': 3521, '秀': 3522, '禀': 3523, '勒': 3524, '亭': 3525, '馘': 3526, '弯': 3527, '邀': 3528, '喈': 3529, '缕': 3530, '呤': 3531, '瘴': 3532, '米': 3533, '橘': 3534, '削': 3535, '抛': 3536, '龈': 3537, '伛': 3538, '泠': 3539, '冽': 3540, '姒': 3541, '旧': 3542, '纺': 3543, '城': 3544, '恍': 3545, '舀': 3546, '乐': 3547, '卤': 3548, '殳': 3549, '燃': 3550, '桦': 3551, '聋': 3552, '婪': 3553, '唏': 3554, '我': 3555, '吁': 3556, '叟': 3557, '箴': 3558, '摘': 3559, '怜': 3560, '栈': 3561, '桶': 3562, '今': 3563, '咿': 3564, '\\ue3ff': 3565, '午': 3566, '决': 3567, '怯': 3568, '册': 3569, '弈': 3570, '蒲': 3571, '抚': 3572, '教': 3573, '园': 3574, '魂': 3575, '齿': 3576, '锢': 3577, '泰': 3578, '\\ue4bf': 3579, '”': 3580, '抑': 3581, '冁': 3582, '徕': 3583, '衾': 3584, '歧': 3585, '伤': 3586, 'Ａ': 3587, '竽': 3588, '政': 3589, '杉': 3590, '贤': 3591, '绅': 3592, '魅': 3593, '壤': 3594, '喃': 3595, '懔': 3596, '兮': 3597, '当': 3598, '酋': 3599, '缙': 3600, '迂': 3601, '饱': 3602, '萝': 3603, '２': 3604, '刂': 3605, '箸': 3606, '永': 3607, '舳': 3608, '顾': 3609, '次': 3610, '可': 3611, '腥': 3612, '绮': 3613, '鳊': 3614, '磔': 3615, '怅': 3616, '歃': 3617, '臬': 3618, '桔': 3619, '串': 3620, '效': 3621, '廖': 3622, '睥': 3623, '槿': 3624, '龋': 3625, '卸': 3626, '伽': 3627, '茅': 3628, '卯': 3629, '片': 3630, '藐': 3631, '捎': 3632, '蕤': 3633, '早': 3634, '蛄': 3635, '挞': 3636, '仂': 3637, '湃': 3638, '视': 3639, '煌': 3640, '荛': 3641, '浮': 3642, '汜': 3643, '丑': 3644, '只': 3645, '馔': 3646, '嫖': 3647, '蹈': 3648, '护': 3649, '瓒': 3650, '奔': 3651, '逋': 3652, '虞': 3653, '臼': 3654, '妈': 3655, '波': 3656, '岿': 3657, '铎': 3658, '弱': 3659, '盒': 3660, '地': 3661, '恭': 3662, '渚': 3663, '靥': 3664, '间': 3665, '旬': 3666, '论': 3667, '见': 3668, '连': 3669, '足': 3670, '鱼': 3671, '贲': 3672, '踏': 3673, '蜜': 3674, '翟': 3675, '籀': 3676, '伍': 3677, '眯': 3678, '晡': 3679, '试': 3680, '御': 3681, '偷': 3682, '卢': 3683, '刹': 3684, '棂': 3685, '尾': 3686, '超': 3687, '冀': 3688, '冰': 3689, '施': 3690, '褒': 3691, '轿': 3692, '沈': 3693, '篆': 3694, '阮': 3695, '芍': 3696, '郸': 3697, '跚': 3698, '渤': 3699, '甃': 3700, '咸': 3701, '僧': 3702, '穑': 3703, '哺': 3704, '劝': 3705, '雀': 3706, '贰': 3707, '邙': 3708, '酥': 3709, '衔': 3710, '龛': 3711, '舟': 3712, '蹊': 3713, '静': 3714, '革': 3715, '褥': 3716, '骤': 3717, '茆': 3718, '裟': 3719, '镂': 3720, '侍': 3721, '车': 3722, '仁': 3723, '谈': 3724, '晰': 3725, '掠': 3726, '楦': 3727, '撄': 3728, '悄': 3729, '帝': 3730, '畜': 3731, '烘': 3732, '斗': 3733, '娴': 3734, '邯': 3735, '锐': 3736, '佶': 3737, '稿': 3738, '霍': 3739, '健': 3740, '繭': 3741, '悻': 3742, '糠': 3743, '贻': 3744, '固': 3745, '辅': 3746, '撞': 3747, '丕': 3748, '俗': 3749, '罚': 3750, '宠': 3751, '绳': 3752, '矣': 3753, '琉': 3754, '搽': 3755, '囉': 3756, '谕': 3757, '菁': 3758, '冒': 3759, '牟': 3760, '肓': 3761, '晶': 3762, '枯': 3763, '翡': 3764, '省': 3765, '拌': 3766, '薪': 3767, '剪': 3768, '犯': 3769, '四': 3770, '莺': 3771, '昊': 3772, '凛': 3773, '蹰': 3774, '搏': 3775, '┾': 3776, '耿': 3777, '溱': 3778, '縻': 3779, '镊': 3780, '违': 3781, '霄': 3782, '拮': 3783, '拜': 3784, '钿': 3785, '闻': 3786, '喔': 3787, '饴': 3788, '患': 3789, '绛': 3790, '鹫': 3791, '揶': 3792, '罍': 3793, '板': 3794, '安': 3795, '偿': 3796, '鮓': 3797, '峭': 3798, '妥': 3799, '土': 3800, '企': 3801, '炀': 3802, '诠': 3803, '军': 3804, '锄': 3805, '鸥': 3806, '恶': 3807, '骅': 3808, '戊': 3809, '屺': 3810, '婀': 3811, '幢': 3812, '慧': 3813, '鸳': 3814, '沓': 3815, '详': 3816, '炜': 3817, '岩': 3818, '憝': 3819, '展': 3820, '匡': 3821, '蚪': 3822, '载': 3823, '觊': 3824, '谛': 3825, '迫': 3826, '洳': 3827, '尘': 3828, '煨': 3829, '劬': 3830, '薄': 3831, '崩': 3832, '舆': 3833, '鹓': 3834, 'ソ': 3835, '秣': 3836, '槌': 3837, '胎': 3838, '豉': 3839, '贮': 3840, '捐': 3841, '醯': 3842, '踞': 3843, '星': 3844, '徉': 3845, '结': 3846, '洛': 3847, '衄': 3848, '宾': 3849, '赢': 3850, '庸': 3851, '故': 3852, '蛱': 3853, '似': 3854, '答': 3855, '悸': 3856, '阄': 3857, '豢': 3858, '校': 3859, '梧': 3860, '蜃': 3861, '英': 3862, '抠': 3863, '钦': 3864, '饰': 3865, '蹴': 3866, '矧': 3867, '淬': 3868, '稂': 3869, '骎': 3870, '隗': 3871, '酽': 3872, '喧': 3873, '局': 3874, '宴': 3875, '炷': 3876, '；': 3877, '烟': 3878, '余': 3879, '用': 3880, '诤': 3881, '凹': 3882, '技': 3883, '舂': 3884, '呜': 3885, '号': 3886, '鹢': 3887, '鑺': 3888, '盱': 3889, '钝': 3890, '览': 3891, '廊': 3892, '郴': 3893, '庆': 3894, '痛': 3895, '粒': 3896, '酹': 3897, '年': 3898, '掩': 3899, '萧': 3900, '嶢': 3901, '匹': 3902, '践': 3903, '借': 3904, '赣': 3905, '沩': 3906, '砧': 3907, '酎': 3908, '忧': 3909, '湫': 3910, '权': 3911, '睛': 3912, '懊': 3913, '茱': 3914, '媸': 3915, '绽': 3916, '胙': 3917, '简': 3918, '冉': 3919, '麻': 3920, '炼': 3921, '樽': 3922, '介': 3923, '弧': 3924, '擗': 3925, '桴': 3926, '鸶': 3927, '卞': 3928, '筐': 3929, '扆': 3930, '振': 3931, '遣': 3932, '须': 3933, '双': 3934, '痍': 3935, '焙': 3936, '测': 3937, '母': 3938, '挼': 3939, '盎': 3940, '献': 3941, '泊': 3942, '荪': 3943, '腼': 3944, '飕': 3945, '枚': 3946, '师': 3947, '淫': 3948, '宋': 3949, '坞': 3950, '李': 3951, '垩': 3952, '殃': 3953, '爱': 3954, '员': 3955, '慈': 3956, '洧': 3957, '魉': 3958, '衰': 3959, '舷': 3960, '鹈': 3961, '羡': 3962, '插': 3963, '娜': 3964, '奥': 3965, '伐': 3966, '果': 3967, '持': 3968, '既': 3969, '蘸': 3970, '褫': 3971, '嘤': 3972, '矾': 3973, '拽': 3974, '扮': 3975, '蒡': 3976, '踌': 3977, '佳': 3978, '咬': 3979, '段': 3980, '猬': 3981, '骛': 3982, '遍': 3983, '返': 3984, '焉': 3985, '麾': 3986, '但': 3987, '然': 3988, '剥': 3989, '议': 3990, '沃': 3991, '喷': 3992, '菖': 3993, '挠': 3994, '晷': 3995, '氅': 3996, '铭': 3997, '珧': 3998, '？': 3999, '溽': 4000, '逄': 4001, '正': 4002, '工': 4003, '佩': 4004, '糁': 4005, '勃': 4006, '袜': 4007, '冤': 4008, '璎': 4009, '讦': 4010, '轫': 4011, '绣': 4012, '捋': 4013, '雹': 4014, '酤': 4015, '殒': 4016, '空': 4017, '俟': 4018, '戚': 4019, '寇': 4020, '奇': 4021, '调': 4022, '垫': 4023, '卦': 4024, '勋': 4025, '茏': 4026, '孥': 4027, '峨': 4028, '删': 4029, '寰': 4030, '殿': 4031, '沧': 4032, '惝': 4033, '报': 4034, '榆': 4035, '筹': 4036, '睫': 4037, '拈': 4038, '欤': 4039, '谘': 4040, '耕': 4041, '鹄': 4042, '伶': 4043, '障': 4044, '秽': 4045, '颉': 4046, '漉': 4047, '唧': 4048, '朴': 4049, '揄': 4050, '祧': 4051, '中': 4052, '謦': 4053, '馁': 4054, 'ā': 4055, '粲': 4056, '被': 4057, '磴': 4058, '筛': 4059, '理': 4060, '核': 4061, '鸿': 4062, '涑': 4063, '梓': 4064, '柽': 4065, '装': 4066, '滋': 4067, '钳': 4068, '老': 4069, '蛤': 4070, '┭': 4071, '膏': 4072, '系': 4073, '蝎': 4074, '候': 4075, '挪': 4076, '轳': 4077, '嬴': 4078, '荷': 4079, '裀': 4080, '焘': 4081, '邺': 4082, '嚎': 4083, '这': 4084, '及': 4085, '梵': 4086, '思': 4087, '腋': 4088, '瓯': 4089, '么': 4090, '唱': 4091, '翕': 4092, '喜': 4093, '埸': 4094, '搅': 4095, '和': 4096, '蜂': 4097, '鹿': 4098, '荑': 4099, '蔚': 4100, '顿': 4101, '斤': 4102, '与': 4103, '眷': 4104, '爪': 4105, '倪': 4106, '拨': 4107, '丞': 4108, '岜': 4109, '输': 4110, '趺': 4111, '皮': 4112, '寂': 4113, 'が': 4114, '敞': 4115, '厦': 4116, '秸': 4117, '筱': 4118, '攀': 4119, '杲': 4120, '屉': 4121, '剀': 4122, '百': 4123, '缸': 4124, '川': 4125, '酉': 4126, '徒': 4127, '悼': 4128, '贪': 4129, '慳': 4130, '娑': 4131, '逦': 4132, '蛙': 4133, 'ヵ': 4134, '栗': 4135, '乞': 4136, '裥': 4137, '胝': 4138, '虽': 4139, '鲂': 4140, '浃': 4141, '浍': 4142, '辙': 4143, '肃': 4144, '规': 4145, '鹑': 4146, '磨': 4147, '榻': 4148, '瑰': 4149, '、': 4150, '抬': 4151, '杀': 4152, '肾': 4153, '鲁': 4154, '作': 4155, '魏': 4156, '熊': 4157, '徐': 4158, '飙': 4159, '瘁': 4160, '缨': 4161, '养': 4162, '笠': 4163, 'や': 4164, '址': 4165, '肠': 4166, '耐': 4167, '子': 4168, '仇': 4169, '合': 4170, '胶': 4171, '赐': 4172, '貔': 4173, '舜': 4174, '阶': 4175, '洲': 4176, '胞': 4177, '勤': 4178, '忍': 4179, '砰': 4180, '徘': 4181, '嗥': 4182, '停': 4183, '浥': 4184, '芨': 4185, '秦': 4186, '镳': 4187, '已': 4188, '胄': 4189, '篾': 4190, '蕨': 4191, '鸟': 4192, '镜': 4193, '贞': 4194, '湟': 4195, '欣': 4196, '掇': 4197, '暨': 4198, '积': 4199, '羹': 4200, '样': 4201, '讴': 4202, '迳': 4203, '昏': 4204, '屦': 4205, '》': 4206, '仝': 4207, '荜': 4208, '驶': 4209, '莳': 4210, 'シ': 4211, '伸': 4212, '荧': 4213, '幌': 4214, '俸': 4215, '绍': 4216, '互': 4217, '威': 4218, '惠': 4219, '犒': 4220, '艟': 4221, '卖': 4222, '嬉': 4223, '管': 4224, '弋': 4225, '葭': 4226, '慎': 4227, '鄂': 4228, '楫': 4229, '搔': 4230, '涩': 4231, '纳': 4232, '克': 4233, '浦': 4234, '肘': 4235, '菟': 4236, '牖': 4237, '燮': 4238, '樗': 4239, '旖': 4240, '亚': 4241, '虮': 4242, '义': 4243, '芽': 4244, '蕊': 4245, '蛮': 4246, '汁': 4247, '睇': 4248, '蹭': 4249, '润': 4250, '冯': 4251, '羲': 4252, '蹲': 4253, '篦': 4254, '敕': 4255, '髹': 4256, '闹': 4257, '摹': 4258, '悔': 4259, '鞚': 4260, '镒': 4261, '俩': 4262, '卮': 4263, '枵': 4264, '花': 4265, '阳': 4266, '越': 4267, '基': 4268, '居': 4269, '媚': 4270, '躁': 4271, '木': 4272, '躞': 4273, '尤': 4274, '禄': 4275, '澌': 4276, '砥': 4277, '寓': 4278, '逮': 4279, '濠': 4280, '醴': 4281, '渥': 4282, '狠': 4283, '飚': 4284, '垢': 4285, '童': 4286, '废': 4287, '婆': 4288, '季': 4289, '棱': 4290, '弹': 4291, '蹉': 4292, '桀': 4293, '元': 4294, '昧': 4295, '牝': 4296, '九': 4297, '缥': 4298, '座': 4299, '珂': 4300, '诟': 4301, '柄': 4302, '桕': 4303, '揖': 4304, '心': 4305, '蒹': 4306, '伏': 4307, '荆': 4308, '或': 4309, '敛': 4310, '璋': 4311, '冷': 4312, '柯': 4313, '纵': 4314, '薏': 4315, '蕖': 4316, '肩': 4317, '趣': 4318, '忒': 4319, '灏': 4320, '萼': 4321, '妁': 4322, '像': 4323, '濮': 4324, '蚀': 4325, '六': 4326, '撇': 4327, '婵': 4328, '竹': 4329, '汀': 4330, '起': 4331, '渴': 4332, '饬': 4333, '社': 4334, '瀹': 4335, '嘴': 4336, '臧': 4337, '达': 4338, '某': 4339, '霞': 4340, '愫': 4341, '咻': 4342, '畎': 4343, '棺': 4344, '栲': 4345, '路': 4346, '菀': 4347, '少': 4348, '巨': 4349, '捺': 4350, '畀': 4351, '砣': 4352, '钮': 4353, '造': 4354, '钢': 4355, '蜍': 4356, '房': 4357, '吉': 4358, '肆': 4359, '煦': 4360, '凯': 4361, '析': 4362, '首': 4363, '苘': 4364, '续': 4365, '夤': 4366, '屡': 4367, '怎': 4368, 'Ｗ': 4369, '潮': 4370, '禊': 4371, '朗': 4372, '獒': 4373, '嫱': 4374, '耻': 4375, '邹': 4376, '卑': 4377, '枘': 4378, '夭': 4379, '苛': 4380, '柜': 4381, '闱': 4382, '凝': 4383, '祠': 4384, '跬': 4385, '萁': 4386, '弟': 4387, '跣': 4388, '鲵': 4389, '柔': 4390, '沁': 4391, '厅': 4392, '，': 4393, '铲': 4394, '狯': 4395, '阎': 4396, '涵': 4397, '于': 4398, '仆': 4399, '呵': 4400, '骄': 4401, '篝': 4402, '泞': 4403, '裸': 4404, '棣': 4405, '傥': 4406, '差': 4407, '刁': 4408, '俪': 4409, '占': 4410, '跸': 4411, '璇': 4412, '轮': 4413, '邻': 4414, '霸': 4415, '泥': 4416, '兹': 4417, '‘': 4418, '莉': 4419, '顽': 4420, '敌': 4421, '皎': 4422, '穰': 4423, '诙': 4424, '僮': 4425, '梨': 4426, '戟': 4427, '炙': 4428, '橄': 4429, '沤': 4430, '蹶': 4431, '掏': 4432, '怕': 4433, '濒': 4434, '默': 4435, '猛': 4436, '爆': 4437, '淝': 4438, '唐': 4439, '向': 4440, '火': 4441, '杠': 4442, '篮': 4443, '癃': 4444, '拼': 4445, '愈': 4446, '螽': 4447, '绶': 4448, '弗': 4449, '颠': 4450, '汇': 4451, '澒': 4452, '颚': 4453, '蛇': 4454, '槎': 4455, '扌': 4456, '曜': 4457, '暄': 4458, '顸': 4459, '曾': 4460, '樊': 4461, '俞': 4462, '蓦': 4463, '掬': 4464, '醉': 4465, '鞠': 4466, '明': 4467, '喙': 4468, '抉': 4469, '不': 4470, '凌': 4471, '萋': 4472, '函': 4473, '酢': 4474, '尹': 4475, '纲': 4476, '芴': 4477, '联': 4478, '阚': 4479, '竖': 4480, '绌': 4481, '袂': 4482, '暑': 4483, '医': 4484, '褐': 4485, '沆': 4486, '船': 4487, '厌': 4488, '旅': 4489, '体': 4490, '拭': 4491, '墩': 4492, '吸': 4493, '楹': 4494, '巢': 4495, '茶': 4496, '盗': 4497, '蜗': 4498, '岘': 4499, '两': 4500, '淞': 4501, '虐': 4502, '涝': 4503, '篱': 4504, '湔': 4505, '鄜': 4506, '表': 4507, 'ど': 4508, '弁': 4509, '辋': 4510, '桠': 4511, '乔': 4512, '狨': 4513, '伟': 4514, '猎': 4515, '钗': 4516, '所': 4517, '撺': 4518, '伪': 4519, '瞋': 4520, '吴': 4521, '绯': 4522, '枷': 4523, '辊': 4524, '吾': 4525, '天': 4526, '簧': 4527, '等': 4528, '认': 4529, '踯': 4530, '倭': 4531, '劲': 4532, '下': 4533, '乖': 4534, '汛': 4535, '朦': 4536, '粪': 4537, '鼠': 4538, '斛': 4539, '橡': 4540, '把': 4541, '雩': 4542, '特': 4543, '罟': 4544, 'ь': 4545, '恬': 4546, '柁': 4547, '倾': 4548, '石': 4549, '油': 4550, '谣': 4551, '惋': 4552, '虹': 4553, '喑': 4554, '祺': 4555, '朵': 4556, '统': 4557, '铅': 4558, '腮': 4559, '惊': 4560, '愤': 4561, '驷': 4562, '含': 4563, '崖': 4564, '憔': 4565, '殊': 4566, '茨': 4567, '组': 4568, '郊': 4569, '诱': 4570, '幡': 4571, '兴': 4572, '萍': 4573, '恧': 4574, '柘': 4575, '蜾': 4576, '短': 4577, '念': 4578, '彘': 4579, '崎': 4580, '珑': 4581, '沦': 4582, '毹': 4583, '箨': 4584, '马': 4585, '聊': 4586, '柏': 4587, '察': 4588, '驯': 4589, '倡': 4590, '晟': 4591, '蹬': 4592, '习': 4593, '葛': 4594, '貌': 4595, '善': 4596, '寐': 4597, '侃': 4598, '鹎': 4599, '趾': 4600, '霹': 4601, '皙': 4602, '跨': 4603, '涤': 4604, '舸': 4605, '跽': 4606, '拂': 4607, '帙': 4608, '熹': 4609, '堡': 4610, '棼': 4611, '喟': 4612, '豫': 4613, '漫': 4614, '炯': 4615, '琳': 4616, '迁': 4617, '赌': 4618, '靓': 4619, '祁': 4620, '悯': 4621, '豸': 4622, '神': 4623, '箕': 4624, '陪': 4625, '坑': 4626, '话': 4627, '崇': 4628, '鹚': 4629, '蔓': 4630, '侏': 4631, '陟': 4632, '亏': 4633, '挹': 4634, '飐': 4635, '袅': 4636, '鞘': 4637, '陕': 4638, '艚': 4639, '旦': 4640, '袄': 4641, '剔': 4642, '珞': 4643, '井': 4644, '扼': 4645, '涟': 4646, '模': 4647, '半': 4648, '萨': 4649, '夷': 4650, '建': 4651, '巅': 4652, '比': 4653, '芙': 4654, '垦': 4655, '倥': 4656, '吼': 4657, '戋': 4658, '丧': 4659, '泸': 4660, '截': 4661, '孺': 4662, '滓': 4663, '蚁': 4664, '益': 4665, '酲': 4666, '鞋': 4667, '嘿': 4668, '葫': 4669, '醇': 4670, '示': 4671, '纹': 4672, '写': 4673, '俐': 4674, '泉': 4675, '爷': 4676, '瓜': 4677, '侧': 4678, '去': 4679, '懿': 4680, '邃': 4681, '扁': 4682, '惺': 4683, '出': 4684, '丰': 4685, '玛': 4686, '斥': 4687, '丈': 4688, '孙': 4689, '盥': 4690, '以': 4691, '幛': 4692, '婚': 4693, '漠': 4694, '况': 4695, '告': 4696, '厩': 4697, '幞': 4698, '闵': 4699, '懑': 4700, '妨': 4701, '彼': 4702, '碌': 4703, '洁': 4704, '距': 4705, '眶': 4706, '妃': 4707, '坏': 4708, '饕': 4709, '窬': 4710, '蹙': 4711, '精': 4712, '泮': 4713, '杆': 4714, '婕': 4715, '边': 4716, '夺': 4717, '枥': 4718, '颌': 4719, '跃': 4720, '鞲': 4721, '启': 4722, '斋': 4723, '釜': 4724, '讹': 4725, '挥': 4726, '琚': 4727, '贵': 4728, '忆': 4729, '犬': 4730, '竭': 4731, '竣': 4732, '灞': 4733, '筋': 4734, '俶': 4735, '埋': 4736, '乡': 4737, '嫁': 4738, '换': 4739, '疣': 4740, '瑁': 4741, '劣': 4742, '筒': 4743, '蜒': 4744, '裕': 4745, '道': 4746, '附': 4747, '限': 4748, '友': 4749, '鸣': 4750, '遁': 4751, '灺': 4752, '休': 4753, '襁': 4754, '骧': 4755, '嫦': 4756, '鹣': 4757, '缧': 4758, '螯': 4759, '蚤': 4760, '芋': 4761, '馈': 4762, '拳': 4763, '鼋': 4764, '缜': 4765, '掳': 4766, '绀': 4767, '郢': 4768, '鸭': 4769, '闽': 4770, '聚': 4771, '鹪': 4772, '扉': 4773, '滩': 4774, '复': 4775, '披': 4776, '蝇': 4777, '莼': 4778, '硌': 4779, '楝': 4780, '鴂': 4781, '阴': 4782, '侠': 4783, '恽': 4784, '菽': 4785, '粽': 4786, '蠲': 4787, '潇': 4788, '夸': 4789, '寡': 4790, '猗': 4791, '骊': 4792, '峰': 4793, '沽': 4794, '诃': 4795, '漳': 4796, '岫': 4797, '芷': 4798, '銮': 4799, '馨': 4800, '钏': 4801, '擐': 4802, '陨': 4803, '壶': 4804, '灾': 4805, '茑': 4806, '衢': 4807, '膝': 4808, '凄': 4809, '仄': 4810, '祗': 4811, '康': 4812, '家': 4813, '饫': 4814, '雉': 4815, '韵': 4816, '哪': 4817, '聿': 4818, '粝': 4819, '谒': 4820, '湿': 4821, '倍': 4822, '朱': 4823, '鳄': 4824, '泪': 4825, '沱': 4826, '菇': 4827, '细': 4828, '鹉': 4829, '末': 4830, '拘': 4831, '姊': 4832, '恣': 4833, '触': 4834, '父': 4835, '恸': 4836, '锡': 4837, '翁': 4838, '肥': 4839, '宫': 4840, '舵': 4841, '侨': 4842, '辛': 4843, '槁': 4844, '诳': 4845, '絷': 4846, '蘼': 4847, '铮': 4848, '邱': 4849, '坂': 4850, '拔': 4851, '鄹': 4852, '贴': 4853, '迥': 4854, '馗': 4855, '响': 4856, '到': 4857, '帔': 4858, '雍': 4859, '捻': 4860, '驸': 4861, '霎': 4862, '毫': 4863, '榴': 4864, '髦': 4865, '从': 4866, '酃': 4867, '偎': 4868, '堍': 4869, '错': 4870, '惫': 4871, '陔': 4872, '谠': 4873, '鲥': 4874, '捩': 4875, '跪': 4876, '万': 4877, '醪': 4878, '箔': 4879, '俱': 4880, '黏': 4881, '访': 4882, '亥': 4883, '戈': 4884, '缛': 4885, '剂': 4886, '戌': 4887, '嗔': 4888, '裼': 4889, '功': 4890, '萸': 4891, '辗': 4892, '疆': 4893, '鹭': 4894, '妆': 4895, '场': 4896, '宪': 4897, '骇': 4898, '衣': 4899, '辍': 4900, '扪': 4901, '肿': 4902, '注': 4903, '烽': 4904, '残': 4905, '民': 4906, 'ょ': 4907, '化': 4908, '澜': 4909, '叔': 4910, '尼': 4911, '讠': 4912, '吏': 4913, '绡': 4914, '碑': 4915, '霏': 4916, '坚': 4917, '榜': 4918, '胥': 4919, '晒': 4920, '竞': 4921, '哩': 4922, '糊': 4923, '诋': 4924, '羊': 4925, '洙': 4926, '铸': 4927, '荀': 4928, '眄': 4929, '矛': 4930, '昂': 4931, '邮': 4932, '堂': 4933, '迤': 4934, '蝠': 4935, '谧': 4936, '痕': 4937, '磅': 4938, '拣': 4939, '冈': 4940, '餍': 4941, '蜕': 4942, '朝': 4943, '雨': 4944, '赶': 4945, '陆': 4946, '逢': 4947, '呕': 4948, '汶': 4949, '瘼': 4950, '熔': 4951, '芘': 4952, '烦': 4953, '滥': 4954, '哽': 4955, '箧': 4956, '稳': 4957, '徇': 4958, '鸺': 4959, '苻': 4960, '椅': 4961, '耦': 4962, '凉': 4963, '聒': 4964, '趋': 4965, '怊': 4966, '诚': 4967, '枋': 4968, '熙': 4969, '丘': 4970, '浣': 4971, '碣': 4972, '恻': 4973, '鹃': 4974, '腆': 4975, '貅': 4976, '镌': 4977, '灌': 4978, '骢': 4979, '徜': 4980, '周': 4981, '勇': 4982, '此': 4983, '瑜': 4984, '鬓': 4985, '兜': 4986, '香': 4987, '境': 4988, '拯': 4989, '誓': 4990, '睍': 4991, '忽': 4992, '缠': 4993, '森': 4994, '丐': 4995, '酝': 4996, '助': 4997, '棋': 4998, '骆': 4999, '久': 5000, '交': 5001, '卿': 5002, '疗': 5003, '缄': 5004, '顶': 5005, '蹀': 5006, '詹': 5007, '询': 5008, '陌': 5009, '篪': 5010, '喉': 5011, '亦': 5012, '讲': 5013, '笙': 5014, '祝': 5015, '巫': 5016, '外': 5017, '騕': 5018, '立': 5019, '瘐': 5020, '巧': 5021, '嫉': 5022, '蓐': 5023, '舐': 5024, '磊': 5025, '喝': 5026, '前': 5027, '锭': 5028, '彬': 5029, '勺': 5030, '苹': 5031, '托': 5032, '关': 5033, '轶': 5034, '偶': 5035, '者': 5036, '囿': 5037, '炊': 5038, '踉': 5039, '讥': 5040, '谔': 5041, '橛': 5042, '灰': 5043, '鬼': 5044, '格': 5045, '敲': 5046, '砌': 5047, '胚': 5048, '桧': 5049, '脚': 5050, '桃': 5051, '瑾': 5052, '镞': 5053, '负': 5054, '鼙': 5055, '斩': 5056, '偃': 5057, '唇': 5058, '姣': 5059, '跹': 5060, '债': 5061, '艰': 5062, '镫': 5063, '侗': 5064, '娠': 5065, '染': 5066, '怛': 5067, '坳': 5068, '唾': 5069, '粹': 5070, '骖': 5071, '盆': 5072, '族': 5073, '牵': 5074, '雅': 5075, '溅': 5076, '钱': 5077, '庇': 5078, '惕': 5079, '埭': 5080, '里': 5081, '汨': 5082, '酣': 5083, '脉': 5084, '鼹': 5085, '琢': 5086, '艋': 5087, '臣': 5088, '憎': 5089, '聱': 5090, '种': 5091, '驰': 5092, '蠃': 5093, '代': 5094, '叠': 5095, '邛': 5096, '卫': 5097, '绎': 5098, '陉': 5099, '氍': 5100, '拗': 5101, '梦': 5102, '市': 5103, '汪': 5104, 'Ｈ': 5105, '呆': 5106, '纱': 5107, '宵': 5108, '扩': 5109, '孔': 5110, '寤': 5111, '璀': 5112, '咫': 5113, '菱': 5114, '碍': 5115, '淮': 5116, '隆': 5117, '缣': 5118, '蘩': 5119, '倘': 5120, '辕': 5121, '劭': 5122, '垓': 5123, '“': 5124, '邴': 5125, '紧': 5126, '缓': 5127, '度': 5128, '髅': 5129, '翔': 5130, '苇': 5131, '筵': 5132, '憾': 5133, '歉': 5134, '仅': 5135, '榧': 5136, '岖': 5137, '椒': 5138, '咒': 5139, '铫': 5140, '椎': 5141, '炬': 5142, '漏': 5143, '募': 5144, '仞': 5145, '包': 5146, '霜': 5147, '奕': 5148, '叹': 5149, '兄': 5150, '刘': 5151, '替': 5152, '麸': 5153, '危': 5154, '贷': 5155, '悚': 5156, '扬': 5157, '穿': 5158, '画': 5159, '槐': 5160, '擢': 5161, '撮': 5162, '营': 5163, '跌': 5164, '浩': 5165, '裆': 5166, '擒': 5167, '蔬': 5168, '鳌': 5169, '锻': 5170, '庵': 5171, '谦': 5172, '舞': 5173, '芊': 5174, '鸢': 5175, '阀': 5176, '骸': 5177, '稻': 5178, '毒': 5179, '右': 5180, '迹': 5181, '帧': 5182, '□': 5183, '娘': 5184, '澄': 5185, '寺': 5186, '媒': 5187, '景': 5188, '取': 5189, '弩': 5190, '航': 5191, '捷': 5192, '廷': 5193, '貂': 5194, '埽': 5195, '勿': 5196, '署': 5197, '幅': 5198, '俏': 5199, '瑕': 5200, '福': 5201, '秤': 5202, '层': 5203, '蓿': 5204, '佚': 5205, '瞎': 5206, '氲': 5207, '畴': 5208, '痣': 5209, '偏': 5210, '坤': 5211, '渎': 5212, '眚': 5213, '芭': 5214, '柬': 5215, '循': 5216, '瞿': 5217, '旎': 5218, '芹': 5219, '担': 5220, '槊': 5221, '领': 5222, '辈': 5223, '畛': 5224, '岛': 5225, '躯': 5226, '姜': 5227, '变': 5228, '畋': 5229, '禅': 5230, '嫂': 5231, '稣': 5232, '标': 5233, '褚': 5234, '庐': 5235, '弄': 5236, '赞': 5237, '饵': 5238, '瀚': 5239, '上': 5240, '栖': 5241, '象': 5242, '狂': 5243, '勉': 5244, '熬': 5245, '莠': 5246, '质': 5247, '胪': 5248, '添': 5249, '掰': 5250, '忤': 5251, '驳': 5252, '苦': 5253, '蕴': 5254, '赈': 5255, '暇': 5256, '峄': 5257, '搴': 5258, '允': 5259, '股': 5260, '鸬': 5261, '琴': 5262, '讵': 5263, '裒': 5264, '佃': 5265, '霈': 5266, '韩': 5267, '禧': 5268, '畦': 5269, '啭': 5270, '浚': 5271, '坛': 5272, '慰': 5273, '荃': 5274, '闲': 5275, '漱': 5276, '禁': 5277, '耗': 5278, '跳': 5279, '馅': 5280, '澶': 5281, '眇': 5282, '应': 5283, '津': 5284, '朕': 5285, '逵': 5286, '磬': 5287, '概': 5288, '渐': 5289, '商': 5290, '姝': 5291, '啬': 5292, 'E': 5293, 'S': 5294, ' ': 5295} {'0': '坼', '1': '卉', '2': '堵', '3': '尫', '4': '如', '5': 'ō', '6': '郡', '7': '匝', '8': '业', '9': '制', '10': '玲', '11': '厓', '12': '蓖', '13': '藿', '14': '砂', '15': '帘', '16': '旒', '17': '飓', '18': '玺', '19': '众', '20': '盈', '21': '钥', '22': '蛰', '23': '拐', '24': '枨', '25': '为', '26': '撒', '27': '鹊', '28': '鳞', '29': '男', '30': '垆', '31': '怪', '32': '溥', '33': '佗', '34': '叙', '35': '雁', '36': '荐', '37': '豺', '38': '独', '39': '沔', '40': '炮', '41': '彀', '42': '菸', '43': '清', '44': '俊', '45': '柴', '46': '奏', '47': '查', '48': '身', '49': '门', '50': '妫', '51': '围', '52': '仔', '53': '鼓', '54': '枳', '55': '１', '56': '翠', '57': '搂', '58': '美', '59': '菅', '60': '缤', '61': '坝', '62': '苟', '63': '阐', '64': '锝', '65': '灼', '66': '带', '67': '砻', '68': '箜', '69': '赴', '70': '推', '71': '倚', '72': '冶', '73': '伎', '74': '浅', '75': '台', '76': '窥', '77': '酌', '78': '毁', '79': '猫', '80': '缉', '81': '谷', '82': '莽', '83': '舍', '84': '裳', '85': '殆', '86': '怆', '87': '嫩', '88': '辁', '89': '凿', '90': '纭', '91': '竺', '92': '坟', '93': '潺', '94': '记', '95': '淑', '96': '挂', '97': '算', '98': '粤', '99': '蒙', '100': '鄱', '101': '让', '102': '啄', '103': '黟', '104': '闰', '105': '轻', '106': '媾', '107': '集', '108': '泾', '109': '蝤', '110': '蛜', '111': '腐', '112': '镝', '113': '籴', '114': '初', '115': '鹦', '116': '礴', '117': '网', '118': '打', '119': '胃', '120': '渡', '121': '滁', '122': '辆', '123': '利', '124': '柿', '125': '碇', '126': '掖', '127': '菌', '128': '鹗', '129': '树', '130': '璜', '131': '壑', '132': '史', '133': '缭', '134': '徂', '135': '荟', '136': '任', '137': '瘠', '138': '述', '139': '彰', '140': '挑', '141': '虺', '142': '琵', '143': '击', '144': '修', '145': '娟', '146': '汊', '147': '犊', '148': '京', '149': '骓', '150': '砖', '151': '宜', '152': '嵯', '153': '螗', '154': '昭', '155': '骞', '156': '溢', '157': '咏', '158': '潆', '159': '鸾', '160': '厢', '161': '赎', '162': '簌', '163': '订', '164': '贩', '165': '脸', '166': '蜉', '167': '綦', '168': '窠', '169': '辖', '170': '瘗', '171': '臆', '172': '覆', '173': '驿', '174': '诺', '175': '原', '176': '慢', '177': '快', '178': '眸', '179': '列', '180': '奚', '181': '窅', '182': '闳', '183': '岗', '184': '就', '185': '适', '186': '蜓', '187': '晕', '188': '隼', '189': '榔', '190': '耶', '191': '褊', '192': '华', '193': '蔌', '194': '嗳', '195': '馐', '196': '髀', '197': '凤', '198': '爨', '199': '舒', '200': '禹', '201': '池', '202': '怡', '203': '蒇', '204': '撷', '205': '荻', '206': '聪', '207': 'ン', '208': '鞿', '209': '珉', '210': '黉', '211': '轭', '212': '乎', '213': '俚', '214': '泳', '215': '尊', '216': '仍', '217': '黔', '218': '猴', '219': '谪', '220': '户', '221': '农', '222': '恢', '223': '馡', '224': '骝', '225': '醐', '226': '钞', '227': 'Α', '228': '镰', '229': '椰', '230': '咱', '231': '虎', '232': '檎', '233': '淙', '234': '镪', '235': '晗', '236': '沣', '237': '幂', '238': '蛾', '239': '恤', '240': '霾', '241': '恝', '242': '膻', '243': '钉', '244': '斑', '245': '羁', '246': '戮', '247': '颇', '248': '钧', '249': '汗', '250': '觑', '251': '菊', '252': '圻', '253': '递', '254': '睽', '255': '弃', '256': '堠', '257': '虬', '258': '苌', '259': '瑚', '260': '极', '261': '闪', '262': '腾', '263': '郁', '264': '缪', '265': '扳', '266': '目', '267': '璃', '268': '挚', '269': '荚', '270': '颐', '271': '缀', '272': '鞍', '273': '敖', '274': '谋', '275': '剩', '276': '阊', '277': '儿', '278': '店', '279': '骀', '280': '罡', '281': '勘', '282': '侔', '283': '愁', '284': '仕', '285': '伦', '286': '黯', '287': '牧', '288': '坪', '289': '跎', '290': '惬', '291': '狐', '292': '魄', '293': '澡', '294': '蜘', '295': '浯', '296': '缔', '297': '粮', '298': '句', '299': '瞥', '300': '栀', '301': '虚', '302': '噤', '303': '滞', '304': '拚', '305': '癯', '306': '魁', '307': '是', '308': '鲐', '309': '涕', '310': '胖', '311': '枪', '312': '铗', '313': '隈', '314': '官', '315': '渺', '316': '稷', '317': '沲', '318': '胯', '319': '谊', '320': '迎', '321': '人', '322': '琮', '323': '渌', '324': '祀', '325': '尽', '326': '抱', '327': '囊', '328': '甬', '329': '咭', '330': '缦', '331': '翳', '332': '榄', '333': '茄', '334': '铺', '335': '睢', '336': '暗', '337': '争', '338': '嗷', '339': '尧', '340': '泄', '341': '宸', '342': '储', '343': '敏', '344': '钓', '345': '锥', '346': '镟', '347': '辫', '348': '埃', '349': '垤', '350': '眺', '351': '歇', '352': '遂', '353': '捣', '354': '麒', '355': '彪', '356': '巳', '357': '孰', '358': '杨', '359': '誉', '360': '动', '361': '庠', '362': '孩', '363': '敢', '364': '牲', '365': '鏖', '366': '芳', '367': '综', '368': '殚', '369': '苔', '370': '菏', '371': '阗', '372': '祸', '373': '绉', '374': '戆', '375': '楮', '376': '杖', '377': '绨', '378': '授', '379': '晓', '380': '暮', '381': '屈', '382': '拓', '383': '哦', '384': '觐', '385': '兼', '386': '棒', '387': '懂', '388': '十', '389': '怀', '390': '茧', '391': '艮', '392': '镛', '393': '簿', '394': '毕', '395': '徽', '396': '湛', '397': '汩', '398': '涛', '399': '朽', '400': '衷', '401': '免', '402': '枸', '403': '幽', '404': '蒋', '405': '裨', '406': '抨', '407': '刃', '408': '辉', '409': '蒸', '410': '颤', '411': '量', '412': '吃', '413': '顷', '414': 'ㄓ', '415': '蘖', '416': '轨', '417': '攻', '418': '庚', '419': '墓', '420': '趄', '421': '容', '422': '其', '423': '匕', '424': '盲', '425': '赀', '426': '娈', '427': '灶', '428': '绔', '429': '麽', '430': '蚍', '431': '哲', '432': '窗', '433': '甥', '434': '庄', '435': '加', '436': '。', '437': '噬', '438': '嘹', '439': '沐', '440': '株', '441': '羽', '442': '霰', '443': '榘', '444': '樯', '445': '瞪', '446': '埠', '447': '唤', '448': '擤', '449': '解', '450': '颓', '451': '淹', '452': '俦', '453': '芟', '454': '<', '455': '萎', '456': '畔', '457': '瓶', '458': '乌', '459': '脏', '460': '孛', '461': '蓄', '462': '髓', '463': '罪', '464': '党', '465': '昆', '466': '夜', '467': '涴', '468': '笑', '469': '疴', '470': '咨', '471': '黜', '472': '濯', '473': '酾', '474': '皖', '475': '笋', '476': '臊', '477': '诬', '478': '肺', '479': '耸', '480': '仗', '481': '压', '482': '蠡', '483': '芡', '484': '旋', '485': '掾', '486': '诵', '487': '蓓', '488': '褶', '489': '溪', '490': '煊', '491': '孽', '492': '课', '493': '侈', '494': '构', '495': '虾', '496': '抽', '497': '必', '498': '磷', '499': '帜', '500': '箪', '501': '罂', '502': '塾', '503': '辇', '504': '摇', '505': '涧', '506': '承', '507': '襞', '508': '欠', '509': '圆', '510': '敝', '511': '靖', '512': '污', '513': '湖', '514': '舡', '515': '楣', '516': '蝉', '517': '穹', '518': '菔', '519': '醍', '520': '煮', '521': '黎', '522': '追', '523': '藩', '524': '墀', '525': '蘅', '526': '穷', '527': '强', '528': '的', '529': '绰', '530': '涓', '531': '叶', '532': '饥', '533': '汴', '534': '媂', '535': '监', '536': '莸', '537': '埙', '538': '潸', '539': '桑', '540': '纽', '541': '觌', '542': '噎', '543': '绒', '544': '艨', '545': '梯', '546': '舫', '547': '闸', '548': '悦', '549': '块', '550': '剧', '551': '咳', '552': '炫', '553': '赠', '554': '虢', '555': '净', '556': '绾', '557': '钌', '558': '仲', '559': '绷', '560': '口', '561': '潦', '562': '小', '563': '青', '564': '散', '565': '拄', '566': '窝', '567': '螺', '568': '获', '569': '蓼', '570': '窨', '571': '逑', '572': '迟', '573': '媪', '574': '眉', '575': '颍', '576': '遐', '577': '倮', '578': '怃', '579': '斡', '580': '湍', '581': '峥', '582': '笄', '583': '忝', '584': '笃', '585': '樱', '586': '匀', '587': '侄', '588': '帛', '589': '彦', '590': '饿', '591': '八', '592': '嘶', '593': '成', '594': '入', '595': '遗', '596': '蚊', '597': '碱', '598': '即', '599': '括', '600': '谶', '601': '醑', '602': '济', '603': '溺', '604': '竿', '605': '科', '606': '遭', '607': '希', '608': '觅', '609': '套', '610': '颧', '611': '狙', '612': '诅', '613': '迭', '614': '臻', '615': '骋', '616': '享', '617': '掷', '618': '镇', '619': '赤', '620': '後', '621': '壳', '622': '才', '623': '旰', '624': '覃', '625': '藏', '626': '癸', '627': '郫', '628': '绂', '629': '莅', '630': '蜩', '631': '胧', '632': '每', '633': '撤', '634': '筌', '635': '缰', '636': '础', '637': '姆', '638': 'ぢ', '639': '西', '640': '睦', '641': '儡', '642': '巍', '643': '登', '644': '浪', '645': '渊', '646': '糯', '647': '踮', '648': '俘', '649': '著', '650': '隧', '651': '委', '652': '币', '653': '闯', '654': '蜡', '655': '铩', '656': '龊', '657': '昨', '658': '硎', '659': '绸', '660': '赝', '661': '峻', '662': '绁', '663': '凸', '664': 'и', '665': '扇', '666': '祥', '667': '颢', '668': '帮', '669': '隅', '670': '努', '671': '曙', '672': '都', '673': '蔫', '674': '凫', '675': '豳', '676': '栉', '677': '碗', '678': '氵', '679': '叛', '680': '哙', '681': '絮', '682': '禽', '683': '屋', '684': '揠', '685': '缗', '686': '坯', '687': '女', '688': '膺', '689': '雄', '690': '辣', '691': '崧', '692': '幕', '693': '舔', '694': '恓', '695': '惨', '696': '谤', '697': '叮', '698': '薛', '699': '纂', '700': '稠', '701': '椟', '702': '笞', '703': '筑', '704': '绘', '705': '阵', '706': '鹜', '707': '服', '708': '訇', '709': '回', '710': '姗', '711': '蛹', '712': '金', '713': '茫', '714': '姚', '715': '敷', '716': '斫', '717': '忠', '718': '宗', '719': '瞑', '720': '恺', '721': '悴', '722': '褓', '723': '郇', '724': '媲', '725': '释', '726': '兢', '727': '翰', '728': '洼', '729': '鄣', '730': '曛', '731': '骼', '732': '迷', '733': '淋', '734': '呼', '735': '枰', '736': '淀', '737': '滨', '738': '封', '739': '嶂', '740': '水', '741': '匏', '742': '屣', '743': '喘', '744': '慷', '745': '流', '746': '璁', '747': '轺', '748': '鲒', '749': '磐', '750': '笺', '751': '骥', '752': '引', '753': '溟', '754': '光', '755': '芯', '756': '哨', '757': '耜', '758': '帱', '759': '夙', '760': '融', '761': '曝', '762': '诲', '763': '葺', '764': '奈', '765': '挫', '766': '摸', '767': '枻', '768': '桥', '769': '畅', '770': '娣', '771': '沟', '772': '鹘', '773': '餐', '774': '鳜', '775': '衽', '776': '恐', '777': '诞', '778': '摩', '779': '缱', '780': '邸', '781': '卧', '782': '悃', '783': '识', '784': '攸', '785': '欢', '786': '淘', '787': '僵', '788': '颖', '789': '烨', '790': '便', '791': '供', '792': '横', '793': '脐', '794': '吠', '795': '妲', '796': '牙', '797': '愠', '798': '邪', '799': '躔', '800': '栏', '801': '柑', '802': '粕', '803': '排', '804': '啮', '805': '畿', '806': '期', '807': '窟', '808': '怼', '809': '酡', '810': '舴', '811': '烂', '812': '谬', '813': '挺', '814': '跋', '815': '觋', '816': '盏', '817': '宽', '818': '褪', '819': '煤', '820': '阼', '821': '揭', '822': '钩', '823': '扶', '824': '祯', '825': '枝', '826': '央', '827': '笥', '828': '刺', '829': '垒', '830': 'Н', '831': '梅', '832': '多', '833': '墨', '834': '嫌', '835': '楚', '836': '准', '837': '呷', '838': '晦', '839': '笕', '840': '歙', '841': '绩', '842': '仓', '843': '游', '844': '糖', '845': '呀', '846': '藁', '847': '菡', '848': '跄', '849': '维', '850': '狻', '851': '头', '852': '燕', '853': '谗', '854': '怵', '855': '閟', '856': '隽', '857': '祈', '858': '援', '859': '文', '860': '逗', '861': '寒', '862': '芸', '863': '淆', '864': '盼', '865': '赉', '866': '堰', '867': '’', '868': '缈', '869': '贶', '870': '蚋', '871': '骷', '872': '啸', '873': '祟', '874': '罗', '875': '瓦', '876': '敬', '877': '籁', '878': '面', '879': '剖', '880': '峋', '881': '翦', '882': '刊', '883': '鹆', '884': '混', '885': '鞑', '886': '矗', '887': '董', '888': '玑', '889': '诸', '890': '丹', '891': '钟', '892': '刻', '893': '则', '894': '幻', '895': '闼', '896': '毋', '897': '摆', '898': '救', '899': '圭', '900': '囷', '901': '瞩', '902': '霉', '903': '曰', '904': '炎', '905': '纩', '906': '艹', '907': '瓞', '908': '捍', '909': '寮', '910': '涪', '911': '哳', '912': '改', '913': '浊', '914': '柰', '915': '跫', '916': '肤', '917': '缢', '918': '纤', '919': '睚', '920': '_', '921': '衙', '922': '至', '923': '躇', '924': '酴', '925': '殉', '926': '嫣', '927': '觖', '928': '琨', '929': '滟', '930': '瘳', '931': '岂', '932': '泗', '933': '觥', '934': '败', '935': '孝', '936': '豕', '937': '捱', '938': '韦', '939': '犍', '940': '河', '941': '突', '942': '豆', '943': '绫', '944': '秘', '945': '旷', '946': '⒛', '947': '喏', '948': '寿', '949': '训', '950': '珥', '951': '膳', '952': '滴', '953': '魍', '954': '猱', '955': '猜', '956': '睐', '957': 'б', '958': '璞', '959': '绞', '960': '汐', '961': '问', '962': '醮', '963': '乳', '964': '柳', '965': '时', '966': '隘', '967': '霅', '968': '卓', '969': '更', '970': '洗', '971': '丫', '972': '甜', '973': '操', '974': '发', '975': '协', '976': '丁', '977': '私', '978': '易', '979': '袁', '980': '攘', '981': '檄', '982': '国', '983': '愕', '984': '凡', '985': '螭', '986': '殇', '987': '法', '988': '迢', '989': '宇', '990': '桨', '991': '亵', '992': '赂', '993': '柱', '994': '陋', '995': '巷', '996': '自', '997': '毯', '998': 'ｓ', '999': '抒', '1000': '礼', '1001': '娥', '1002': '岐', '1003': '鹕', '1004': '案', '1005': '祚', '1006': '菩', '1007': '丽', '1008': '邦', '1009': '拢', '1010': '同', '1011': '谥', '1012': '榭', '1013': '畲', '1014': '臂', '1015': '纾', '1016': '兵', '1017': '转', '1018': '鹏', '1019': '腌', '1020': '鸯', '1021': '秕', '1022': '圯', '1023': '痼', '1024': '俨', '1025': '鲸', '1026': '绚', '1027': '产', '1028': '什', '1029': '杪', '1030': '指', '1031': '珀', '1032': '撰', '1033': '零', '1034': '悬', '1035': '卣', '1036': '蕙', '1037': '滇', '1038': '盖', '1039': '考', '1040': '尻', '1041': '锤', '1042': '床', '1043': '盐', '1044': '髯', '1045': '却', '1046': '宛', '1047': '攒', '1048': '凑', '1049': '橼', '1050': '贺', '1051': '愉', '1052': '税', '1053': '寸', '1054': '重', '1055': '梁', '1056': '蛩', '1057': '霆', '1058': '材', '1059': '责', '1060': '梳', '1061': '莆', '1062': '坠', '1063': '妓', '1064': '阅', '1065': '运', '1066': '港', '1067': '壬', '1068': '软', '1069': '逍', '1070': '軿', '1071': '绵', '1072': '磕', '1073': '饼', '1074': '郧', '1075': '杭', '1076': '撩', '1077': '茗', '1078': '嵇', '1079': '仃', '1080': '麹', '1081': '生', '1082': '劳', '1083': '筲', '1084': '榼', '1085': '樟', '1086': '又', '1087': '溯', '1088': '肌', '1089': '阜', '1090': '谭', '1091': '棹', '1092': '逝', '1093': '辔', '1094': '隔', '1095': '恂', '1096': '皱', '1097': '罾', '1098': '榷', '1099': '挨', '1100': '疑', '1101': '灭', '1102': '着', '1103': '狮', '1104': '秫', '1105': '夹', '1106': '迸', '1107': '赆', '1108': '定', '1109': '獭', '1110': '拉', '1111': '张', '1112': '冱', '1113': '纸', '1114': '忘', '1115': '会', '1116': '芜', '1117': '忡', '1118': '赊', '1119': '甍', '1120': '照', '1121': '窭', '1122': '晃', '1123': '垅', '1124': '侬', '1125': '苒', '1126': '第', '1127': '莪', '1128': '贳', '1129': '拆', '1130': '魔', '1131': '高', '1132': '阔', '1133': '稍', '1134': '麟', '1135': '谄', '1136': '捧', '1137': '选', '1138': '膜', '1139': '演', '1140': '艾', '1141': '冼', '1142': '柞', '1143': '踬', '1144': '君', '1145': '预', '1146': '辜', '1147': '琤', '1148': '簖', '1149': '唆', '1150': '娱', '1151': '劾', '1152': '劈', '1153': '鬲', '1154': '燧', '1155': '界', '1156': '烧', '1157': '曼', '1158': '红', '1159': 'は', '1160': 'づ', '1161': '饷', '1162': '冗', '1163': '绊', '1164': '速', '1165': '蟀', '1166': '草', '1167': '沪', '1168': '尺', '1169': '嫔', '1170': '【', '1171': '谆', '1172': '鳖', '1173': '茵', '1174': '咎', '1175': '札', '1176': '黛', '1177': '哭', '1178': '吕', '1179': '萏', '1180': '坐', '1181': '匈', '1182': '饶', '1183': '甄', '1184': '屑', '1185': '塞', '1186': '簸', '1187': '蕃', '1188': '睾', '1189': '哇', '1190': '冢', '1191': '谨', '1192': '山', '1193': '兆', '1194': '分', '1195': '奖', '1196': 'ㄇ', '1197': '说', '1198': '遄', '1199': '鹩', '1200': '罅', '1201': '逊', '1202': '呢', '1203': '汲', '1204': '蜻', '1205': '讨', '1206': '妤', '1207': '纯', '1208': '食', '1209': '扃', '1210': '绝', '1211': '具', '1212': '非', '1213': '斧', '1214': '毅', '1215': '豚', '1216': '恨', '1217': '钤', '1218': '螓', '1219': '觜', '1220': '移', '1221': '驻', '1222': '练', '1223': '粥', '1224': '耄', '1225': '吝', '1226': '奸', '1227': '遛', '1228': '廛', '1229': '鍧', '1230': '遇', '1231': '仪', '1232': '垂', '1233': '旱', '1234': '爽', '1235': '稼', '1236': '佛', '1237': '萦', '1238': '槔', '1239': '证', '1240': '行', '1241': '契', '1242': '袭', '1243': '婺', '1244': '蜊', '1245': '鸦', '1246': '之', '1247': '沥', '1248': '辘', '1249': '烬', '1250': '庑', '1251': '倒', '1252': '罕', '1253': '放', '1254': '区', '1255': '暾', '1256': '摺', '1257': '眨', '1258': '枕', '1259': '植', '1260': '苞', '1261': '镖', '1262': '世', '1263': '望', '1264': '窖', '1265': '逼', '1266': '弦', '1267': '堑', '1268': '赡', '1269': '哑', '1270': '侪', '1271': '还', '1272': '频', '1273': '销', '1274': '粜', '1275': '蔼', '1276': '撑', '1277': '蠢', '1278': '赵', '1279': '骈', '1280': '炽', '1281': '物', '1282': '落', '1283': '签', '1284': '郗', '1285': '忪', '1286': '唳', '1287': '吻', '1288': '廉', '1289': '猥', '1290': '脑', '1291': '活', '1292': '麴', '1293': '影', '1294': '蟆', '1295': '梗', '1296': '舻', '1297': '寥', '1298': '忙', '1299': '鍪', '1300': '娼', '1301': '梢', '1302': '珮', '1303': '抡', '1304': '荦', '1305': '搬', '1306': '箫', '1307': '姐', '1308': '湘', '1309': '新', '1310': '拿', '1311': '僻', '1312': '圉', '1313': '孟', '1314': '嵬', '1315': '驾', '1316': '拊', '1317': '采', '1318': '藕', '1319': '恳', '1320': '气', '1321': '晁', '1322': '槟', '1323': '熟', '1324': '逆', '1325': '矢', '1326': '嗟', '1327': '驱', '1328': '跷', '1329': '翥', '1330': '帚', '1331': '肯', '1332': '牍', '1333': '属', '1334': '昙', '1335': '黑', '1336': '蜣', '1337': '枇', '1338': '焕', '1339': '翻', '1340': '龙', '1341': '纷', '1342': '浼', '1343': '峡', '1344': '偬', '1345': '嘘', '1346': '坎', '1347': '娓', '1348': '颦', '1349': '杂', '1350': '枣', '1351': '飒', '1352': '楸', '1353': '按', '1354': '揣', '1355': '拥', '1356': '缑', '1357': '醿', '1358': '许', '1359': '瓢', '1360': '！', '1361': '啤', '1362': '漂', '1363': '荫', '1364': '矜', '1365': '窦', '1366': '映', '1367': '怏', '1368': '缶', '1369': '铿', '1370': '樾', '1371': '拶', '1372': '将', '1373': '禾', '1374': '颔', '1375': '挛', '1376': '邈', '1377': '峒', '1378': '崛', '1379': '那', '1380': '髭', '1381': '蒺', '1382': '郎', '1383': '祉', '1384': '怨', '1385': '莎', '1386': '蓠', '1387': '砑', '1388': '忏', '1389': '翊', '1390': '雾', '1391': '汝', '1392': '填', '1393': '焰', '1394': '冥', '1395': '蒂', '1396': '棚', '1397': '涅', '1398': '名', '1399': '催', '1400': '逅', '1401': '意', '1402': '宓', '1403': '件', '1404': '司', '1405': '腰', '1406': '襦', '1407': '彭', '1408': '惧', '1409': '悰', '1410': '珈', '1411': '实', '1412': '玳', '1413': '滑', '1414': '嘱', '1415': '射', '1416': '杏', '1417': '菘', '1418': '谀', '1419': '廓', '1420': '粟', '1421': '瑟', '1422': '警', '1423': '扫', '1424': '鹳', '1425': '揆', '1426': '岷', '1427': '得', '1428': '栾', '1429': '缯', '1430': '曲', '1431': '办', '1432': '韫', '1433': '秧', '1434': '配', '1435': '透', '1436': '吭', '1437': '妙', '1438': '蓂', '1439': '颅', '1440': '苕', '1441': '奄', '1442': '拍', '1443': '悒', '1444': '崆', '1445': '塘', '1446': '泖', '1447': '锺', '1448': '颊', '1449': '欸', '1450': '彻', '1451': '咄', '1452': '风', '1453': '宙', '1454': '闒', '1455': '整', '1456': '抗', '1457': '他', '1458': '券', '1459': '贽', '1460': '诰', '1461': '玩', '1462': '哀', '1463': '富', '1464': '愆', '1465': '罘', '1466': '涨', '1467': '沼', '1468': '猪', '1469': '珩', '1470': '暴', '1471': '瞰', '1472': '德', '1473': '蹄', '1474': '墙', '1475': '颗', '1476': '嵌', '1477': '淤', '1478': '耀', '1479': '矩', '1480': '猿', '1481': '哝', '1482': '闺', '1483': '璈', '1484': '值', '1485': '大', '1486': '燥', '1487': '扰', '1488': '虱', '1489': '蚌', '1490': '恁', '1491': '芗', '1492': '酬', '1493': '激', '1494': '玷', '1495': '押', '1496': '琊', '1497': '圜', '1498': '铜', '1499': '翮', '1500': '沅', '1501': '碟', '1502': '岁', '1503': '鸠', '1504': '肝', '1505': '浆', '1506': '巡', '1507': '蔽', '1508': '荏', '1509': '逾', '1510': '驹', '1511': '贫', '1512': '嵩', '1513': '斐', '1514': '鸡', '1515': '荒', '1516': '昔', '1517': '萌', '1518': '筇', '1519': '鹞', '1520': '卺', '1521': '际', '1522': '机', '1523': '戎', '1524': '亩', '1525': '翘', '1526': '它', '1527': '罔', '1528': '泱', '1529': '陷', '1530': '蛑', '1531': '蟪', '1532': '腻', '1533': '袷', '1534': '锁', '1535': '咽', '1536': '儒', '1537': '芦', '1538': '钵', '1539': '音', '1540': '瘦', '1541': '灵', '1542': '殷', '1543': '幔', '1544': '滔', '1545': '爰', '1546': '守', '1547': '祓', '1548': '樻', '1549': '柚', '1550': '杜', '1551': '单', '1552': '碛', '1553': '巩', '1554': '芬', '1555': '俜', '1556': '鬖', '1557': '忻', '1558': '肉', '1559': '减', '1560': '柝', '1561': '喋', '1562': '蔺', '1563': '喻', '1564': '学', '1565': '裘', '1566': '靳', '1567': '衿', '1568': 'ぇ', '1569': '假', '1570': '沙', '1571': '炉', '1572': '娄', '1573': '隰', '1574': '皆', '1575': '祆', '1576': '糈', '1577': '蚕', '1578': '谳', '1579': '何', '1580': '瓣', '1581': '觇', '1582': '骨', '1583': '栅', '1584': '织', '1585': '栋', '1586': '肴', '1587': '槽', '1588': '挤', '1589': '诧', '1590': '钜', '1591': '掺', '1592': '埏', '1593': '挝', '1594': '衡', '1595': '髫', '1596': '膈', '1597': '薇', '1598': '跖', '1599': '牡', '1600': '婷', '1601': '馆', '1602': '淼', '1603': '僽', '1604': '桡', '1605': '街', '1606': '拦', '1607': '奁', '1608': '坊', '1609': '项', '1610': '谡', '1611': '抄', '1612': '芎', '1613': '队', '1614': '凭', '1615': '继', '1616': '甚', '1617': '袈', '1618': '留', '1619': '掉', '1620': '唼', '1621': '鸪', '1622': '绋', '1623': '战', '1624': '庙', '1625': '滤', '1626': '臭', '1627': '匙', '1628': '辨', '1629': '戡', '1630': '桄', '1631': '锼', '1632': '掐', '1633': '驴', '1634': '篘', '1635': '嘉', '1636': '冬', '1637': '佑', '1638': '观', '1639': '昼', '1640': '聆', '1641': '蛟', '1642': '倦', '1643': '虻', '1644': '疲', '1645': '煅', '1646': '籍', '1647': 'め', '1648': '绕', '1649': '涯', '1650': '崃', '1651': '脱', '1652': '鳏', '1653': '窃', '1654': '觞', '1655': '洄', '1656': '洒', '1657': '悫', '1658': '琐', '1659': '啜', '1660': '懦', '1661': '江', '1662': '姨', '1663': '薮', '1664': '脓', '1665': '布', '1666': '爇', '1667': '斯', '1668': '儋', '1669': '荥', '1670': '席', '1671': '凶', '1672': '择', '1673': '堤', '1674': '屠', '1675': '抢', '1676': '凋', '1677': '帕', '1678': '颟', '1679': '婿', '1680': '步', '1681': '俭', '1682': '厄', '1683': '蓟', '1684': '例', '1685': '魑', '1686': '晖', '1687': '丙', '1688': '靡', '1689': '命', '1690': '衍', '1691': '虿', '1692': '傅', '1693': '远', '1694': '庭', '1695': '颃', '1696': '财', '1697': '琅', '1698': '尝', '1699': '广', '1700': '佣', '1701': '冲', '1702': '醭', '1703': 'ㄛ', '1704': '撕', '1705': '事', '1706': '襄', '1707': '垄', '1708': '瞌', '1709': '踵', '1710': '澈', '1711': '翼', '1712': '辎', '1713': '增', '1714': '径', '1715': '裁', '1716': '烁', '1717': '叱', '1718': '帖', '1719': '螟', '1720': '奢', '1721': '笏', '1722': '橐', '1723': '靠', '1724': '徊', '1725': '畹', '1726': '╆', '1727': '憧', '1728': '亲', '1729': '穴', '1730': '耘', '1731': '偕', '1732': '囝', '1733': '讳', '1734': '沉', '1735': '镐', '1736': '本', '1737': '肄', '1738': '搓', '1739': '充', '1740': '苴', '1741': '瞳', '1742': '额', '1743': '沾', '1744': '肪', '1745': '蓍', '1746': '葬', '1747': '汉', '1748': '盟', '1749': '赍', '1750': '茂', '1751': '刀', '1752': '勾', '1753': '逃', '1754': '反', '1755': '熏', '1756': '趱', '1757': '蒯', '1758': '茸', '1759': '惮', '1760': '驮', '1761': '钺', '1762': '忌', '1763': '澳', '1764': '竦', '1765': '囚', '1766': '伞', '1767': '几', '1768': '淅', '1769': '皓', '1770': '七', '1771': '屏', '1772': '牢', '1773': '觫', '1774': '噪', '1775': '侑', '1776': '赘', '1777': '智', '1778': '飨', '1779': '露', '1780': 'β', '1781': '术', '1782': '豁', '1783': '岭', '1784': '靴', '1785': '佥', '1786': '蛉', '1787': '斟', '1788': '憩', '1789': '符', '1790': '洎', '1791': '麓', '1792': '砚', '1793': '嗣', '1794': '崔', '1795': '捉', '1796': '栊', '1797': '蹁', '1798': '粘', '1799': '瞬', '1800': '腑', '1801': '感', '1802': '逡', '1803': '菜', '1804': '屯', '1805': '唯', '1806': '嵘', '1807': '舁', '1808': '羞', '1809': '乙', '1810': '昱', '1811': '斝', '1812': '驼', '1813': '拒', '1814': '祛', '1815': '沸', '1816': '篁', '1817': '皴', '1818': '涔', '1819': '皂', '1820': '袍', '1821': '淖', '1822': '补', '1823': '尸', '1824': '嗓', '1825': '鸷', '1826': '索', '1827': '拱', '1828': '涡', '1829': '幺', '1830': '殢', '1831': '色', '1832': '玻', '1833': '碾', '1834': '饮', '1835': '鳅', '1836': '迪', '1837': '惑', '1838': '毖', '1839': '蕞', '1840': '莹', '1841': '刚', '1842': '涿', '1843': '收', '1844': '匆', '1845': '炝', '1846': '节', '1847': '於', '1848': '赭', '1849': '乾', '1850': '锋', '1851': '睿', '1852': '讽', '1853': '汤', '1854': '们', '1855': '慊', '1856': '粳', '1857': '投', '1858': '硕', '1859': '陬', '1860': '{', '1861': '缟', '1862': '亿', '1863': '绢', '1864': '缇', '1865': '蝛', '1866': '劫', '1867': '杼', '1868': '泛', '1869': '庾', '1870': '玎', '1871': '叉', '1872': '确', '1873': '旺', '1874': '鲠', '1875': '磁', '1876': '阒', '1877': '程', '1878': '冠', '1879': '邕', '1880': '鵊', '1881': '吊', '1882': '脊', '1883': '嗾', '1884': '烛', '1885': '式', '1886': '版', '1887': '慵', '1888': '千', '1889': '婴', '1890': '予', '1891': '龌', '1892': '驭', '1893': '电', '1894': '冻', '1895': '龟', '1896': '艺', '1897': '搦', '1898': '淳', '1899': '暖', '1900': '玖', '1901': '舄', '1902': '锚', '1903': '吒', '1904': '铃', '1905': '薜', '1906': '仰', '1907': '嚼', '1908': '血', '1909': '圮', '1910': '线', '1911': '角', '1912': '粉', '1913': '斜', '1914': '举', '1915': '峤', '1916': '素', '1917': '读', '1918': '皋', '1919': '戢', '1920': '滹', '1921': '熄', '1922': '有', '1923': '北', '1924': '陂', '1925': '田', '1926': '笳', '1927': '沫', '1928': '绻', '1929': '趁', '1930': '苜', '1931': '浴', '1932': '圈', '1933': '堕', '1934': '啻', '1935': '妩', '1936': '曹', '1937': '力', '1938': '擞', '1939': '现', '1940': '味', '1941': '割', '1942': '虔', '1943': '想', '1944': '狸', '1945': '酸', '1946': '徙', '1947': '随', '1948': '纫', '1949': '诛', '1950': '昴', '1951': '欹', '1952': '培', '1953': '牌', '1954': '芄', '1955': '檬', '1956': '叵', '1957': '纶', '1958': '卵', '1959': '乱', '1960': '刍', '1961': '狡', '1962': '渝', '1963': '逸', '1964': '糕', '1965': '峙', '1966': '型', '1967': '汞', '1968': '传', '1969': '保', '1970': '芾', '1971': '淡', '1972': '踟', '1973': '纬', '1974': '疟', '1975': '鳝', '1976': '般', '1977': '宅', '1978': '敦', '1979': '胆', '1980': '眼', '1981': '亨', '1982': '殖', '1983': '宿', '1984': '耨', '1985': '杞', '1986': '镬', '1987': '束', '1988': '飘', '1989': '秋', '1990': '雕', '1991': '摊', '1992': '鲭', '1993': '贾', '1994': '谯', '1995': '励', '1996': '鲛', '1997': '窈', '1998': '阖', '1999': '姿', '2000': '罢', '2001': '亡', '2002': '据', '2003': '砢', '2004': '戍', '2005': '扈', '2006': '愍', '2007': '叩', '2008': '谅', '2009': '肇', '2010': '漾', '2011': '壹', '2012': '脍', '2013': '较', '2014': '遵', '2015': '慑', '2016': '坻', '2017': '阑', '2018': '喁', '2019': '荼', '2020': '途', '2021': '弓', '2022': '州', '2023': '匠', '2024': '呻', '2025': '韭', '2026': '堞', '2027': '仿', '2028': '贝', '2029': '喂', '2030': '妪', '2031': '诘', '2032': '渠', '2033': '图', '2034': '晔', '2035': '崭', '2036': '育', '2037': '濑', '2038': '嘲', '2039': '请', '2040': '娲', '2041': '牺', '2042': '雷', '2043': '瓷', '2044': '贱', '2045': '帐', '2046': '潼', '2047': '眠', '2048': '荣', '2049': '榛', '2050': '盾', '2051': 'ホ', '2052': '走', '2053': '尔', '2054': '穗', '2055': '酿', '2056': '麋', '2057': '堪', '2058': '处', '2059': '息', '2060': '显', '2061': '荇', '2062': '涉', '2063': '蜇', '2064': '琼', '2065': '慕', '2066': '蕲', '2067': '洋', '2068': '鄙', '2069': '蔗', '2070': '：', '2071': '刈', '2072': '嚲', '2073': '粗', '2074': '鼾', '2075': '嚣', '2076': '桂', '2077': '嵫', '2078': '躅', '2079': '冕', '2080': '诉', '2081': '衲', '2082': '珠', '2083': '笼', '2084': '…', '2085': '赏', '2086': '晌', '2087': '梭', '2088': '捏', '2089': '方', '2090': '泵', '2091': '你', '2092': '砍', '2093': '吟', '2094': '泷', '2095': '虑', '2096': '惘', '2097': '仑', '2098': '藤', '2099': '锯', '2100': '律', '2101': '赫', '2102': '租', '2103': '鸱', '2104': '类', '2105': '濂', '2106': '泼', '2107': '蝙', '2108': '谏', '2109': '迈', '2110': '婢', '2111': '伴', '2112': '器', '2113': '职', '2114': '眦', '2115': '娉', '2116': '俾', '2117': '防', '2118': '嫫', '2119': '盘', '2120': '廿', '2121': '酩', '2122': '伊', '2123': 'ㄏ', '2124': '雳', '2125': '溘', '2126': '役', '2127': '谱', '2128': '椽', '2129': '讶', '2130': '申', '2131': '苗', '2132': '瑙', '2133': '征', '2134': '亸', '2135': '妻', '2136': '妒', '2137': '寨', '2138': '赦', '2139': '隐', '2140': '楞', '2141': '再', '2142': '潢', '2143': '势', '2144': '珊', '2145': '弥', '2146': '塑', '2147': '潘', '2148': '迨', '2149': '攫', '2150': '咚', '2151': '裂', '2152': '些', '2153': '姻', '2154': '妾', '2155': '描', '2156': '枫', '2157': '蓉', '2158': '缩', '2159': '一', '2160': '形', '2161': '手', '2162': '砺', '2163': '蚓', '2164': '诗', '2165': '呶', '2166': '林', '2167': '欲', '2168': '鬟', '2169': '沮', '2170': '阍', '2171': '榕', '2172': '暌', '2173': '耔', '2174': '巑', '2175': '铤', '2176': '陇', '2177': '贬', '2178': '副', '2179': '研', '2180': '溉', '2181': '云', '2182': '苓', '2183': '蒜', '2184': '逶', '2185': '缆', '2186': '暂', '2187': '轼', '2188': '提', '2189': '垣', '2190': '彝', '2191': '挟', '2192': '派', '2193': '骚', '2194': '鬣', '2195': '篇', '2196': '舅', '2197': '栽', '2198': '甘', '2199': '獗', '2200': '洪', '2201': '价', '2202': '斓', '2203': '猷', '2204': '窕', '2205': '甲', '2206': '浇', '2207': '该', '2208': '磋', '2209': '孚', '2210': '悲', '2211': '槲', '2212': '桐', '2213': '使', '2214': '蔻', '2215': '茎', '2216': '夔', '2217': '鹧', '2218': '亢', '2219': '吹', '2220': '穆', '2221': '瑞', '2222': '橱', '2223': '犀', '2224': '岑', '2225': '蝗', '2226': '纛', '2227': '娇', '2228': '葆', '2229': '缵', '2230': '雒', '2231': '庖', '2232': '执', '2233': '舶', '2234': '院', '2235': '绐', '2236': '浙', '2237': '宝', '2238': '欧', '2239': '剜', '2240': '且', '2241': '雏', '2242': '共', '2243': '拟', '2244': '真', '2245': '窍', '2246': '姑', '2247': '良', '2248': '蒿', '2249': '祷', '2250': '病', '2251': '痎', '2252': '缝', '2253': '螂', '2254': '熨', '2255': '鲫', '2256': '兰', '2257': '检', '2258': '判', '2259': '县', '2260': '孳', '2261': '腔', '2262': '岚', '2263': '煜', '2264': '悟', '2265': '弘', '2266': '棉', '2267': '瞒', '2268': '剿', '2269': '琪', '2270': '撸', '2271': '袢', '2272': '棘', '2273': '晴', '2274': '胭', '2275': '滕', '2276': '８', '2277': '楷', '2278': '糜', '2279': '嫡', '2280': '兖', '2281': '徭', '2282': '锉', '2283': '另', '2284': '荡', '2285': '霪', '2286': '羿', '2287': '络', '2288': '湄', '2289': '伧', '2290': '泽', '2291': '轰', '2292': '愚', '2293': '禳', '2294': '邓', '2295': '浒', '2296': '罩', '2297': '蒌', '2298': '涂', '2299': '孪', '2300': '褰', '2301': '逐', '2302': '贡', '2303': '掘', '2304': '媛', '2305': '羸', '2306': '寞', '2307': '骑', '2308': '薰', '2309': '能', '2310': '燠', '2311': '霖', '2312': '湓', '2313': '疏', '2314': '泻', '2315': '焚', '2316': '避', '2317': '厨', '2318': '筮', '2319': '旌', '2320': '袖', '2321': '爝', '2322': '背', '2323': '措', '2324': '壁', '2325': '髡', '2326': '轴', '2327': '坦', '2328': '螳', '2329': '丸', '2330': '蹋', '2331': '狼', '2332': '侥', '2333': '哗', '2334': '揩', '2335': '佯', '2336': '曩', '2337': '旭', '2338': '鼐', '2339': '藻', '2340': '室', '2341': '帏', '2342': '悉', '2343': '班', '2344': '颛', '2345': '烙', '2346': '葑', '2347': '莱', '2348': '因', '2349': '消', '2350': '彗', '2351': '祢', '2352': '匪', '2353': '锵', '2354': '各', '2355': '庶', '2356': '哂', '2357': '槛', '2358': '袋', '2359': '缲', '2360': '闩', '2361': '揾', '2362': '铢', '2363': '裔', '2364': '剑', '2365': '裹', '2366': '旗', '2367': '巽', '2368': '揉', '2369': '仙', '2370': '鳃', '2371': '陵', '2372': '叨', '2373': '求', '2374': '辱', '2375': '栳', '2376': '辏', '2377': '蝴', '2378': '无', '2379': '跻', '2380': '濛', '2381': '奎', '2382': '焦', '2383': '招', '2384': '孕', '2385': '瀣', '2386': '谰', '2387': '晞', '2388': '颂', '2389': '否', '2390': '赖', '2391': '谇', '2392': '厚', '2393': '轩', '2394': '退', '2395': '肋', '2396': '近', '2397': '携', '2398': '闾', '2399': '买', '2400': '完', '2401': '昌', '2402': '对', '2403': '嘻', '2404': '芥', '2405': '松', '2406': 'そ', '2407': '挲', '2408': '妄', '2409': '二', '2410': '捞', '2411': '笾', '2412': '主', '2413': '彷', '2414': '歌', '2415': '黠', '2416': '枞', '2417': '由', '2418': '/', '2419': '窄', '2420': '祭', '2421': '伥', '2422': '裛', '2423': '壮', '2424': '犁', '2425': '侯', '2426': '搐', '2427': '荤', '2428': '溃', '2429': '很', '2430': '嫠', '2431': '堆', '2432': '悭', '2433': '鹤', '2434': '骰', '2435': '狱', '2436': '嚏', '2437': '淦', '2438': '慨', '2439': '妇', '2440': '惭', '2441': '枭', '2442': '狗', '2443': '葳', '2444': '荔', '2445': '幼', '2446': '纠', '2447': '鹰', '2448': '骘', '2449': '临', '2450': '府', '2451': '蝣', '2452': '总', '2453': '碎', '2454': '裴', '2455': '弛', '2456': '泯', '2457': '捕', '2458': '煞', '2459': '茯', '2460': '三', '2461': '崑', '2462': '薤', '2463': '烈', '2464': '尉', '2465': '稔', '2466': '姮', '2467': '娶', '2468': '讫', '2469': '刷', '2470': '颁', '2471': '晤', '2472': '接', '2473': '偈', '2474': '轵', '2475': '愿', '2476': '侦', '2477': '曷', '2478': '蛴', '2479': '§', '2480': '爬', '2481': '疚', '2482': '祖', '2483': '芒', '2484': '檐', '2485': '毂', '2486': '切', '2487': '谌', '2488': '烹', '2489': '挽', '2490': '瓮', '2491': '茇', '2492': '款', '2493': '虏', '2494': '椠', '2495': '志', '2496': '坷', '2497': '罴', '2498': '０', '2499': '搭', '2500': '廪', '2501': '塍', '2502': '赓', '2503': '蟠', '2504': '炭', '2505': '殄', '2506': '热', '2507': '纪', '2508': '录', '2509': '旻', '2510': '茉', '2511': '刮', '2512': '球', '2513': '罨', '2514': '奋', '2515': '髻', '2516': '王', '2517': '诜', '2518': '嗄', '2519': '氛', '2520': '辂', '2521': '溆', '2522': '厥', '2523': '浸', '2524': '曳', '2525': '噫', '2526': '称', '2527': '岱', '2528': '萃', '2529': '根', '2530': '隍', '2531': '闷', '2532': '凰', '2533': '没', '2534': '荭', '2535': '咤', '2536': '饧', '2537': '蛐', '2538': '忉', '2539': '戏', '2540': '琛', '2541': '妍', '2542': '涌', '2543': '撅', '2544': '弭', '2545': '铙', '2546': '痴', '2547': '惶', '2548': '听', '2549': 'け', '2550': '卜', '2551': '设', '2552': '控', '2553': '羝', '2554': '夕', '2555': '俯', '2556': '娃', '2557': '诮', '2558': '晏', '2559': '镡', '2560': '蓝', '2561': '陡', '2562': '桓', '2563': '燔', '2564': '艳', '2565': '舰', '2566': '缡', '2567': '茹', '2568': '耍', '2569': '舌', '2570': '懆', '2571': '杓', '2572': '召', '2573': '渑', '2574': '恰', '2575': '擅', '2576': '播', '2577': '椿', '2578': '杳', '2579': '夫', '2580': '泓', '2581': '捶', '2582': '全', '2583': '矶', '2584': '若', '2585': '迩', '2586': '开', '2587': '裾', '2588': '壅', '2589': '疾', '2590': '辞', '2591': '篚', '2592': '馑', '2593': '衬', '2594': '铉', '2595': '陈', '2596': '艘', '2597': '曦', '2598': '珍', '2599': '厮', '2600': '费', '2601': '韶', '2602': '书', '2603': '玄', '2604': '拖', '2605': '俄', '2606': '僚', '2607': '蕾', '2608': '计', '2609': '侵', '2610': '咀', '2611': '品', '2612': '茕', '2613': '欷', '2614': '后', '2615': '隋', '2616': '胡', '2617': '觚', '2618': '武', '2619': '五', '2620': '幸', '2621': '亟', '2622': '霭', '2623': '聃', '2624': '玉', '2625': '葩', '2626': '畸', '2627': '檠', '2628': '麈', '2629': '长', '2630': '槭', '2631': '吓', '2632': '谢', '2633': '衩', '2634': '鲍', '2635': '密', '2636': 'Ｖ', '2637': '寝', '2638': '屐', '2639': '架', '2640': '狩', '2641': '诈', '2642': '茔', '2643': '灯', '2644': '暧', '2645': '太', '2646': '亘', '2647': '倜', '2648': '翅', '2649': '龚', '2650': '给', '2651': '沂', '2652': '夏', '2653': '宣', '2654': '诀', '2655': '阃', '2656': '孱', '2657': '璧', '2658': '蟹', '2659': '玫', '2660': '浔', '2661': '底', '2662': '浏', '2663': '揎', '2664': '栩', '2665': '稽', '2666': '亮', '2667': '赋', '2668': 'ㄉ', '2669': '霓', '2670': '辟', '2671': '巾', '2672': '卩', '2673': '骏', '2674': '性', '2675': '躲', '2676': '戬', '2677': '辐', '2678': '旆', '2679': '毙', '2680': '牒', '2681': '昃', '2682': '失', '2683': '状', '2684': '昵', '2685': '脂', '2686': '兑', '2687': '⑵', '2688': '楠', '2689': '待', '2690': '鼍', '2691': '严', '2692': '皈', '2693': '咛', '2694': '紫', '2695': '狎', '2696': '尿', '2697': '陀', '2698': '鸽', '2699': '干', '2700': '蔡', '2701': '镠', '2702': '濡', '2703': '簪', '2704': '言', '2705': '迓', '2706': '握', '2707': '芰', '2708': '延', '2709': '腊', '2710': '讷', '2711': '枢', '2712': '樨', '2713': '吞', '2714': '逖', '2715': '拙', '2716': '矍', '2717': '郑', '2718': '桩', '2719': '绿', '2720': '抵', '2721': '蜀', '2722': '《', '2723': '忖', '2724': '猝', '2725': '豹', '2726': '嶙', '2727': '偻', '2728': '创', '2729': '倏', '2730': '啖', '2731': '奉', '2732': '酒', '2733': '犹', '2734': '痒', '2735': '塔', '2736': '狞', '2737': '匿', '2738': 'ピ', '2739': '悠', '2740': '啅', '2741': '跟', '2742': '胜', '2743': '弊', '2744': '垛', '2745': '缘', '2746': '瘿', '2747': 'х', '2748': '黍', '2749': '渍', '2750': '瀑', '2751': '溜', '2752': '阻', '2753': '萱', '2754': '豪', '2755': '矮', '2756': '硗', '2757': '澹', '2758': '甑', '2759': '浑', '2760': '沿', '2761': '}', '2762': '郄', '2763': '飞', '2764': '遨', '2765': '葡', '2766': '恒', '2767': '煎', '2768': '遽', '2769': '嘛', '2770': '崤', '2771': '掌', '2772': '泫', '2773': '啼', '2774': '扛', '2775': '骡', '2776': '娆', '2777': '陶', '2778': '皇', '2779': '公', '2780': '宥', '2781': '橙', '2782': '资', '2783': '墟', '2784': '醺', '2785': '经', '2786': '蒉', '2787': '脾', '2788': '普', '2789': '筠', '2790': '疮', '2791': '数', '2792': '住', '2793': '离', '2794': '胲', '2795': '蓑', '2796': '篷', '2797': '淇', '2798': '域', '2799': '轧', '2800': '瘵', '2801': '.', '2802': '置', '2803': '蹇', '2804': '湾', '2805': '辄', '2806': '历', '2807': '洞', '2808': '橹', '2809': '归', '2810': '雌', '2811': '椹', '2812': '遏', '2813': '务', '2814': '棠', '2815': '傍', '2816': '圹', '2817': '直', '2818': '苎', '2819': '幄', '2820': '摅', '2821': '簟', '2822': '翩', '2823': '倬', '2824': '龠', '2825': '赛', '2826': '蹑', '2827': '付', '2828': '伯', '2829': '遥', '2830': '针', '2831': '徨', '2832': '帻', '2833': '孀', '2834': '锦', '2835': '诩', '2836': '侣', '2837': '蛆', '2838': '条', '2839': '獐', '2840': '靶', '2841': '划', '2842': '胁', '2843': '掀', '2844': '平', '2845': '蠹', '2846': '部', '2847': '钻', '2848': '笛', '2849': '盍', '2850': '倩', '2851': '受', '2852': '濉', '2853': '摄', '2854': '涸', '2855': '繇', '2856': '骂', '2857': '而', '2858': '莘', '2859': '缅', '2860': '秩', '2861': '灿', '2862': '箝', '2863': '郝', '2864': '恕', '2865': '绠', '2866': '缺', '2867': '点', '2868': '挈', '2869': '栎', '2870': '银', '2871': '耳', '2872': '峦', '2873': '语', '2874': '谍', '2875': '谑', '2876': '隶', '2877': '累', '2878': '毗', '2879': '究', '2880': '矫', '2881': '鲑', '2882': '爹', '2883': '庞', '2884': '死', '2885': '猩', '2886': '毓', '2887': '并', '2888': '圣', '2889': '醅', '2890': '略', '2891': '脆', '2892': '疃', '2893': '抖', '2894': '楯', '2895': '溶', '2896': 'ち', '2897': '朔', '2898': '漓', '2899': '咙', '2900': '莲', '2901': '旨', '2902': '狭', '2903': '除', '2904': '印', '2905': '朋', '2906': '瞻', '2907': '乃', '2908': '蛛', '2909': '依', '2910': '萤', '2911': '匣', '2912': '鞭', '2913': '在', '2914': '脯', '2915': '未', '2916': '险', '2917': '渭', '2918': '刑', '2919': '邵', '2920': '漪', '2921': '迅', '2922': '海', '2923': '茁', '2924': '好', '2925': '蠖', '2926': '阡', '2927': '虫', '2928': '轾', '2929': '黻', '2930': '群', '2931': '徵', '2932': '逞', '2933': '扑', '2934': '醒', '2935': '裙', '2936': '看', '2937': '要', '2938': '踢', '2939': '兀', '2940': '歆', '2941': '日', '2942': '蓬', '2943': '窘', '2944': '馋', '2945': '氏', '2946': '汰', '2947': '相', '2948': '粼', '2949': '履', '2950': '莩', '2951': '恙', '2952': '颡', '2953': '葱', '2954': '滂', '2955': '最', '2956': '繁', '2957': '榱', '2958': '眈', '2959': '批', '2960': '摧', '2961': '黄', '2962': '蜚', '2963': '醵', '2964': '了', '2965': '蚩', '2966': '姹', '2967': '爻', '2968': '漕', '2969': '棕', '2970': '锓', '2971': '嗜', '2972': '洽', '2973': '篙', '2974': '灸', '2975': '猖', '2976': '嵚', '2977': '觳', '2978': '坡', '2979': '南', '2980': '乏', '2981': '晋', '2982': '典', '2983': '降', '2984': '襟', '2985': '姬', '2986': '舣', '2987': '通', '2988': '乇', '2989': '涣', '2990': '翎', '2991': '谁', '2992': '困', '2993': '厕', '2994': '桉', '2995': '阕', '2996': '轸', '2997': '急', '2998': '闭', '2999': '擂', '3000': '治', '3001': '郐', '3002': '>', '3003': '锸', '3004': '常', '3005': '肢', '3006': '馒', '3007': '娅', '3008': '低', '3009': '熳', '3010': '渔', '3011': '牛', '3012': '嵛', '3013': '震', '3014': '液', '3015': '箍', '3016': '赚', '3017': '戛', '3018': '宏', '3019': '奶', '3020': '佞', '3021': '声', '3022': '寄', '3023': '环', '3024': '嗽', '3025': '位', '3026': '盂', '3027': '嘏', '3028': '呖', '3029': '卒', '3030': '楼', '3031': '搀', '3032': '村', '3033': '藉', '3034': '鼎', '3035': '戴', '3036': '恹', '3037': '窜', '3038': '药', '3039': '侮', '3040': '辽', '3041': '瞠', '3042': '毵', '3043': '鲇', '3044': '彩', '3045': '番', '3046': '断', '3047': '袤', '3048': '觉', '3049': '也', '3050': 'ò', '3051': '戒', '3052': '佼', '3053': '婉', '3054': '笔', '3055': '簇', '3056': '愣', '3057': '皑', '3058': '泣', '3059': '畏', '3060': '奠', '3061': '来', '3062': '暝', '3063': '飧', '3064': '谙', '3065': '潜', '3066': '饯', '3067': '奂', '3068': '晚', '3069': '纡', '3070': '宦', '3071': '黼', '3072': '崦', '3073': '硬', '3074': '客', '3075': '抟', '3076': '谴', '3077': '阁', '3078': '鉴', '3079': '缴', '3080': '贼', '3081': '屿', '3082': '裯', '3083': '郏', '3084': '宰', '3085': '蕉', '3086': '懵', '3087': '月', '3088': '专', '3089': '绦', '3090': '损', '3091': '毛', '3092': '情', '3093': '谓', '3094': '惜', '3095': '竟', '3096': '古', '3097': '辰', '3098': '左', '3099': '潞', '3100': '蚨', '3101': '缬', '3102': '醋', '3103': '棰', '3104': '评', '3105': '稚', '3106': '诏', '3107': '衫', '3108': '獠', '3109': '忔', '3110': '腕', '3111': '箬', '3112': '届', '3113': '端', '3114': '甓', '3115': '姥', '3116': '寅', '3117': '娩', '3118': '傲', '3119': '箭', '3120': '蜿', '3121': '圃', '3122': '宕', '3123': '题', '3124': '眵', '3125': '妹', '3126': '藓', '3127': '蹂', '3128': '级', '3129': '狄', '3130': '篌', '3131': '萄', '3132': '优', '3133': '燎', '3134': '粱', '3135': '率', '3136': '罹', '3137': '疵', '3138': '毡', '3139': '霁', '3140': '怿', '3141': '害', '3142': '癖', '3143': '键', '3144': '蝼', '3145': '验', '3146': '垠', '3147': '秃', '3148': '轲', '3149': '蔷', '3150': '臾', '3151': '酷', '3152': '馀', '3153': '芩', '3154': '咋', '3155': '硫', '3156': '傀', '3157': '铨', '3158': '肚', '3159': '鬯', '3160': '墉', '3161': '瓴', '3162': '遴', '3163': '鲈', '3164': '蛞', '3165': '嗅', '3166': '参', '3167': '贯', '3168': '弼', '3169': '锅', '3170': '睬', '3171': '字', '3172': '囤', '3173': '芝', '3174': '备', '3175': '啾', '3176': '桅', '3177': '蟋', '3178': '先', '3179': '杷', '3180': '俳', '3181': '哉', '3182': '叫', '3183': '丝', '3184': '译', '3185': '盛', '3186': '误', '3187': '厘', '3188': '讼', '3189': '莞', '3190': '诣', '3191': '阿', '3192': '己', '3193': '柙', '3194': '砾', '3195': '宁', '3196': '裤', '3197': '筝', '3198': '撋', '3199': '耆', '3200': '剡', '3201': '貉', '3202': '乍', '3203': '傩', '3204': '督', '3205': '白', '3206': '琥', '3207': '骐', '3208': '厉', '3209': '玕', '3210': '纨', '3211': '歼', '3212': '送', '3213': '壕', '3214': '汹', '3215': '嵋', '3216': '迦', '3217': '信', '3218': '内', '3219': '佐', '3220': '鞅', '3221': '兕', '3222': '孤', '3223': '晨', '3224': '妊', '3225': '异', '3226': '诡', '3227': '耒', '3228': '章', '3229': '嘈', '3230': '策', '3231': '始', '3232': '惹', '3233': '俑', '3234': '苑', '3235': '齐', '3236': '团', '3237': '鹅', '3238': '惚', '3239': '阱', '3240': '眢', '3241': '酊', '3242': '苏', '3243': '菰', '3244': '肖', '3245': '悌', '3246': '奴', '3247': '愧', '3248': '审', '3249': '兔', '3250': '存', '3251': '均', '3252': '微', '3253': '跏', '3254': 'с', '3255': '鹂', '3256': '岸', '3257': '妖', '3258': '过', '3259': '藜', '3260': '】', '3261': '铠', '3262': '恃', '3263': '雠', '3264': '哄', '3265': '缁', '3266': '踊', '3267': '炳', '3268': '缫', '3269': '啧', '3270': '撼', '3271': '眩', '3272': '滚', '3273': '帽', '3274': '搜', '3275': '莓', '3276': '进', '3277': '瑶', '3278': '惰', '3279': '浓', '3280': '巴', '3281': '扣', '3282': '杵', '3283': '破', '3284': '鸩', '3285': '逻', '3286': '做', '3287': '琶', '3288': '桤', '3289': '旁', '3290': '雪', '3291': '嶷', '3292': '稀', '3293': '羔', '3294': '源', '3295': '诹', '3296': '博', '3297': '肱', '3298': '懒', '3299': '蟾', '3300': '阆', '3301': '觯', '3302': '璐', '3303': '缚', '3304': '鲤', '3305': '袒', '3306': '铄', '3307': '杰', '3308': '徼', '3309': '揽', '3310': '擎', '3311': '编', '3312': '序', '3313': '钲', '3314': '汾', '3315': '酪', '3316': '瘢', '3317': '氓', '3318': '升', '3319': '陛', '3320': '躬', '3321': '深', '3322': '探', '3323': '瓠', '3324': '绥', '3325': '伫', '3326': '饭', '3327': '导', '3328': '阙', '3329': '顺', '3330': '邗', '3331': '春', '3332': '恋', '3333': '漆', '3334': '尖', '3335': '琬', '3336': '饩', '3337': '隙', '3338': '蘧', '3339': '野', '3340': '荠', '3341': '螃', '3342': '士', '3343': '嗤', '3344': '脔', '3345': '郭', '3346': '帅', '3347': '樵', '3348': '铁', '3349': '璨', '3350': '跛', '3351': '颈', '3352': '渗', '3353': '谐', '3354': '踪', '3355': '菲', '3356': '糟', '3357': '漭', '3358': '鲜', '3359': '憨', '3360': '帷', '3361': '痨', '3362': '彤', '3363': '翱', '3364': '欺', '3365': '碧', '3366': '卷', '3367': '檀', '3368': '邑', '3369': '艇', '3370': '躐', '3371': '瑛', '3372': '往', '3373': '聘', '3374': '邂', '3375': '匮', '3376': '呈', '3377': '锷', '3378': '熠', '3379': '龄', '3380': '孜', '3381': '擘', '3382': '东', '3383': '词', '3384': '馥', '3385': '皤', '3386': '鞯', '3387': '哥', '3388': '谟', '3389': '抹', '3390': '满', '3391': '瞢', '3392': '鲆', '3393': '温', '3394': '呦', '3395': '葵', '3396': '鼯', '3397': '潋', '3398': '泡', '3399': '茜', '3400': '寻', '3401': '譬', '3402': '睨', '3403': '约', '3404': '麝', '3405': '猊', '3406': '个', '3407': '跗', '3408': '鼻', '3409': '绪', '3410': '支', '3411': '桁', '3412': '涎', '3413': '箱', '3414': '帆', '3415': '刳', '3416': '翌', '3417': '别', '3418': '忿', '3419': '鲲', '3420': '澎', '3421': '簦', '3422': '缃', '3423': '砉', '3424': '致', '3425': '陲', '3426': '腹', '3427': '促', '3428': '难', '3429': '驺', '3430': '令', '3431': '＿', '3432': '胸', '3433': '忱', '3434': '僦', '3435': '氤', '3436': '铛', '3437': '惆', '3438': '苍', '3439': '止', '3440': '潭', '3441': '兽', '3442': '库', '3443': '拾', '3444': '秾', '3445': '雎', '3446': '蹒', '3447': '甸', '3448': '旃', '3449': '迄', '3450': '淰', '3451': '需', '3452': '岳', '3453': '态', '3454': '讯', '3455': '乘', '3456': '货', '3457': '恼', '3458': '鄞', '3459': '琰', '3460': '范', '3461': '夥', '3462': '耽', '3463': '辩', '3464': '俎', '3465': '睹', '3466': '折', '3467': '秉', '3468': '韬', '3469': '怒', '3470': '酏', '3471': '羯', '3472': '吮', '3473': '桷', '3474': '吐', '3475': '掣', '3476': '洮', '3477': '谩', '3478': '甫', '3479': '麦', '3480': '杯', '3481': '丛', '3482': '齑', '3483': '枉', '3484': '俺', '3485': '腴', '3486': '饪', '3487': '鲙', '3488': '羌', '3489': '鹁', '3490': '啁', '3491': '埒', '3492': '沛', '3493': '页', '3494': '罄', '3495': '瀛', '3496': '诨', '3497': '旄', '3498': '衮', '3499': '丿', '3500': '知', '3501': '粢', '3502': '惟', '3503': '蝶', '3504': '料', '3505': '睡', '3506': '尚', '3507': '氐', '3508': '恩', '3509': '惯', '3510': '遮', '3511': '笈', '3512': '莫', '3513': '终', '3514': '祜', '3515': '爵', '3516': '墅', '3517': '姓', '3518': '屹', '3519': '沌', '3520': '僝', '3521': '颜', '3522': '秀', '3523': '禀', '3524': '勒', '3525': '亭', '3526': '馘', '3527': '弯', '3528': '邀', '3529': '喈', '3530': '缕', '3531': '呤', '3532': '瘴', '3533': '米', '3534': '橘', '3535': '削', '3536': '抛', '3537': '龈', '3538': '伛', '3539': '泠', '3540': '冽', '3541': '姒', '3542': '旧', '3543': '纺', '3544': '城', '3545': '恍', '3546': '舀', '3547': '乐', '3548': '卤', '3549': '殳', '3550': '燃', '3551': '桦', '3552': '聋', '3553': '婪', '3554': '唏', '3555': '我', '3556': '吁', '3557': '叟', '3558': '箴', '3559': '摘', '3560': '怜', '3561': '栈', '3562': '桶', '3563': '今', '3564': '咿', '3565': '\\ue3ff', '3566': '午', '3567': '决', '3568': '怯', '3569': '册', '3570': '弈', '3571': '蒲', '3572': '抚', '3573': '教', '3574': '园', '3575': '魂', '3576': '齿', '3577': '锢', '3578': '泰', '3579': '\\ue4bf', '3580': '”', '3581': '抑', '3582': '冁', '3583': '徕', '3584': '衾', '3585': '歧', '3586': '伤', '3587': 'Ａ', '3588': '竽', '3589': '政', '3590': '杉', '3591': '贤', '3592': '绅', '3593': '魅', '3594': '壤', '3595': '喃', '3596': '懔', '3597': '兮', '3598': '当', '3599': '酋', '3600': '缙', '3601': '迂', '3602': '饱', '3603': '萝', '3604': '２', '3605': '刂', '3606': '箸', '3607': '永', '3608': '舳', '3609': '顾', '3610': '次', '3611': '可', '3612': '腥', '3613': '绮', '3614': '鳊', '3615': '磔', '3616': '怅', '3617': '歃', '3618': '臬', '3619': '桔', '3620': '串', '3621': '效', '3622': '廖', '3623': '睥', '3624': '槿', '3625': '龋', '3626': '卸', '3627': '伽', '3628': '茅', '3629': '卯', '3630': '片', '3631': '藐', '3632': '捎', '3633': '蕤', '3634': '早', '3635': '蛄', '3636': '挞', '3637': '仂', '3638': '湃', '3639': '视', '3640': '煌', '3641': '荛', '3642': '浮', '3643': '汜', '3644': '丑', '3645': '只', '3646': '馔', '3647': '嫖', '3648': '蹈', '3649': '护', '3650': '瓒', '3651': '奔', '3652': '逋', '3653': '虞', '3654': '臼', '3655': '妈', '3656': '波', '3657': '岿', '3658': '铎', '3659': '弱', '3660': '盒', '3661': '地', '3662': '恭', '3663': '渚', '3664': '靥', '3665': '间', '3666': '旬', '3667': '论', '3668': '见', '3669': '连', '3670': '足', '3671': '鱼', '3672': '贲', '3673': '踏', '3674': '蜜', '3675': '翟', '3676': '籀', '3677': '伍', '3678': '眯', '3679': '晡', '3680': '试', '3681': '御', '3682': '偷', '3683': '卢', '3684': '刹', '3685': '棂', '3686': '尾', '3687': '超', '3688': '冀', '3689': '冰', '3690': '施', '3691': '褒', '3692': '轿', '3693': '沈', '3694': '篆', '3695': '阮', '3696': '芍', '3697': '郸', '3698': '跚', '3699': '渤', '3700': '甃', '3701': '咸', '3702': '僧', '3703': '穑', '3704': '哺', '3705': '劝', '3706': '雀', '3707': '贰', '3708': '邙', '3709': '酥', '3710': '衔', '3711': '龛', '3712': '舟', '3713': '蹊', '3714': '静', '3715': '革', '3716': '褥', '3717': '骤', '3718': '茆', '3719': '裟', '3720': '镂', '3721': '侍', '3722': '车', '3723': '仁', '3724': '谈', '3725': '晰', '3726': '掠', '3727': '楦', '3728': '撄', '3729': '悄', '3730': '帝', '3731': '畜', '3732': '烘', '3733': '斗', '3734': '娴', '3735': '邯', '3736': '锐', '3737': '佶', '3738': '稿', '3739': '霍', '3740': '健', '3741': '繭', '3742': '悻', '3743': '糠', '3744': '贻', '3745': '固', '3746': '辅', '3747': '撞', '3748': '丕', '3749': '俗', '3750': '罚', '3751': '宠', '3752': '绳', '3753': '矣', '3754': '琉', '3755': '搽', '3756': '囉', '3757': '谕', '3758': '菁', '3759': '冒', '3760': '牟', '3761': '肓', '3762': '晶', '3763': '枯', '3764': '翡', '3765': '省', '3766': '拌', '3767': '薪', '3768': '剪', '3769': '犯', '3770': '四', '3771': '莺', '3772': '昊', '3773': '凛', '3774': '蹰', '3775': '搏', '3776': '┾', '3777': '耿', '3778': '溱', '3779': '縻', '3780': '镊', '3781': '违', '3782': '霄', '3783': '拮', '3784': '拜', '3785': '钿', '3786': '闻', '3787': '喔', '3788': '饴', '3789': '患', '3790': '绛', '3791': '鹫', '3792': '揶', '3793': '罍', '3794': '板', '3795': '安', '3796': '偿', '3797': '鮓', '3798': '峭', '3799': '妥', '3800': '土', '3801': '企', '3802': '炀', '3803': '诠', '3804': '军', '3805': '锄', '3806': '鸥', '3807': '恶', '3808': '骅', '3809': '戊', '3810': '屺', '3811': '婀', '3812': '幢', '3813': '慧', '3814': '鸳', '3815': '沓', '3816': '详', '3817': '炜', '3818': '岩', '3819': '憝', '3820': '展', '3821': '匡', '3822': '蚪', '3823': '载', '3824': '觊', '3825': '谛', '3826': '迫', '3827': '洳', '3828': '尘', '3829': '煨', '3830': '劬', '3831': '薄', '3832': '崩', '3833': '舆', '3834': '鹓', '3835': 'ソ', '3836': '秣', '3837': '槌', '3838': '胎', '3839': '豉', '3840': '贮', '3841': '捐', '3842': '醯', '3843': '踞', '3844': '星', '3845': '徉', '3846': '结', '3847': '洛', '3848': '衄', '3849': '宾', '3850': '赢', '3851': '庸', '3852': '故', '3853': '蛱', '3854': '似', '3855': '答', '3856': '悸', '3857': '阄', '3858': '豢', '3859': '校', '3860': '梧', '3861': '蜃', '3862': '英', '3863': '抠', '3864': '钦', '3865': '饰', '3866': '蹴', '3867': '矧', '3868': '淬', '3869': '稂', '3870': '骎', '3871': '隗', '3872': '酽', '3873': '喧', '3874': '局', '3875': '宴', '3876': '炷', '3877': '；', '3878': '烟', '3879': '余', '3880': '用', '3881': '诤', '3882': '凹', '3883': '技', '3884': '舂', '3885': '呜', '3886': '号', '3887': '鹢', '3888': '鑺', '3889': '盱', '3890': '钝', '3891': '览', '3892': '廊', '3893': '郴', '3894': '庆', '3895': '痛', '3896': '粒', '3897': '酹', '3898': '年', '3899': '掩', '3900': '萧', '3901': '嶢', '3902': '匹', '3903': '践', '3904': '借', '3905': '赣', '3906': '沩', '3907': '砧', '3908': '酎', '3909': '忧', '3910': '湫', '3911': '权', '3912': '睛', '3913': '懊', '3914': '茱', '3915': '媸', '3916': '绽', '3917': '胙', '3918': '简', '3919': '冉', '3920': '麻', '3921': '炼', '3922': '樽', '3923': '介', '3924': '弧', '3925': '擗', '3926': '桴', '3927': '鸶', '3928': '卞', '3929': '筐', '3930': '扆', '3931': '振', '3932': '遣', '3933': '须', '3934': '双', '3935': '痍', '3936': '焙', '3937': '测', '3938': '母', '3939': '挼', '3940': '盎', '3941': '献', '3942': '泊', '3943': '荪', '3944': '腼', '3945': '飕', '3946': '枚', '3947': '师', '3948': '淫', '3949': '宋', '3950': '坞', '3951': '李', '3952': '垩', '3953': '殃', '3954': '爱', '3955': '员', '3956': '慈', '3957': '洧', '3958': '魉', '3959': '衰', '3960': '舷', '3961': '鹈', '3962': '羡', '3963': '插', '3964': '娜', '3965': '奥', '3966': '伐', '3967': '果', '3968': '持', '3969': '既', '3970': '蘸', '3971': '褫', '3972': '嘤', '3973': '矾', '3974': '拽', '3975': '扮', '3976': '蒡', '3977': '踌', '3978': '佳', '3979': '咬', '3980': '段', '3981': '猬', '3982': '骛', '3983': '遍', '3984': '返', '3985': '焉', '3986': '麾', '3987': '但', '3988': '然', '3989': '剥', '3990': '议', '3991': '沃', '3992': '喷', '3993': '菖', '3994': '挠', '3995': '晷', '3996': '氅', '3997': '铭', '3998': '珧', '3999': '？', '4000': '溽', '4001': '逄', '4002': '正', '4003': '工', '4004': '佩', '4005': '糁', '4006': '勃', '4007': '袜', '4008': '冤', '4009': '璎', '4010': '讦', '4011': '轫', '4012': '绣', '4013': '捋', '4014': '雹', '4015': '酤', '4016': '殒', '4017': '空', '4018': '俟', '4019': '戚', '4020': '寇', '4021': '奇', '4022': '调', '4023': '垫', '4024': '卦', '4025': '勋', '4026': '茏', '4027': '孥', '4028': '峨', '4029': '删', '4030': '寰', '4031': '殿', '4032': '沧', '4033': '惝', '4034': '报', '4035': '榆', '4036': '筹', '4037': '睫', '4038': '拈', '4039': '欤', '4040': '谘', '4041': '耕', '4042': '鹄', '4043': '伶', '4044': '障', '4045': '秽', '4046': '颉', '4047': '漉', '4048': '唧', '4049': '朴', '4050': '揄', '4051': '祧', '4052': '中', '4053': '謦', '4054': '馁', '4055': 'ā', '4056': '粲', '4057': '被', '4058': '磴', '4059': '筛', '4060': '理', '4061': '核', '4062': '鸿', '4063': '涑', '4064': '梓', '4065': '柽', '4066': '装', '4067': '滋', '4068': '钳', '4069': '老', '4070': '蛤', '4071': '┭', '4072': '膏', '4073': '系', '4074': '蝎', '4075': '候', '4076': '挪', '4077': '轳', '4078': '嬴', '4079': '荷', '4080': '裀', '4081': '焘', '4082': '邺', '4083': '嚎', '4084': '这', '4085': '及', '4086': '梵', '4087': '思', '4088': '腋', '4089': '瓯', '4090': '么', '4091': '唱', '4092': '翕', '4093': '喜', '4094': '埸', '4095': '搅', '4096': '和', '4097': '蜂', '4098': '鹿', '4099': '荑', '4100': '蔚', '4101': '顿', '4102': '斤', '4103': '与', '4104': '眷', '4105': '爪', '4106': '倪', '4107': '拨', '4108': '丞', '4109': '岜', '4110': '输', '4111': '趺', '4112': '皮', '4113': '寂', '4114': 'が', '4115': '敞', '4116': '厦', '4117': '秸', '4118': '筱', '4119': '攀', '4120': '杲', '4121': '屉', '4122': '剀', '4123': '百', '4124': '缸', '4125': '川', '4126': '酉', '4127': '徒', '4128': '悼', '4129': '贪', '4130': '慳', '4131': '娑', '4132': '逦', '4133': '蛙', '4134': 'ヵ', '4135': '栗', '4136': '乞', '4137': '裥', '4138': '胝', '4139': '虽', '4140': '鲂', '4141': '浃', '4142': '浍', '4143': '辙', '4144': '肃', '4145': '规', '4146': '鹑', '4147': '磨', '4148': '榻', '4149': '瑰', '4150': '、', '4151': '抬', '4152': '杀', '4153': '肾', '4154': '鲁', '4155': '作', '4156': '魏', '4157': '熊', '4158': '徐', '4159': '飙', '4160': '瘁', '4161': '缨', '4162': '养', '4163': '笠', '4164': 'や', '4165': '址', '4166': '肠', '4167': '耐', '4168': '子', '4169': '仇', '4170': '合', '4171': '胶', '4172': '赐', '4173': '貔', '4174': '舜', '4175': '阶', '4176': '洲', '4177': '胞', '4178': '勤', '4179': '忍', '4180': '砰', '4181': '徘', '4182': '嗥', '4183': '停', '4184': '浥', '4185': '芨', '4186': '秦', '4187': '镳', '4188': '已', '4189': '胄', '4190': '篾', '4191': '蕨', '4192': '鸟', '4193': '镜', '4194': '贞', '4195': '湟', '4196': '欣', '4197': '掇', '4198': '暨', '4199': '积', '4200': '羹', '4201': '样', '4202': '讴', '4203': '迳', '4204': '昏', '4205': '屦', '4206': '》', '4207': '仝', '4208': '荜', '4209': '驶', '4210': '莳', '4211': 'シ', '4212': '伸', '4213': '荧', '4214': '幌', '4215': '俸', '4216': '绍', '4217': '互', '4218': '威', '4219': '惠', '4220': '犒', '4221': '艟', '4222': '卖', '4223': '嬉', '4224': '管', '4225': '弋', '4226': '葭', '4227': '慎', '4228': '鄂', '4229': '楫', '4230': '搔', '4231': '涩', '4232': '纳', '4233': '克', '4234': '浦', '4235': '肘', '4236': '菟', '4237': '牖', '4238': '燮', '4239': '樗', '4240': '旖', '4241': '亚', '4242': '虮', '4243': '义', '4244': '芽', '4245': '蕊', '4246': '蛮', '4247': '汁', '4248': '睇', '4249': '蹭', '4250': '润', '4251': '冯', '4252': '羲', '4253': '蹲', '4254': '篦', '4255': '敕', '4256': '髹', '4257': '闹', '4258': '摹', '4259': '悔', '4260': '鞚', '4261': '镒', '4262': '俩', '4263': '卮', '4264': '枵', '4265': '花', '4266': '阳', '4267': '越', '4268': '基', '4269': '居', '4270': '媚', '4271': '躁', '4272': '木', '4273': '躞', '4274': '尤', '4275': '禄', '4276': '澌', '4277': '砥', '4278': '寓', '4279': '逮', '4280': '濠', '4281': '醴', '4282': '渥', '4283': '狠', '4284': '飚', '4285': '垢', '4286': '童', '4287': '废', '4288': '婆', '4289': '季', '4290': '棱', '4291': '弹', '4292': '蹉', '4293': '桀', '4294': '元', '4295': '昧', '4296': '牝', '4297': '九', '4298': '缥', '4299': '座', '4300': '珂', '4301': '诟', '4302': '柄', '4303': '桕', '4304': '揖', '4305': '心', '4306': '蒹', '4307': '伏', '4308': '荆', '4309': '或', '4310': '敛', '4311': '璋', '4312': '冷', '4313': '柯', '4314': '纵', '4315': '薏', '4316': '蕖', '4317': '肩', '4318': '趣', '4319': '忒', '4320': '灏', '4321': '萼', '4322': '妁', '4323': '像', '4324': '濮', '4325': '蚀', '4326': '六', '4327': '撇', '4328': '婵', '4329': '竹', '4330': '汀', '4331': '起', '4332': '渴', '4333': '饬', '4334': '社', '4335': '瀹', '4336': '嘴', '4337': '臧', '4338': '达', '4339': '某', '4340': '霞', '4341': '愫', '4342': '咻', '4343': '畎', '4344': '棺', '4345': '栲', '4346': '路', '4347': '菀', '4348': '少', '4349': '巨', '4350': '捺', '4351': '畀', '4352': '砣', '4353': '钮', '4354': '造', '4355': '钢', '4356': '蜍', '4357': '房', '4358': '吉', '4359': '肆', '4360': '煦', '4361': '凯', '4362': '析', '4363': '首', '4364': '苘', '4365': '续', '4366': '夤', '4367': '屡', '4368': '怎', '4369': 'Ｗ', '4370': '潮', '4371': '禊', '4372': '朗', '4373': '獒', '4374': '嫱', '4375': '耻', '4376': '邹', '4377': '卑', '4378': '枘', '4379': '夭', '4380': '苛', '4381': '柜', '4382': '闱', '4383': '凝', '4384': '祠', '4385': '跬', '4386': '萁', '4387': '弟', '4388': '跣', '4389': '鲵', '4390': '柔', '4391': '沁', '4392': '厅', '4393': '，', '4394': '铲', '4395': '狯', '4396': '阎', '4397': '涵', '4398': '于', '4399': '仆', '4400': '呵', '4401': '骄', '4402': '篝', '4403': '泞', '4404': '裸', '4405': '棣', '4406': '傥', '4407': '差', '4408': '刁', '4409': '俪', '4410': '占', '4411': '跸', '4412': '璇', '4413': '轮', '4414': '邻', '4415': '霸', '4416': '泥', '4417': '兹', '4418': '‘', '4419': '莉', '4420': '顽', '4421': '敌', '4422': '皎', '4423': '穰', '4424': '诙', '4425': '僮', '4426': '梨', '4427': '戟', '4428': '炙', '4429': '橄', '4430': '沤', '4431': '蹶', '4432': '掏', '4433': '怕', '4434': '濒', '4435': '默', '4436': '猛', '4437': '爆', '4438': '淝', '4439': '唐', '4440': '向', '4441': '火', '4442': '杠', '4443': '篮', '4444': '癃', '4445': '拼', '4446': '愈', '4447': '螽', '4448': '绶', '4449': '弗', '4450': '颠', '4451': '汇', '4452': '澒', '4453': '颚', '4454': '蛇', '4455': '槎', '4456': '扌', '4457': '曜', '4458': '暄', '4459': '顸', '4460': '曾', '4461': '樊', '4462': '俞', '4463': '蓦', '4464': '掬', '4465': '醉', '4466': '鞠', '4467': '明', '4468': '喙', '4469': '抉', '4470': '不', '4471': '凌', '4472': '萋', '4473': '函', '4474': '酢', '4475': '尹', '4476': '纲', '4477': '芴', '4478': '联', '4479': '阚', '4480': '竖', '4481': '绌', '4482': '袂', '4483': '暑', '4484': '医', '4485': '褐', '4486': '沆', '4487': '船', '4488': '厌', '4489': '旅', '4490': '体', '4491': '拭', '4492': '墩', '4493': '吸', '4494': '楹', '4495': '巢', '4496': '茶', '4497': '盗', '4498': '蜗', '4499': '岘', '4500': '两', '4501': '淞', '4502': '虐', '4503': '涝', '4504': '篱', '4505': '湔', '4506': '鄜', '4507': '表', '4508': 'ど', '4509': '弁', '4510': '辋', '4511': '桠', '4512': '乔', '4513': '狨', '4514': '伟', '4515': '猎', '4516': '钗', '4517': '所', '4518': '撺', '4519': '伪', '4520': '瞋', '4521': '吴', '4522': '绯', '4523': '枷', '4524': '辊', '4525': '吾', '4526': '天', '4527': '簧', '4528': '等', '4529': '认', '4530': '踯', '4531': '倭', '4532': '劲', '4533': '下', '4534': '乖', '4535': '汛', '4536': '朦', '4537': '粪', '4538': '鼠', '4539': '斛', '4540': '橡', '4541': '把', '4542': '雩', '4543': '特', '4544': '罟', '4545': 'ь', '4546': '恬', '4547': '柁', '4548': '倾', '4549': '石', '4550': '油', '4551': '谣', '4552': '惋', '4553': '虹', '4554': '喑', '4555': '祺', '4556': '朵', '4557': '统', '4558': '铅', '4559': '腮', '4560': '惊', '4561': '愤', '4562': '驷', '4563': '含', '4564': '崖', '4565': '憔', '4566': '殊', '4567': '茨', '4568': '组', '4569': '郊', '4570': '诱', '4571': '幡', '4572': '兴', '4573': '萍', '4574': '恧', '4575': '柘', '4576': '蜾', '4577': '短', '4578': '念', '4579': '彘', '4580': '崎', '4581': '珑', '4582': '沦', '4583': '毹', '4584': '箨', '4585': '马', '4586': '聊', '4587': '柏', '4588': '察', '4589': '驯', '4590': '倡', '4591': '晟', '4592': '蹬', '4593': '习', '4594': '葛', '4595': '貌', '4596': '善', '4597': '寐', '4598': '侃', '4599': '鹎', '4600': '趾', '4601': '霹', '4602': '皙', '4603': '跨', '4604': '涤', '4605': '舸', '4606': '跽', '4607': '拂', '4608': '帙', '4609': '熹', '4610': '堡', '4611': '棼', '4612': '喟', '4613': '豫', '4614': '漫', '4615': '炯', '4616': '琳', '4617': '迁', '4618': '赌', '4619': '靓', '4620': '祁', '4621': '悯', '4622': '豸', '4623': '神', '4624': '箕', '4625': '陪', '4626': '坑', '4627': '话', '4628': '崇', '4629': '鹚', '4630': '蔓', '4631': '侏', '4632': '陟', '4633': '亏', '4634': '挹', '4635': '飐', '4636': '袅', '4637': '鞘', '4638': '陕', '4639': '艚', '4640': '旦', '4641': '袄', '4642': '剔', '4643': '珞', '4644': '井', '4645': '扼', '4646': '涟', '4647': '模', '4648': '半', '4649': '萨', '4650': '夷', '4651': '建', '4652': '巅', '4653': '比', '4654': '芙', '4655': '垦', '4656': '倥', '4657': '吼', '4658': '戋', '4659': '丧', '4660': '泸', '4661': '截', '4662': '孺', '4663': '滓', '4664': '蚁', '4665': '益', '4666': '酲', '4667': '鞋', '4668': '嘿', '4669': '葫', '4670': '醇', '4671': '示', '4672': '纹', '4673': '写', '4674': '俐', '4675': '泉', '4676': '爷', '4677': '瓜', '4678': '侧', '4679': '去', '4680': '懿', '4681': '邃', '4682': '扁', '4683': '惺', '4684': '出', '4685': '丰', '4686': '玛', '4687': '斥', '4688': '丈', '4689': '孙', '4690': '盥', '4691': '以', '4692': '幛', '4693': '婚', '4694': '漠', '4695': '况', '4696': '告', '4697': '厩', '4698': '幞', '4699': '闵', '4700': '懑', '4701': '妨', '4702': '彼', '4703': '碌', '4704': '洁', '4705': '距', '4706': '眶', '4707': '妃', '4708': '坏', '4709': '饕', '4710': '窬', '4711': '蹙', '4712': '精', '4713': '泮', '4714': '杆', '4715': '婕', '4716': '边', '4717': '夺', '4718': '枥', '4719': '颌', '4720': '跃', '4721': '鞲', '4722': '启', '4723': '斋', '4724': '釜', '4725': '讹', '4726': '挥', '4727': '琚', '4728': '贵', '4729': '忆', '4730': '犬', '4731': '竭', '4732': '竣', '4733': '灞', '4734': '筋', '4735': '俶', '4736': '埋', '4737': '乡', '4738': '嫁', '4739': '换', '4740': '疣', '4741': '瑁', '4742': '劣', '4743': '筒', '4744': '蜒', '4745': '裕', '4746': '道', '4747': '附', '4748': '限', '4749': '友', '4750': '鸣', '4751': '遁', '4752': '灺', '4753': '休', '4754': '襁', '4755': '骧', '4756': '嫦', '4757': '鹣', '4758': '缧', '4759': '螯', '4760': '蚤', '4761': '芋', '4762': '馈', '4763': '拳', '4764': '鼋', '4765': '缜', '4766': '掳', '4767': '绀', '4768': '郢', '4769': '鸭', '4770': '闽', '4771': '聚', '4772': '鹪', '4773': '扉', '4774': '滩', '4775': '复', '4776': '披', '4777': '蝇', '4778': '莼', '4779': '硌', '4780': '楝', '4781': '鴂', '4782': '阴', '4783': '侠', '4784': '恽', '4785': '菽', '4786': '粽', '4787': '蠲', '4788': '潇', '4789': '夸', '4790': '寡', '4791': '猗', '4792': '骊', '4793': '峰', '4794': '沽', '4795': '诃', '4796': '漳', '4797': '岫', '4798': '芷', '4799': '銮', '4800': '馨', '4801': '钏', '4802': '擐', '4803': '陨', '4804': '壶', '4805': '灾', '4806': '茑', '4807': '衢', '4808': '膝', '4809': '凄', '4810': '仄', '4811': '祗', '4812': '康', '4813': '家', '4814': '饫', '4815': '雉', '4816': '韵', '4817': '哪', '4818': '聿', '4819': '粝', '4820': '谒', '4821': '湿', '4822': '倍', '4823': '朱', '4824': '鳄', '4825': '泪', '4826': '沱', '4827': '菇', '4828': '细', '4829': '鹉', '4830': '末', '4831': '拘', '4832': '姊', '4833': '恣', '4834': '触', '4835': '父', '4836': '恸', '4837': '锡', '4838': '翁', '4839': '肥', '4840': '宫', '4841': '舵', '4842': '侨', '4843': '辛', '4844': '槁', '4845': '诳', '4846': '絷', '4847': '蘼', '4848': '铮', '4849': '邱', '4850': '坂', '4851': '拔', '4852': '鄹', '4853': '贴', '4854': '迥', '4855': '馗', '4856': '响', '4857': '到', '4858': '帔', '4859': '雍', '4860': '捻', '4861': '驸', '4862': '霎', '4863': '毫', '4864': '榴', '4865': '髦', '4866': '从', '4867': '酃', '4868': '偎', '4869': '堍', '4870': '错', '4871': '惫', '4872': '陔', '4873': '谠', '4874': '鲥', '4875': '捩', '4876': '跪', '4877': '万', '4878': '醪', '4879': '箔', '4880': '俱', '4881': '黏', '4882': '访', '4883': '亥', '4884': '戈', '4885': '缛', '4886': '剂', '4887': '戌', '4888': '嗔', '4889': '裼', '4890': '功', '4891': '萸', '4892': '辗', '4893': '疆', '4894': '鹭', '4895': '妆', '4896': '场', '4897': '宪', '4898': '骇', '4899': '衣', '4900': '辍', '4901': '扪', '4902': '肿', '4903': '注', '4904': '烽', '4905': '残', '4906': '民', '4907': 'ょ', '4908': '化', '4909': '澜', '4910': '叔', '4911': '尼', '4912': '讠', '4913': '吏', '4914': '绡', '4915': '碑', '4916': '霏', '4917': '坚', '4918': '榜', '4919': '胥', '4920': '晒', '4921': '竞', '4922': '哩', '4923': '糊', '4924': '诋', '4925': '羊', '4926': '洙', '4927': '铸', '4928': '荀', '4929': '眄', '4930': '矛', '4931': '昂', '4932': '邮', '4933': '堂', '4934': '迤', '4935': '蝠', '4936': '谧', '4937': '痕', '4938': '磅', '4939': '拣', '4940': '冈', '4941': '餍', '4942': '蜕', '4943': '朝', '4944': '雨', '4945': '赶', '4946': '陆', '4947': '逢', '4948': '呕', '4949': '汶', '4950': '瘼', '4951': '熔', '4952': '芘', '4953': '烦', '4954': '滥', '4955': '哽', '4956': '箧', '4957': '稳', '4958': '徇', '4959': '鸺', '4960': '苻', '4961': '椅', '4962': '耦', '4963': '凉', '4964': '聒', '4965': '趋', '4966': '怊', '4967': '诚', '4968': '枋', '4969': '熙', '4970': '丘', '4971': '浣', '4972': '碣', '4973': '恻', '4974': '鹃', '4975': '腆', '4976': '貅', '4977': '镌', '4978': '灌', '4979': '骢', '4980': '徜', '4981': '周', '4982': '勇', '4983': '此', '4984': '瑜', '4985': '鬓', '4986': '兜', '4987': '香', '4988': '境', '4989': '拯', '4990': '誓', '4991': '睍', '4992': '忽', '4993': '缠', '4994': '森', '4995': '丐', '4996': '酝', '4997': '助', '4998': '棋', '4999': '骆', '5000': '久', '5001': '交', '5002': '卿', '5003': '疗', '5004': '缄', '5005': '顶', '5006': '蹀', '5007': '詹', '5008': '询', '5009': '陌', '5010': '篪', '5011': '喉', '5012': '亦', '5013': '讲', '5014': '笙', '5015': '祝', '5016': '巫', '5017': '外', '5018': '騕', '5019': '立', '5020': '瘐', '5021': '巧', '5022': '嫉', '5023': '蓐', '5024': '舐', '5025': '磊', '5026': '喝', '5027': '前', '5028': '锭', '5029': '彬', '5030': '勺', '5031': '苹', '5032': '托', '5033': '关', '5034': '轶', '5035': '偶', '5036': '者', '5037': '囿', '5038': '炊', '5039': '踉', '5040': '讥', '5041': '谔', '5042': '橛', '5043': '灰', '5044': '鬼', '5045': '格', '5046': '敲', '5047': '砌', '5048': '胚', '5049': '桧', '5050': '脚', '5051': '桃', '5052': '瑾', '5053': '镞', '5054': '负', '5055': '鼙', '5056': '斩', '5057': '偃', '5058': '唇', '5059': '姣', '5060': '跹', '5061': '债', '5062': '艰', '5063': '镫', '5064': '侗', '5065': '娠', '5066': '染', '5067': '怛', '5068': '坳', '5069': '唾', '5070': '粹', '5071': '骖', '5072': '盆', '5073': '族', '5074': '牵', '5075': '雅', '5076': '溅', '5077': '钱', '5078': '庇', '5079': '惕', '5080': '埭', '5081': '里', '5082': '汨', '5083': '酣', '5084': '脉', '5085': '鼹', '5086': '琢', '5087': '艋', '5088': '臣', '5089': '憎', '5090': '聱', '5091': '种', '5092': '驰', '5093': '蠃', '5094': '代', '5095': '叠', '5096': '邛', '5097': '卫', '5098': '绎', '5099': '陉', '5100': '氍', '5101': '拗', '5102': '梦', '5103': '市', '5104': '汪', '5105': 'Ｈ', '5106': '呆', '5107': '纱', '5108': '宵', '5109': '扩', '5110': '孔', '5111': '寤', '5112': '璀', '5113': '咫', '5114': '菱', '5115': '碍', '5116': '淮', '5117': '隆', '5118': '缣', '5119': '蘩', '5120': '倘', '5121': '辕', '5122': '劭', '5123': '垓', '5124': '“', '5125': '邴', '5126': '紧', '5127': '缓', '5128': '度', '5129': '髅', '5130': '翔', '5131': '苇', '5132': '筵', '5133': '憾', '5134': '歉', '5135': '仅', '5136': '榧', '5137': '岖', '5138': '椒', '5139': '咒', '5140': '铫', '5141': '椎', '5142': '炬', '5143': '漏', '5144': '募', '5145': '仞', '5146': '包', '5147': '霜', '5148': '奕', '5149': '叹', '5150': '兄', '5151': '刘', '5152': '替', '5153': '麸', '5154': '危', '5155': '贷', '5156': '悚', '5157': '扬', '5158': '穿', '5159': '画', '5160': '槐', '5161': '擢', '5162': '撮', '5163': '营', '5164': '跌', '5165': '浩', '5166': '裆', '5167': '擒', '5168': '蔬', '5169': '鳌', '5170': '锻', '5171': '庵', '5172': '谦', '5173': '舞', '5174': '芊', '5175': '鸢', '5176': '阀', '5177': '骸', '5178': '稻', '5179': '毒', '5180': '右', '5181': '迹', '5182': '帧', '5183': '□', '5184': '娘', '5185': '澄', '5186': '寺', '5187': '媒', '5188': '景', '5189': '取', '5190': '弩', '5191': '航', '5192': '捷', '5193': '廷', '5194': '貂', '5195': '埽', '5196': '勿', '5197': '署', '5198': '幅', '5199': '俏', '5200': '瑕', '5201': '福', '5202': '秤', '5203': '层', '5204': '蓿', '5205': '佚', '5206': '瞎', '5207': '氲', '5208': '畴', '5209': '痣', '5210': '偏', '5211': '坤', '5212': '渎', '5213': '眚', '5214': '芭', '5215': '柬', '5216': '循', '5217': '瞿', '5218': '旎', '5219': '芹', '5220': '担', '5221': '槊', '5222': '领', '5223': '辈', '5224': '畛', '5225': '岛', '5226': '躯', '5227': '姜', '5228': '变', '5229': '畋', '5230': '禅', '5231': '嫂', '5232': '稣', '5233': '标', '5234': '褚', '5235': '庐', '5236': '弄', '5237': '赞', '5238': '饵', '5239': '瀚', '5240': '上', '5241': '栖', '5242': '象', '5243': '狂', '5244': '勉', '5245': '熬', '5246': '莠', '5247': '质', '5248': '胪', '5249': '添', '5250': '掰', '5251': '忤', '5252': '驳', '5253': '苦', '5254': '蕴', '5255': '赈', '5256': '暇', '5257': '峄', '5258': '搴', '5259': '允', '5260': '股', '5261': '鸬', '5262': '琴', '5263': '讵', '5264': '裒', '5265': '佃', '5266': '霈', '5267': '韩', '5268': '禧', '5269': '畦', '5270': '啭', '5271': '浚', '5272': '坛', '5273': '慰', '5274': '荃', '5275': '闲', '5276': '漱', '5277': '禁', '5278': '耗', '5279': '跳', '5280': '馅', '5281': '澶', '5282': '眇', '5283': '应', '5284': '津', '5285': '朕', '5286': '逵', '5287': '磬', '5288': '概', '5289': '渐', '5290': '商', '5291': '姝', '5292': '啬', '5293': 'E', '5294': 'S', '5295': ' '}\n"
     ]
    }
   ],
   "source": [
    "print(word2id,id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=torch.load('E:\\\\AAA\\\\nlp\\\\AA_my_poem_generator\\\\songci\\\\tensor_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5295, 5295, 5295,  ..., 4224,  436, 5293],\n",
       "        [5295, 5295, 5295,  ..., 2763,  436, 5293],\n",
       "        [5295, 5295, 5295,  ..., 1251,  436, 5293],\n",
       "        ...,\n",
       "        [5295, 5295, 5295,  ...,  594,  436, 5293],\n",
       "        [5295, 5295, 5295,  ..., 4062,  436, 5293],\n",
       "        [5295, 5295, 5295,  ...,  379,  436, 5293]], dtype=torch.int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输出中间结果的测试代码\n",
    "def generate(model, start_words, ix2word, word2ix, prefix_words=None):\n",
    "    \n",
    "    results = list(start_words) #首先将结果置为list of start words\n",
    "    start_word_len = len(start_words)\n",
    "    input = t.Tensor([word2ix['S']]).view(1, 1).long() #第一个input为开始符号'S'\n",
    "    #if opt.use_gpu: input = input.cuda()\n",
    "    hidden = None #传入的hidden是None，在模型内部初始化为0\n",
    "\n",
    "    if prefix_words:\n",
    "        for word in prefix_words:\n",
    "            output, hidden = model(input, hidden)\n",
    "            input = input.data.new([word2id[word]]).view(1, 1)\n",
    "\n",
    "    for i in range(200):\n",
    "        output, hidden = model(input, hidden)\n",
    "\n",
    "        if i < start_word_len:\n",
    "            w = results[i]\n",
    "            input = input.data.new([word2id[w]]).view(1, 1)\n",
    "        else:\n",
    "            top_index = output.data[0].topk(1)[1][0].item()\n",
    "            w = id2word[str(top_index)]\n",
    "            results.append(w)\n",
    "            input = input.data.new([top_index]).view(1, 1)\n",
    "        if w == 'E':\n",
    "            del results[-1]\n",
    "            break\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class POEM(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
    "        super(POEM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.encoder = nn.Embedding(vocab_size, embedding_dim) # one hot representation to embedding dim\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,num_layers=2) #构造有两个隐层的LSTM\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.decoder = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        # 向前遍历，产生一系列的output，最后将output整合与target进行对比\n",
    "\n",
    "        seq_len, batch_size= input.size() #input是batch的形式\n",
    "        if hidden is None:\n",
    "            h = input.data.new(2, batch_size, self.hidden_dim).fill_(0).float()\n",
    "            c = input.data.new(2, batch_size, self.hidden_dim).fill_(0).float()\n",
    "        else:\n",
    "            h,c=hidden\n",
    "        encoded=self.encoder(input)\n",
    "        output, hidden =self.lstm(encoded, (h,c))\n",
    "\n",
    "        output=self.decoder(output.view(seq_len*batch_size, -1))\n",
    "        return output,hidden\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torchnet import meter\n",
    "\n",
    "def train(Epoch,data,word2id,id2word,index):\n",
    "\n",
    "\n",
    "    # 获取数据\n",
    "\n",
    "    dataloader = t.utils.data.DataLoader(data,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "    # 模型定义\n",
    "\n",
    "    model = POEM(len(word2id), embedding_dim, hidden_dim)\n",
    "    if index!=0:\n",
    "        model.load_state_dict(torch.load(model_path+'_'+str(index-1)+'.pth'))\n",
    "    optimizer = t.optim.Adam(model.parameters(), lr=0.0001)#lr:学习率\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss_meter = meter.AverageValueMeter()\n",
    "    for epoch in range(Epoch):\n",
    "        loss_meter.reset()\n",
    "        for ii, data_ in enumerate(dataloader):\n",
    "\n",
    "            # 训练\n",
    "            data_ = data_.long().transpose(1, 0).contiguous()\n",
    "            optimizer.zero_grad()\n",
    "            input_, target = data_[:-1, :], data_[1:, :]#target:y_train, 将整个序列右移\n",
    "\n",
    "            output, _ = model(input_)\n",
    "            print('input:',input_)\n",
    "            print('target:',target)\n",
    "            print('output:',output)\n",
    "            loss = criterion(output, target.view(-1))\n",
    "            print('loss:',loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_meter.add(loss.item())\n",
    "\n",
    "            # 打印诗歌\n",
    "            if (1 + ii) % 20 == 0:\n",
    "                # 诗歌原文\n",
    "                gen_poetries = []\n",
    "                # 分别以这几个字作为诗歌的第一个字，生成8首诗\n",
    "                for word in list(u'春江花月夜凉如水'):\n",
    "                    gen_poetry = ''.join(generate(model, word, id2word, word2id))\n",
    "                    gen_poetries.append(gen_poetry)\n",
    "                print(gen_poetries)\n",
    "\n",
    "        t.save(model.state_dict(), '%s_%s.pth' % (model_path, epoch+index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:10, 10.69s/it]\n",
      "2it [00:18,  9.88s/it]\n",
      "3it [00:26,  9.37s/it]\n",
      "4it [00:34,  9.00s/it]\n",
      "5it [00:43,  8.85s/it]\n",
      "6it [00:52,  8.77s/it]\n",
      "7it [01:00,  8.70s/it]\n",
      "8it [01:09,  8.66s/it]\n",
      "9it [01:17,  8.65s/it]\n",
      "10it [01:26,  8.63s/it]\n",
      "11it [01:34,  8.52s/it]\n",
      "12it [01:42,  8.42s/it]\n",
      "13it [01:50,  8.34s/it]\n",
      "14it [01:59,  8.36s/it]\n",
      "15it [02:07,  8.40s/it]\n",
      "16it [02:16,  8.40s/it]\n",
      "17it [02:24,  8.37s/it]\n",
      "18it [02:33,  8.51s/it]\n",
      "19it [02:42,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春                                                                                                                                                                                                       ', '江                                                                                                                                                                                                       ', '花                                                                                                                                                                                                       ', '月                                                                                                                                                                                                       ', '夜                                                                                                                                                                                                       ', '凉                                                                                                                                                                                                       ', '如                                                                                                                                                                                                       ', '水                                                                                                                                                                                                       ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "20it [02:51,  8.89s/it]\n",
      "21it [03:00,  8.76s/it]\n",
      "22it [03:09,  8.78s/it]\n",
      "23it [03:17,  8.70s/it]\n",
      "24it [03:26,  8.61s/it]\n",
      "25it [03:34,  8.62s/it]\n",
      "26it [03:43,  8.59s/it]\n",
      "27it [03:52,  8.70s/it]\n",
      "28it [04:00,  8.65s/it]\n",
      "29it [04:09,  8.66s/it]\n",
      "30it [04:17,  8.59s/it]\n",
      "31it [04:26,  8.57s/it]\n",
      "32it [04:34,  8.52s/it]\n",
      "33it [04:43,  8.53s/it]\n",
      "34it [04:51,  8.45s/it]\n",
      "35it [05:00,  8.62s/it]\n",
      "36it [05:09,  8.66s/it]\n",
      "37it [05:18,  8.69s/it]\n",
      "38it [05:27,  8.78s/it]\n",
      "39it [05:35,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春                                                                                                                                                                                                       ', '江。娈演嶢磕磕。万屹璞演磕。娴泸泸渥磕磕磕骂。娴渥跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '花                                                                                                                                                                                                       ', '月。万演蓄蓄蓄淞跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '夜。演娴磕渥磕万                                                                                                                                                                                                ', '凉                                                                                                                                                                                                       ', '如                                                                                                                                                                                                       ', '水                                                                                                                                                                                                       ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "40it [05:46,  9.19s/it]\n",
      "41it [05:55,  9.14s/it]\n",
      "42it [06:03,  9.05s/it]\n",
      "43it [06:12,  8.99s/it]\n",
      "44it [06:21,  8.95s/it]\n",
      "45it [06:30,  8.87s/it]\n",
      "46it [06:39,  8.85s/it]\n",
      "47it [06:48,  8.88s/it]\n",
      "48it [06:57,  8.90s/it]\n",
      "49it [07:06,  8.98s/it]\n",
      "50it [07:15,  8.95s/it]\n",
      "51it [07:23,  8.94s/it]\n",
      "52it [07:32,  8.88s/it]\n",
      "53it [07:41,  8.89s/it]\n",
      "54it [07:49,  8.72s/it]\n",
      "55it [07:58,  8.68s/it]\n",
      "56it [08:07,  8.66s/it]\n",
      "57it [08:16,  8.76s/it]\n",
      "58it [08:25,  8.88s/it]\n",
      "59it [08:33,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春                                                                                                                                                                                                       ', '江。娴辏裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕', '花。年辏娴裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕裕', '月。娴娴泸渥泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸', '夜演倜。泸娴泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸', '凉。佯娴跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '如                                                                                                                                                                                                       ', '水                                                                                                                                                                                                       ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "60it [08:44,  9.22s/it]\n",
      "61it [08:53,  9.14s/it]\n",
      "62it [09:02,  9.13s/it]\n",
      "63it [09:11,  9.14s/it]\n",
      "64it [09:20,  9.12s/it]\n",
      "65it [09:29,  9.19s/it]\n",
      "66it [09:38,  9.09s/it]\n",
      "67it [09:47,  9.08s/it]\n",
      "68it [09:57,  9.28s/it]\n",
      "69it [10:06,  9.22s/it]\n",
      "70it [10:16,  9.45s/it]\n",
      "71it [10:25,  9.37s/it]\n",
      "72it [10:34,  9.29s/it]\n",
      "73it [10:44,  9.33s/it]\n",
      "74it [10:53,  9.22s/it]\n",
      "75it [11:02,  9.15s/it]\n",
      "76it [11:11,  9.11s/it]\n",
      "77it [11:20,  9.28s/it]\n",
      "78it [11:31,  9.63s/it]\n",
      "79it [11:41,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。佯娴跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '江煨觫租泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸', '花。演娴跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '月租娴泸泸泸渥泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸', '夜演倜磕                                                                                                                                                                                                    ', '凉万。万演辏涝涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '如。演娴泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸泸', '水                                                                                                                                                                                                       ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "80it [11:52,  9.99s/it]\n",
      "81it [12:01,  9.68s/it]\n",
      "82it [12:09,  9.41s/it]\n",
      "83it [12:18,  9.34s/it]\n",
      "84it [12:27,  9.19s/it]\n",
      "85it [12:37,  9.22s/it]\n",
      "86it [12:46,  9.30s/it]\n",
      "87it [12:56,  9.43s/it]\n",
      "88it [13:05,  9.29s/it]\n",
      "89it [13:14,  9.24s/it]\n",
      "90it [13:23,  9.16s/it]\n",
      "91it [13:32,  9.06s/it]\n",
      "92it [13:40,  8.93s/it]\n",
      "93it [13:49,  8.88s/it]\n",
      "94it [13:58,  8.87s/it]\n",
      "95it [14:07,  8.86s/it]\n",
      "96it [14:16,  8.86s/it]\n",
      "97it [14:25,  9.03s/it]\n",
      "98it [14:34,  8.99s/it]\n",
      "99it [14:43,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。佯娴涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '江脏涝涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '花。娴涝涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '月淞泸泸泸洎扼。渥娴涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '夜脏涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '凉万                                                                                                                                                                                                      ', '如。演娴涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '水                                                                                                                                                                                                       ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100it [14:54,  9.56s/it]\n",
      "101it [15:03,  9.30s/it]\n",
      "102it [15:12,  9.20s/it]\n",
      "103it [15:21,  9.13s/it]\n",
      "104it [15:30,  9.07s/it]\n",
      "105it [15:38,  8.95s/it]\n",
      "106it [15:47,  8.96s/it]\n",
      "107it [15:57,  9.13s/it]\n",
      "108it [16:05,  8.94s/it]\n",
      "109it [16:14,  8.91s/it]\n",
      "110it [16:23,  8.80s/it]\n",
      "111it [16:31,  8.72s/it]\n",
      "112it [16:40,  8.71s/it]\n",
      "113it [16:48,  8.60s/it]\n",
      "114it [16:57,  8.54s/it]\n",
      "115it [17:05,  8.63s/it]\n",
      "116it [17:14,  8.58s/it]\n",
      "117it [17:23,  8.62s/it]\n",
      "118it [17:32,  8.98s/it]\n",
      "119it [17:43,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。佯娴涝涝涝涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '江脏涝涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '花绔烟。演娴涝涝涝涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '月淞泸磕。演娴涝涝涝涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '夜脏涝涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '凉倜                                                                                                                                                                                                      ', '如。演娴涝涝涝涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '水                                                                                                                                                                                                       ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "120it [17:53,  9.74s/it]\n",
      "121it [18:02,  9.57s/it]\n",
      "122it [18:12,  9.64s/it]\n",
      "123it [18:21,  9.35s/it]\n",
      "124it [18:30,  9.14s/it]\n",
      "125it [18:39,  9.25s/it]\n",
      "126it [18:48,  9.25s/it]\n",
      "127it [18:58,  9.29s/it]\n",
      "128it [19:07,  9.22s/it]\n",
      "129it [19:15,  9.01s/it]\n",
      "130it [19:24,  8.90s/it]\n",
      "131it [19:33,  8.83s/it]\n",
      "132it [19:41,  8.77s/it]\n",
      "133it [19:50,  8.77s/it]\n",
      "134it [19:58,  8.64s/it]\n",
      "135it [20:08,  8.80s/it]\n",
      "136it [20:16,  8.70s/it]\n",
      "137it [20:24,  8.61s/it]\n",
      "138it [20:33,  8.66s/it]\n",
      "139it [20:42,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。佯娴鳏涝涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '江脏涝涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '花绔绔。僽娴涝涝涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '月租泸涝泸泸泸泸泸扼月扼风蓄泸跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '夜涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '凉倜                                                                                                                                                                                                      ', '如。演娴涝涝涝涝跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣跣', '水                                                                                                                                                                                                       ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "140it [20:52,  9.06s/it]\n",
      "141it [21:00,  8.87s/it]\n",
      "142it [21:09,  8.79s/it]\n",
      "143it [21:18,  8.84s/it]\n",
      "144it [21:27,  8.90s/it]\n",
      "145it [21:36,  8.82s/it]\n",
      "146it [21:45,  8.97s/it]\n",
      "147it [21:54,  9.01s/it]\n",
      "148it [22:03,  8.92s/it]\n",
      "149it [22:12,  9.01s/it]\n",
      "150it [22:21,  9.09s/it]\n",
      "151it [22:31,  9.22s/it]\n",
      "152it [22:40,  9.25s/it]\n",
      "153it [22:49,  9.19s/it]\n",
      "154it [22:58,  9.23s/it]\n",
      "155it [23:08,  9.23s/it]\n",
      "156it [23:17,  9.15s/it]\n",
      "157it [23:22,  8.15s/it]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:10, 10.77s/it]\n",
      "2it [00:19, 10.19s/it]\n",
      "3it [00:28,  9.86s/it]\n",
      "4it [00:38,  9.74s/it]\n",
      "5it [00:47,  9.61s/it]\n",
      "6it [00:56,  9.47s/it]\n",
      "7it [01:05,  9.35s/it]\n",
      "8it [01:14,  9.27s/it]\n",
      "9it [01:23,  9.15s/it]\n",
      "10it [01:32,  8.99s/it]\n",
      "11it [01:41,  8.96s/it]\n",
      "12it [01:50,  9.06s/it]\n",
      "13it [01:59,  9.07s/it]\n",
      "14it [02:09,  9.34s/it]\n",
      "15it [02:19,  9.46s/it]\n",
      "16it [02:28,  9.44s/it]\n",
      "17it [02:37,  9.22s/it]\n",
      "18it [02:46,  9.18s/it]\n",
      "19it [02:56,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春烟。花演娴涝涝涝泸泸泸扼                                                                                                                                                                                           ', '江魉磕。不娴涝涝涝涝涝泸泸磕                                                                                                                                                                                          ', '花绔倜                                                                                                                                                                                                     ', '月倜。不娴鳏涝涝涝涝泸泸泸驮月月扼。花娴涝涝涝涝涝泸泸泸磕                                                                                                                                                                           ', '夜馡馡泸泸泸扼扼风不泸泸涝泸泸扼                                                                                                                                                                                        ', '凉倜                                                                                                                                                                                                      ', '如倜                                                                                                                                                                                                      ', '水                                                                                                                                                                                                       ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "20it [03:06,  9.59s/it]\n",
      "21it [03:14,  9.21s/it]\n",
      "22it [03:23,  9.07s/it]\n",
      "23it [03:32,  9.00s/it]\n",
      "24it [03:40,  8.92s/it]\n",
      "25it [03:49,  8.92s/it]\n",
      "26it [03:58,  8.81s/it]\n",
      "27it [04:07,  8.76s/it]\n",
      "28it [04:15,  8.73s/it]\n",
      "29it [04:24,  8.67s/it]\n",
      "30it [04:32,  8.67s/it]\n",
      "31it [04:41,  8.64s/it]\n",
      "32it [04:50,  8.78s/it]\n",
      "33it [04:59,  8.75s/it]\n",
      "34it [05:08,  8.82s/it]\n",
      "35it [05:16,  8.79s/it]\n",
      "36it [05:25,  8.74s/it]\n",
      "37it [05:34,  8.71s/it]\n",
      "38it [05:42,  8.64s/it]\n",
      "39it [05:51,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春烟。花演涝涝涝涝泸泸磕                                                                                                                                                                                            ', '江魉磕。不讳涝涝涝涝涝泸泸磕                                                                                                                                                                                          ', '花倜                                                                                                                                                                                                      ', '月魉倜                                                                                                                                                                                                     ', '夜涝涝泸泸泸泸扼月月隧。演讳涝涝涝涝涝泸泸磕                                                                                                                                                                                  ', '凉倜                                                                                                                                                                                                      ', '如倜                                                                                                                                                                                                      ', '水                                                                                                                                                                                                       ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "40it [06:01,  8.99s/it]\n",
      "41it [06:09,  8.87s/it]\n",
      "42it [06:18,  8.77s/it]\n",
      "43it [06:26,  8.67s/it]\n",
      "44it [06:35,  8.69s/it]\n",
      "45it [06:44,  8.88s/it]\n",
      "46it [06:54,  9.06s/it]\n",
      "47it [07:03,  9.22s/it]\n",
      "48it [07:12,  9.20s/it]\n",
      "49it [07:21,  9.10s/it]\n",
      "50it [07:30,  9.08s/it]\n",
      "51it [07:39,  9.02s/it]\n",
      "52it [07:48,  9.04s/it]\n",
      "53it [07:58,  9.21s/it]\n",
      "54it [08:07,  9.26s/it]\n",
      "55it [08:17,  9.39s/it]\n",
      "56it [08:26,  9.30s/it]\n",
      "57it [08:35,  9.23s/it]\n",
      "58it [08:44,  9.17s/it]\n",
      "59it [08:53,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春又倜。不演涝涝涝涝泸泸                                                                                                                                                                                            ', '江馡脏泸涝涝涝泸泸泸泸扼                                                                                                                                                                                            ', '花演。不演涝涝涝涝泸泸                                                                                                                                                                                             ', '月魉倜                                                                                                                                                                                                     ', '夜涝泸泸磕                                                                                                                                                                                                   ', '凉倜                                                                                                                                                                                                      ', '如倜                                                                                                                                                                                                      ', '水                                                                                                                                                                                                       ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "60it [09:04,  9.52s/it]\n",
      "61it [09:13,  9.48s/it]\n",
      "62it [09:22,  9.42s/it]\n",
      "63it [09:31,  9.34s/it]\n",
      "64it [09:40,  9.19s/it]\n",
      "65it [09:49,  9.08s/it]\n",
      "66it [09:59,  9.44s/it]\n",
      "67it [10:09,  9.35s/it]\n",
      "68it [10:18,  9.30s/it]\n",
      "69it [10:28,  9.60s/it]\n",
      "70it [10:38,  9.76s/it]\n",
      "71it [10:47,  9.60s/it]\n",
      "72it [10:57,  9.46s/it]\n",
      "73it [11:06,  9.34s/it]\n",
      "74it [11:15,  9.27s/it]\n",
      "75it [11:24,  9.14s/it]\n",
      "76it [11:33,  9.19s/it]\n",
      "77it [11:42,  9.16s/it]\n",
      "78it [11:51,  9.28s/it]\n",
      "79it [12:01,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春倜                                                                                                                                                                                                      ', '江馡脏泸涝涝泸泸泸泸扼                                                                                                                                                                                             ', '花演。不鳏涝涝涝涝滤泸泸                                                                                                                                                                                            ', '月魉倜                                                                                                                                                                                                     ', '夜涝泸泸磕                                                                                                                                                                                                   ', '凉倜                                                                                                                                                                                                      ', '如倜                                                                                                                                                                                                      ', '水                                                                                                                                                                                                       ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "80it [12:10,  9.41s/it]\n",
      "81it [12:19,  9.21s/it]\n",
      "82it [12:28,  9.04s/it]\n",
      "83it [12:36,  8.88s/it]\n",
      "84it [12:45,  8.95s/it]\n",
      "85it [12:55,  9.15s/it]\n",
      "86it [13:04,  9.11s/it]\n",
      "87it [13:13,  8.97s/it]\n",
      "88it [13:22,  8.95s/it]\n",
      "89it [13:30,  8.80s/it]\n",
      "90it [13:39,  8.73s/it]\n",
      "91it [13:47,  8.72s/it]\n",
      "92it [13:57,  8.86s/it]\n",
      "93it [14:05,  8.82s/it]\n",
      "94it [14:14,  8.74s/it]\n",
      "95it [14:22,  8.71s/it]\n",
      "96it [14:31,  8.67s/it]\n",
      "97it [14:40,  8.65s/it]\n",
      "98it [14:48,  8.63s/it]\n",
      "99it [14:57,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春倜                                                                                                                                                                                                      ', '江涝泸泸泸扼                                                                                                                                                                                                  ', '花演。一演鳏涝涝涝滤泸磕                                                                                                                                                                                            ', '月瘼绔扼。一演鳏涝涝涝滤泸磕                                                                                                                                                                                          ', '夜涝涝泸泸泸泸扼                                                                                                                                                                                                ', '凉倜                                                                                                                                                                                                      ', '如倜                                                                                                                                                                                                      ', '水。不演鳏涝涝涝涝泸磕                                                                                                                                                                                             ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100it [15:06,  8.92s/it]\n",
      "101it [15:15,  8.75s/it]\n",
      "102it [15:23,  8.65s/it]\n",
      "103it [15:32,  8.61s/it]\n",
      "104it [15:40,  8.65s/it]\n",
      "105it [15:49,  8.61s/it]\n",
      "106it [15:58,  8.66s/it]\n",
      "107it [16:07,  8.73s/it]\n",
      "108it [16:15,  8.66s/it]\n",
      "109it [16:24,  8.66s/it]\n",
      "110it [16:32,  8.66s/it]\n",
      "111it [16:41,  8.71s/it]\n",
      "112it [16:50,  8.70s/it]\n",
      "113it [16:59,  8.73s/it]\n",
      "114it [17:08,  8.77s/it]\n",
      "115it [17:17,  9.01s/it]\n",
      "116it [17:26,  9.05s/it]\n",
      "117it [17:35,  8.92s/it]\n",
      "118it [17:44,  8.88s/it]\n",
      "119it [17:52,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春晏。一鳏涝涝涝涝滤泸惫                                                                                                                                                                                            ', '江涝泸泸泸扼                                                                                                                                                                                                  ', '花演。不教鳏涝涝涝滤脏绔亚                                                                                                                                                                                           ', '月魉倜                                                                                                                                                                                                     ', '夜涝脏涝涝涝涝涝涝泸泸泸磕                                                                                                                                                                                           ', '凉倜                                                                                                                                                                                                      ', '如倜                                                                                                                                                                                                      ', '水。不教鳏涝涝涝滤脏绔亚                                                                                                                                                                                            ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "120it [18:02,  9.11s/it]\n",
      "121it [18:11,  8.94s/it]\n",
      "122it [18:19,  8.81s/it]\n",
      "123it [18:28,  8.76s/it]\n",
      "124it [18:37,  8.78s/it]\n",
      "125it [18:46,  8.98s/it]\n",
      "126it [18:55,  8.93s/it]\n",
      "127it [19:04,  8.95s/it]\n",
      "128it [19:14,  9.13s/it]\n",
      "129it [19:22,  8.93s/it]\n",
      "130it [19:31,  8.98s/it]\n",
      "131it [19:40,  8.89s/it]\n",
      "132it [19:49,  8.93s/it]\n",
      "133it [19:58,  8.89s/it]\n",
      "134it [20:07,  8.98s/it]\n",
      "135it [20:17,  9.32s/it]\n",
      "136it [20:26,  9.32s/it]\n",
      "137it [20:35,  9.29s/it]\n",
      "138it [20:45,  9.40s/it]\n",
      "139it [20:54,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。一鳏鳏涝涝涝涝泸{                                                                                                                                                                                             ', '江涝泸泸脏泸涝涝涝涝涝涝涝涝涝涝泸泸泸磕                                                                                                                                                                                    ', '花演                                                                                                                                                                                                      ', '月倜。恐鳏涝涝涝涝涝泸{                                                                                                                                                                                            ', '夜涝涝泸泸泸泸扼                                                                                                                                                                                                ', '凉倜                                                                                                                                                                                                      ', '如倜                                                                                                                                                                                                      ', '水。一教鳏涝涝涝涝泸{                                                                                                                                                                                             ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "140it [21:05,  9.68s/it]\n",
      "141it [21:14,  9.60s/it]\n",
      "142it [21:23,  9.47s/it]\n",
      "143it [21:33,  9.42s/it]\n",
      "144it [21:42,  9.25s/it]\n",
      "145it [21:50,  9.16s/it]\n",
      "146it [22:00,  9.13s/it]\n",
      "147it [22:09,  9.24s/it]\n",
      "148it [22:19,  9.35s/it]\n",
      "149it [22:28,  9.33s/it]\n",
      "150it [22:37,  9.38s/it]\n",
      "151it [22:46,  9.19s/it]\n",
      "152it [22:55,  9.16s/it]\n",
      "153it [23:05,  9.31s/it]\n",
      "154it [23:15,  9.53s/it]\n",
      "155it [23:24,  9.45s/it]\n",
      "156it [23:33,  9.37s/it]\n",
      "157it [23:39,  8.31s/it]\n"
     ]
    }
   ],
   "source": [
    "train(2,data,word2id,id2word,0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [02:43,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。一一一人、一人人。', '江教不不不人人。', '花事。', '月倜                                                                                                                                                                                                      ', '夜演。', '凉。一一一人人、人人。', '如谁                                                                                                                                                                                                      ', '水                                                                                                                                                                                                       ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [05:38,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。一一一人、一人、一人、一人。', '江教不不不人、一人、一人、一人。', '花。一一一不人、一人、一人。', '月晏。一一一不人、一人、一人。', '夜教。一一一不人、一人、一人。', '凉。', '如谁                                                                                                                                                                                                      ', '水。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [08:36,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。一一一人、一人人。', '江谁人。', '花。一一一人、一人人。', '月妨                                                                                                                                                                                                      ', '夜谁。一一一人、一人人。', '凉。', '如谁。', '水。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [11:48, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。一一一人、一人人。', '江谁人。', '花。一一一人、一人人。', '月，一一一一人。', '夜谁。一一一人、一人人。', '凉。', '如谁。', '水。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [15:04,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。一一一人、一人人。', '江谁人。', '花。一一一一人、一人人。', '月，一一一一人、一人。', '夜谁。一一一人、一人人。', '凉。', '如谁。', '水。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119it [1:09:11, 13.37s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。', '江谁人。', '花。一一一人、一人人。', '月，一一一教人。', '夜妨。', '凉。', '如谁。', '水。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [1:12:10,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。', '江谁人。', '花。一一教人、一人人。', '月，一一一教、一人人。', '夜妨。', '凉。', '如谁。', '水。一是一人、一人人。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [1:14:49,  8.13s/it]\n",
      "19it [02:52,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。', '江教更谁人。', '花笑。', '月，一教一教人。', '夜妨。', '凉。', '如谁。', '水。一是一人、一人人。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [05:50,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。', '江妨。', '花笑。', '月淞，不教一人、一是人。', '夜妨。', '凉。', '如笑。', '水。一是一人、一是一人。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [08:47,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。', '江妨间                                                                                                                                                                                                     ', '花。一教番花、一人不知。', '月坤，一是一人、一是人间。', '夜妨。', '凉。', '如笑。', '水，一是一人、一人风。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [11:49,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。', '江番。', '花笑。', '月坤，一是一番、一人如。', '夜时。', '凉。', '如笑。', '水，一番花花人。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [14:53,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。', '江番雨                                                                                                                                                                                                     ', '花笑。', '月坤，一番花花人。', '夜时。', '凉。', '如笑。', '水风。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119it [17:57,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。', '江楼，不是是人间。', '花悴。', '月花，不是是人间。', '夜时。', '凉。', '如笑。', '水花。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [21:02,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。', '江楼，一番花番、一番风。', '花悴。', '月、一番花枝。', '夜时。', '凉。', '如笑。', '水山。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [23:48,  8.37s/it]\n",
      "19it [03:00,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。', '江山。', '花悴。', '月花，不是是人间。', '夜谁知。', '凉。', '如许                                                                                                                                                                                                      ', '水，一番花番、一点春风。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [06:05,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。', '江山月，一点花花、一点春风。', '花悴。', '月花，不是是人间。', '夜风雨                                                                                                                                                                                                     ', '凉。', '如许                                                                                                                                                                                                      ', '水，一番花番、一点花花。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [09:26, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春去                                                                                                                                                                                                      ', '江山月，一点花花、一点春风。', '花悴。', '月花，不妨妨、一番风流。', '夜风雨                                                                                                                                                                                                     ', '凉。', '如许                                                                                                                                                                                                      ', '水，一番花番、一番风。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [12:47, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春。', '江山月，一点花枝、一点春风。', '花悴。', '月花前。', '夜花悴。', '凉悴。', '如许                                                                                                                                                                                                      ', '水，一番花番、一点春风。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [16:08,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春色。', '江山月。', '花悴。', '月勤。', '夜花悴。', '凉悴。', '如许                                                                                                                                                                                                      ', '水，一番花前、一番风。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119it [19:23, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春暮                                                                                                                                                                                                      ', '江南悴。', '花悴。', '月花前。', '夜花悴。', '凉悴。', '如许                                                                                                                                                                                                      ', '水，一番花前、一番风雨。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [22:35,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春色。', '江南悴。', '花悴。', '月下，一番花前、一番风雨。', '夜花悴。', '凉悴。', '如许                                                                                                                                                                                                      ', '水，一番花前、一番风雨。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [25:15,  8.03s/it]\n",
      "19it [02:54,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春色。', '江南悴。', '花悴。', '月下，一番花前、一点春风。', '夜旧时                                                                                                                                                                                                     ', '凉悴。', '如许                                                                                                                                                                                                      ', '水，一番花前、一点春风。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [05:54,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春色。', '江南悴。', '花悴。', '月下，一番花前、一番风雨。', '夜旧时                                                                                                                                                                                                     ', '凉悴。', '如缈                                                                                                                                                                                                      ', '水，一番花前、一番风雨。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [08:58,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春暮                                                                                                                                                                                                      ', '江南北。', '花悴。', '月下，一番花前许。', '夜旧时                                                                                                                                                                                                     ', '凉悴。', '如缈                                                                                                                                                                                                      ', '水，一番花前、一番风雨。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [11:59,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春色。', '江莱悴。', '花悴。', '月下，一番花前许。', '夜旧时                                                                                                                                                                                                     ', '凉悴。', '如许。', '水，一番花前许。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [14:51,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春色。', '江莱悴。', '花悴。', '月下，一番花、一番春去。', '夜蓉深。', '凉悴。', '如缈                                                                                                                                                                                                      ', '水，一番花、一番春去。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119it [17:45,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春暮                                                                                                                                                                                                      ', '江莱悴。', '花悴。', '月下，不妨妨是，一番风雨。', '夜蓉草。', '凉悴。', '如许。', '水，不妨妨是，一番风雨。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [20:38,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花悴。', '月下，一番花、一点春风。', '夜蓉草。', '凉悴。', '如缈                                                                                                                                                                                                      ', '水，一番花、一点春风。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [23:14,  8.14s/it]\n",
      "19it [02:56,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花悴。', '月下，一番花、一点春风。', '夜蓉草。', '凉悴。', '如缈                                                                                                                                                                                                      ', '水，一逦人间，一笑无人。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [05:55,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花悴。', '月下，一番花下、一番春去。', '夜雨。', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一逦人间，一笑无人。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [09:04,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花悴。', '月下，一番花下、一番春色。', '夜蓉雨。', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一逦时时节。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [12:07,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花悴。', '月下，一番花下、一枝春色。', '夜蓉雨。', '凉岛。', '如缈                                                                                                                                                                                                      ', '水晶台月，一枝风月，一枝千里。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [15:09,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花悴。', '月下，一番花、一点春风。', '夜蓉雨。', '凉岛。', '如缈                                                                                                                                                                                                      ', '水晶台月，一枝风月，一夜风流。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119it [18:18,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花悴。', '月下，一番花开酒。', '夜蓉雨。', '凉岛。', '如缈                                                                                                                                                                                                      ', '水晶台月，一枝风月，一夜风流。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [21:22,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花悴。', '月下，一番花、一点春风。', '夜蓉雨。', '凉岛。', '如缈                                                                                                                                                                                                      ', '水晶台月，一枝花下，一片春风。']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [23:58,  8.12s/it]\n"
     ]
    }
   ],
   "source": [
    "train(5,data,word2id,id2word,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3578, 4866, 3331,  ..., 5138, 5183,  422],\n",
      "        [4096, 3563,  754,  ..., 1505, 5183, 3547],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4096, 3563,  754,  ..., 1505, 5183, 3547],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4633, -4.0425, -3.8949,  ..., -5.4169,  6.0162, 12.9514],\n",
      "        [-2.4633, -4.0425, -3.8949,  ..., -5.4169,  6.0162, 12.9514],\n",
      "        [-2.4633, -4.0425, -3.8949,  ..., -5.4169,  6.0162, 12.9514],\n",
      "        ...,\n",
      "        [-4.2152, -3.8265, -4.3285,  ..., 10.3279, -2.2930, -2.5068],\n",
      "        [-5.1368, -5.3473, -5.4678,  ...,  8.6233, -0.3787, -0.2263],\n",
      "        [-4.5735, -3.7406, -4.5269,  ..., 11.4298, -3.1605, -2.8654]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8874, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3500, 1309, 2991,  ..., 1540, 1216,  508],\n",
      "        [4470, 4895, 3500,  ..., 3090,  298, 3634],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4470, 4895, 3500,  ..., 3090,  298, 3634],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4700, -4.0485, -3.9015,  ..., -5.4300,  6.0038, 12.9718],\n",
      "        [-2.4700, -4.0485, -3.9015,  ..., -5.4300,  6.0038, 12.9718],\n",
      "        [-2.4700, -4.0485, -3.9015,  ..., -5.4300,  6.0038, 12.9718],\n",
      "        ...,\n",
      "        [-3.9122, -3.8212, -5.3824,  ...,  8.6645, -3.0715, -3.0341],\n",
      "        [-3.9787, -4.3267, -5.5402,  ...,  8.8490, -3.2001, -3.3660],\n",
      "        [-3.6088, -3.5265, -4.7162,  ...,  8.5826, -3.2875, -3.1969]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9100, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1362,  337, 1912,  ...,    4, 2732,    4],\n",
      "        [3942, 4890, 4559,  ...,  970, 3279, 2405],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3942, 4890, 4559,  ...,  970, 3279, 2405],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4770, -4.0479, -3.9054,  ..., -5.4246,  6.0016, 12.9718],\n",
      "        [-2.4770, -4.0479, -3.9054,  ..., -5.4246,  6.0016, 12.9718],\n",
      "        [-2.4770, -4.0479, -3.9054,  ..., -5.4246,  6.0016, 12.9718],\n",
      "        ...,\n",
      "        [-3.8688, -4.0150, -5.7625,  ...,  9.3847, -2.6773, -2.7617],\n",
      "        [-4.2434, -4.7046, -6.0510,  ..., 11.4549, -2.7372, -2.7973],\n",
      "        [-4.4435, -3.7186, -4.5201,  ...,  9.6576, -2.0782, -1.9505]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8374, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 861, 1452, 4998,  ..., 1398, 2629, 1010],\n",
      "        [2181,  964, 3874,  ..., 1163, 3525,  120],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2181,  964, 3874,  ..., 1163, 3525,  120],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4837, -4.0461, -3.9092,  ..., -5.4184,  5.9975, 12.9731],\n",
      "        [-2.4837, -4.0461, -3.9092,  ..., -5.4184,  5.9975, 12.9731],\n",
      "        [-2.4837, -4.0461, -3.9092,  ..., -5.4184,  5.9975, 12.9731],\n",
      "        ...,\n",
      "        [-4.1928, -3.5521, -4.9678,  ...,  8.0290, -3.3312, -3.4824],\n",
      "        [-4.3787, -3.6710, -4.5806,  ..., 11.6710, -2.1277, -1.8254],\n",
      "        [-4.0451, -3.8765, -4.9213,  ...,  9.5797, -3.1606, -3.2344]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9001, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 843, 1326, 3665,  ..., 3428, 1010, 3382],\n",
      "        [1638, 5149, 2546,  ...,  509,  843,  639],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1638, 5149, 2546,  ...,  509,  843,  639],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4904, -4.0458, -3.9133,  ..., -5.4139,  5.9918, 12.9771],\n",
      "        [-2.4904, -4.0458, -3.9133,  ..., -5.4139,  5.9918, 12.9771],\n",
      "        [-2.4904, -4.0458, -3.9133,  ..., -5.4139,  5.9918, 12.9771],\n",
      "        ...,\n",
      "        [-4.0534, -3.8069, -4.9217,  ...,  9.6087, -2.9117, -3.3345],\n",
      "        [-4.5304, -3.5717, -4.7613,  ..., 10.3084, -2.6796, -2.6099],\n",
      "        [-4.5249, -3.7088, -5.1050,  ..., 10.9265, -2.5519, -2.5806]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9551, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 852, 4265, 4987,  ..., 1086,  965, 5295],\n",
      "        [2873, 2127, 4052,  ..., 1282,  745, 5295],\n",
      "        [ 436,  436,  436,  ...,  436,  436, 5294]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2873, 2127, 4052,  ..., 1282,  745, 5295],\n",
      "        [ 436,  436,  436,  ...,  436,  436, 5294],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4972, -4.0424, -3.9181,  ..., -5.4129,  5.9838, 12.9856],\n",
      "        [-2.4972, -4.0424, -3.9181,  ..., -5.4129,  5.9838, 12.9856],\n",
      "        [-2.4972, -4.0424, -3.9181,  ..., -5.4129,  5.9838, 12.9856],\n",
      "        ...,\n",
      "        [-4.1662, -3.8294, -5.6980,  ..., 11.3652, -3.1843, -3.1466],\n",
      "        [-4.5344, -3.5021, -4.4221,  ..., 11.4261, -2.4433, -2.2902],\n",
      "        [-3.2495, -3.9952, -5.8983,  ...,  7.6691, -0.0842, -0.0545]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8139, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1086, 3770,  321,  ..., 4265,   43,  816],\n",
      "        [1158,   71, 1115,  ..., 2127,  785, 4017],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1158,   71, 1115,  ..., 2127,  785, 4017],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4983, -4.0403, -3.9236,  ..., -5.4154,  5.9746, 12.9972],\n",
      "        [-2.4983, -4.0403, -3.9236,  ..., -5.4154,  5.9746, 12.9972],\n",
      "        [-2.4983, -4.0403, -3.9236,  ..., -5.4154,  5.9746, 12.9972],\n",
      "        ...,\n",
      "        [-4.0368, -4.1868, -5.3122,  ...,  9.6596, -2.5981, -2.7607],\n",
      "        [-4.2475, -3.7110, -5.1502,  ..., 10.5759, -2.2036, -2.2799],\n",
      "        [-4.2621, -4.4400, -5.3555,  ..., 11.2047, -3.0180, -3.1028]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8206, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2210, 4825,  366,  ..., 3990, 5295, 5151],\n",
      "        [1452, 1240,  249,  ..., 3667, 5295, 3695],\n",
      "        [ 436,  436,  436,  ...,  436, 5294,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1452, 1240,  249,  ..., 3667, 5295, 3695],\n",
      "        [ 436,  436,  436,  ...,  436, 5294,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5002, -4.0392, -3.9297,  ..., -5.4187,  5.9653, 13.0100],\n",
      "        [-2.5002, -4.0392, -3.9297,  ..., -5.4187,  5.9653, 13.0100],\n",
      "        [-2.5002, -4.0392, -3.9297,  ..., -5.4187,  5.9653, 13.0100],\n",
      "        ...,\n",
      "        [-4.8701, -4.2019, -4.6208,  ..., 11.0199, -2.1512, -2.1344],\n",
      "        [-3.2401, -3.9904, -5.8824,  ...,  7.5515, -0.0996, -0.0479],\n",
      "        [-3.9483, -3.8014, -4.5397,  ...,  8.0315, -3.1186, -3.3773]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8720, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 792, 1054, 2093,  ..., 4091, 2433, 1452],\n",
      "        [2624, 4145, 2164,  ..., 1693, 1286, 4944],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2624, 4145, 2164,  ..., 1693, 1286, 4944],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4983, -4.0365, -3.9355,  ..., -5.4214,  5.9595, 13.0189],\n",
      "        [-2.4983, -4.0365, -3.9355,  ..., -5.4214,  5.9595, 13.0189],\n",
      "        [-2.4983, -4.0365, -3.9355,  ..., -5.4214,  5.9595, 13.0189],\n",
      "        ...,\n",
      "        [-3.8462, -3.7087, -5.2654,  ...,  9.9410, -2.8931, -2.5977],\n",
      "        [-4.3049, -3.2909, -4.3548,  ..., 10.7689, -2.8458, -2.4772],\n",
      "        [-3.7872, -4.1598, -5.3896,  ...,  8.8323, -2.9572, -2.7714]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9188, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1579, 5146, 3113,  ..., 4166, 4753, 5021],\n",
      "        [1358,  421, 2844,  ..., 1705, 1584, 5270],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1358,  421, 2844,  ..., 1705, 1584, 5270],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4968, -4.0330, -3.9408,  ..., -5.4223,  5.9583, 13.0219],\n",
      "        [-2.4968, -4.0330, -3.9408,  ..., -5.4223,  5.9583, 13.0219],\n",
      "        [-2.4968, -4.0330, -3.9408,  ..., -5.4223,  5.9583, 13.0219],\n",
      "        ...,\n",
      "        [-4.3113, -3.9791, -5.3405,  ..., 10.9778, -3.0026, -2.9784],\n",
      "        [-4.6362, -3.7557, -4.7241,  ..., 10.8394, -2.5924, -2.1392],\n",
      "        [-3.5703, -3.8850, -5.3725,  ...,  8.4309, -3.0080, -3.1485]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8155, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2064, 4491, 3933,  ..., 3331, 4526, 1309],\n",
      "        [  75, 1698, 4493,  ..., 1452,  379, 2197],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  75, 1698, 4493,  ..., 1452,  379, 2197],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4958, -4.0300, -3.9458,  ..., -5.4214,  5.9588, 13.0222],\n",
      "        [-2.4958, -4.0300, -3.9458,  ..., -5.4214,  5.9588, 13.0222],\n",
      "        [-2.4958, -4.0300, -3.9458,  ..., -5.4214,  5.9588, 13.0222],\n",
      "        ...,\n",
      "        [-3.8950, -4.0860, -5.2788,  ..., 10.4755, -2.4324, -2.7197],\n",
      "        [-3.9023, -4.4564, -5.3745,  ...,  9.5367, -2.3621, -2.2744],\n",
      "        [-4.1060, -3.7630, -5.2499,  ...,  9.2858, -2.3504, -2.4701]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9813, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4899,  996,  785,  ..., 1309,  466, 4031],\n",
      "        [3505, 1358,  572,  ..., 1323, 2773, 4441],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3505, 1358,  572,  ..., 1323, 2773, 4441],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4954, -4.0275, -3.9507,  ..., -5.4198,  5.9617, 13.0193],\n",
      "        [-2.4954, -4.0275, -3.9507,  ..., -5.4198,  5.9617, 13.0193],\n",
      "        [-2.4954, -4.0275, -3.9507,  ..., -5.4198,  5.9617, 13.0193],\n",
      "        ...,\n",
      "        [-3.7846, -3.4067, -4.9674,  ...,  9.2766, -2.7203, -2.6619],\n",
      "        [-3.7971, -3.9040, -5.4527,  ..., 10.3662, -3.1486, -3.2651],\n",
      "        [-3.9474, -3.6499, -4.0337,  ...,  8.5565, -2.1634, -2.1270]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8842, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2417, 2200, 3331,  ..., 4470, 2979, 2080],\n",
      "        [3022, 2711, 1192,  ..., 3046, 3256, 3087],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3022, 2711, 1192,  ..., 3046, 3256, 3087],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4941, -4.0255, -3.9500,  ..., -5.4186,  5.9652, 13.0158],\n",
      "        [-2.4941, -4.0255, -3.9500,  ..., -5.4186,  5.9652, 13.0158],\n",
      "        [-2.4941, -4.0255, -3.9500,  ..., -5.4186,  5.9652, 13.0158],\n",
      "        ...,\n",
      "        [-4.2455, -4.5610, -5.8803,  ..., 11.5947, -2.8442, -2.7133],\n",
      "        [-3.9231, -3.8430, -5.3281,  ...,  9.8032, -2.9002, -2.8082],\n",
      "        [-3.8078, -3.8016, -5.2644,  ...,  9.3381, -3.0261, -3.1233]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8943, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2369,  366, 1194,  ..., 3563, 4746,  639],\n",
      "        [2089, 1166,  509,  ..., 3898,  321, 3030],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2089, 1166,  509,  ..., 3898,  321, 3030],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4933, -4.0239, -3.9499,  ..., -5.4185,  5.9678, 13.0134],\n",
      "        [-2.4933, -4.0239, -3.9499,  ..., -5.4185,  5.9678, 13.0134],\n",
      "        [-2.4933, -4.0239, -3.9499,  ..., -5.4185,  5.9678, 13.0134],\n",
      "        ...,\n",
      "        [-4.3671, -3.3804, -4.5718,  ..., 11.6374, -2.7843, -2.4315],\n",
      "        [-4.2604, -4.0467, -5.2429,  ..., 10.6871, -2.9189, -2.9956],\n",
      "        [-4.2876, -4.0696, -5.5036,  ..., 10.8413, -2.3407, -2.2411]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8668, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3010, 4716, 1947,  ...,  948, 4987, 1271],\n",
      "        [3557, 1474,  321,  ..., 3480, 3279, 3077],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3557, 1474,  321,  ..., 3480, 3279, 3077],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4929, -4.0228, -3.9504,  ..., -5.4202,  5.9696, 13.0120],\n",
      "        [-2.4929, -4.0228, -3.9504,  ..., -5.4202,  5.9696, 13.0120],\n",
      "        [-2.4929, -4.0228, -3.9504,  ..., -5.4202,  5.9696, 13.0120],\n",
      "        ...,\n",
      "        [-4.2668, -3.8407, -4.7211,  ..., 10.2608, -2.8087, -3.0722],\n",
      "        [-4.1099, -3.8398, -5.5952,  ..., 10.8725, -2.3239, -2.5197],\n",
      "        [-4.4985, -4.1125, -5.4183,  ..., 11.2178, -3.1766, -3.1341]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8624, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1010, 1015, 2057,  ..., 5051, 3210, 2349],\n",
      "        [3547,  548, 3667,  ..., 3951, 1916, 3575],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3547,  548, 3667,  ..., 3951, 1916, 3575],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4928, -4.0221, -3.9514,  ..., -5.4232,  5.9708, 13.0119],\n",
      "        [-2.4928, -4.0221, -3.9514,  ..., -5.4232,  5.9708, 13.0119],\n",
      "        [-2.4928, -4.0221, -3.9514,  ..., -5.4232,  5.9708, 13.0119],\n",
      "        ...,\n",
      "        [-3.8804, -3.8628, -5.3803,  ...,  9.4900, -3.0855, -3.0063],\n",
      "        [-4.1526, -3.9861, -5.9396,  ...,  9.7077, -2.8549, -2.8586],\n",
      "        [-4.2504, -3.7308, -5.5438,  ..., 10.4701, -2.4886, -2.5372]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0063, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 468, 2227,  738,  ..., 4516, 2249,  874],\n",
      "        [ 321, 1980, 5000,  ..., 1055, 5015, 3665],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 321, 1980, 5000,  ..., 1055, 5015, 3665],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4933, -4.0219, -3.9529,  ..., -5.4260,  5.9725, 13.0117],\n",
      "        [-2.4933, -4.0219, -3.9529,  ..., -5.4260,  5.9725, 13.0117],\n",
      "        [-2.4933, -4.0219, -3.9529,  ..., -5.4260,  5.9725, 13.0117],\n",
      "        ...,\n",
      "        [-4.1199, -4.2450, -5.3149,  ..., 10.9313, -2.8772, -3.1868],\n",
      "        [-3.8290, -3.7178, -5.0582,  ...,  8.7882, -3.2761, -3.1471],\n",
      "        [-4.4411, -3.5973, -4.9507,  ..., 11.2486, -3.0122, -2.8870]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7542, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4526, 1452, 2152,  ..., 3818, 3933, 4944],\n",
      "        [1693, 4679,  277,  ..., 4944, 1010, 2058],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1693, 4679,  277,  ..., 4944, 1010, 2058],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4926, -4.0219, -3.9546,  ..., -5.4289,  5.9726, 13.0127],\n",
      "        [-2.4926, -4.0219, -3.9546,  ..., -5.4289,  5.9726, 13.0127],\n",
      "        [-2.4926, -4.0219, -3.9546,  ..., -5.4289,  5.9726, 13.0127],\n",
      "        ...,\n",
      "        [-4.2602, -3.8311, -5.1165,  ...,  9.9711, -2.8647, -2.6790],\n",
      "        [-4.5491, -3.7729, -4.9503,  ..., 11.4217, -3.0413, -2.7393],\n",
      "        [-3.9363, -4.1682, -5.7737,  ..., 10.7258, -2.7815, -2.8943]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9072, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3382, 4294, 3687,  ..., 2378,  341,  593],\n",
      "        [1192, 2629, 3988,  ..., 2951,  843, 4346],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1192, 2629, 3988,  ..., 2951,  843, 4346],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4923, -4.0222, -3.9562,  ..., -5.4307,  5.9745, 13.0112],\n",
      "        [-2.4923, -4.0222, -3.9562,  ..., -5.4307,  5.9745, 13.0112],\n",
      "        [-2.4923, -4.0222, -3.9562,  ..., -5.4307,  5.9745, 13.0112],\n",
      "        ...,\n",
      "        [-4.2036, -4.4660, -4.9701,  ...,  8.1174, -3.1294, -3.3744],\n",
      "        [-4.7660, -3.9362, -4.8228,  ..., 10.7668, -2.9935, -2.7183],\n",
      "        [-3.9970, -3.8377, -5.3117,  ..., 10.7681, -2.9876, -2.9271]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7718, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3542, 2979, 4265,  ..., 2313, 5000, 2915],\n",
      "        [4937, 3030, 4944,  ...,  964, 2503, 4467],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4937, 3030, 4944,  ...,  964, 2503, 4467],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4923, -4.0226, -3.9579,  ..., -5.4317,  5.9757, 13.0100],\n",
      "        [-2.4923, -4.0226, -3.9579,  ..., -5.4317,  5.9757, 13.0100],\n",
      "        [-2.4923, -4.0226, -3.9579,  ..., -5.4317,  5.9757, 13.0100],\n",
      "        ...,\n",
      "        [-3.6054, -3.8919, -5.3282,  ..., 10.2752, -2.8530, -2.9987],\n",
      "        [-4.6232, -4.2192, -4.8065,  ..., 10.6219, -2.0480, -2.0667],\n",
      "        [-3.8172, -3.6628, -5.5317,  ..., 10.2429, -3.0368, -3.3315]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8755, grad_fn=<NllLossBackward>)\n",
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花李。', '月下，一番花、一点春风。', '夜蓉雨。', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番花开酒。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4265, 5262,  639,  ...,  996,    4, 5295],\n",
      "        [ 825, 2602,  745,  ...,  745, 1579, 5295],\n",
      "        [ 436,  436,  436,  ...,  436,  436, 5294]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 825, 2602,  745,  ...,  745, 1579, 5295],\n",
      "        [ 436,  436,  436,  ...,  436,  436, 5294],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4928, -4.0231, -3.9596,  ..., -5.4307,  5.9760, 13.0092],\n",
      "        [-2.4928, -4.0231, -3.9596,  ..., -5.4307,  5.9760, 13.0092],\n",
      "        [-2.4928, -4.0231, -3.9596,  ..., -5.4307,  5.9760, 13.0092],\n",
      "        ...,\n",
      "        [-4.1801, -3.9154, -5.5791,  ...,  9.9892, -2.9148, -3.1261],\n",
      "        [-4.5694, -4.0689, -5.4433,  ..., 10.4127, -2.5733, -2.5484],\n",
      "        [-3.2506, -3.9641, -5.8945,  ...,  7.5697, -0.1013, -0.0676]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8914, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2792,  740, 1395,  ..., 2745, 4087, 4204],\n",
      "        [3997, 4737, 5253,  ..., 2964,  411, 3087],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3997, 4737, 5253,  ..., 2964,  411, 3087],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4935, -4.0239, -3.9613,  ..., -5.4296,  5.9760, 13.0085],\n",
      "        [-2.4935, -4.0239, -3.9613,  ..., -5.4296,  5.9760, 13.0085],\n",
      "        [-2.4935, -4.0239, -3.9613,  ..., -5.4296,  5.9760, 13.0085],\n",
      "        ...,\n",
      "        [-4.2610, -4.0013, -5.5912,  ..., 10.6342, -2.8011, -2.6637],\n",
      "        [-4.0663, -4.0305, -5.1221,  ...,  9.9844, -2.2719, -2.6360],\n",
      "        [-3.5795, -4.3985, -5.1480,  ...,  9.2324, -2.8307, -2.8426]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8807, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  56, 3321, 3428,  ..., 2733, 2378, 3771],\n",
      "        [1779, 3705, 5277,  ..., 1693, 3021, 3403],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1779, 3705, 5277,  ..., 1693, 3021, 3403],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4946, -4.0243, -3.9605,  ..., -5.4285,  5.9764, 13.0076],\n",
      "        [-2.4946, -4.0243, -3.9605,  ..., -5.4285,  5.9764, 13.0076],\n",
      "        [-2.4946, -4.0243, -3.9605,  ..., -5.4285,  5.9764, 13.0076],\n",
      "        ...,\n",
      "        [-4.0018, -4.3742, -5.9718,  ...,  9.8996, -2.8402, -2.9825],\n",
      "        [-3.6588, -4.1462, -5.7419,  ...,  8.6562, -2.9088, -3.3166],\n",
      "        [-4.3066, -3.9299, -5.2805,  ..., 10.5243, -3.3619, -3.2359]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7166, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4560, 1131, 2947,  ..., 2809, 3390,  151],\n",
      "        [1989, 1914, 1230,  ..., 4679,  513, 4753],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1989, 1914, 1230,  ..., 4679,  513, 4753],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4944, -4.0249, -3.9597,  ..., -5.4281,  5.9745, 13.0096],\n",
      "        [-2.4944, -4.0249, -3.9597,  ..., -5.4281,  5.9745, 13.0096],\n",
      "        [-2.4944, -4.0249, -3.9597,  ..., -5.4281,  5.9745, 13.0096],\n",
      "        ...,\n",
      "        [-4.4849, -4.3465, -5.4632,  ..., 11.0341, -2.7114, -2.5059],\n",
      "        [-4.0785, -4.3704, -5.1845,  ..., 10.4406, -2.7564, -2.9607],\n",
      "        [-4.2397, -3.9834, -5.0436,  ..., 10.0837, -2.8703, -3.0151]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0134, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2947, 1947, 4828,  ..., 2133,  105, 1194],\n",
      "        [4365, 1245, 2611,  ..., 3107, 1062, 5201],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4365, 1245, 2611,  ..., 3107, 1062, 5201],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4947, -4.0258, -3.9596,  ..., -5.4274,  5.9736, 13.0113],\n",
      "        [-2.4947, -4.0258, -3.9596,  ..., -5.4274,  5.9736, 13.0113],\n",
      "        [-2.4947, -4.0258, -3.9596,  ..., -5.4274,  5.9736, 13.0113],\n",
      "        ...,\n",
      "        [-4.3399, -3.7527, -5.1186,  ..., 10.8450, -2.3952, -2.4298],\n",
      "        [-4.3814, -3.8440, -5.2527,  ..., 10.6328, -3.1954, -3.2366],\n",
      "        [-4.5436, -3.7010, -4.8264,  ..., 10.8344, -3.1361, -2.9841]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8927, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 790, 4679, 2961,  ..., 4525,  969, 1706],\n",
      "        [5036,  325, 4204,  ..., 2164, 2719, 2516],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5036,  325, 4204,  ..., 2164, 2719, 2516],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4952, -4.0269, -3.9598,  ..., -5.4277,  5.9726, 13.0130],\n",
      "        [-2.4952, -4.0269, -3.9598,  ..., -5.4277,  5.9726, 13.0130],\n",
      "        [-2.4952, -4.0269, -3.9598,  ..., -5.4277,  5.9726, 13.0130],\n",
      "        ...,\n",
      "        [-4.6675, -4.1849, -5.2355,  ..., 11.2130, -2.8405, -3.1600],\n",
      "        [-4.1724, -3.8783, -5.2832,  ..., 11.3023, -3.2328, -3.0094],\n",
      "        [-4.8793, -3.8296, -5.0966,  ..., 11.9523, -2.9648, -2.7929]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9238, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2017,  712, 4963,  ...,  912, 1054, 4470],\n",
      "        [2699, 3328, 3049,  ..., 1220, 4774, 3046],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2699, 3328, 3049,  ..., 1220, 4774, 3046],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4960, -4.0283, -3.9604,  ..., -5.4279,  5.9722, 13.0144],\n",
      "        [-2.4960, -4.0283, -3.9604,  ..., -5.4279,  5.9722, 13.0144],\n",
      "        [-2.4960, -4.0283, -3.9604,  ..., -5.4279,  5.9722, 13.0144],\n",
      "        ...,\n",
      "        [-4.2477, -4.0291, -5.5630,  ...,  9.5036, -2.5793, -2.7352],\n",
      "        [-4.6228, -3.7583, -5.4014,  ..., 11.9077, -2.9052, -2.8691],\n",
      "        [-4.3615, -3.8879, -5.5842,  ...,  9.8900, -3.3933, -3.3664]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9005, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1082, 1192, 4002,  ..., 3061, 4648, 4496],\n",
      "        [4305, 2578,  861,  ...,  961,  832,   30],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4305, 2578,  861,  ...,  961,  832,   30],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4968, -4.0299, -3.9613,  ..., -5.4281,  5.9724, 13.0153],\n",
      "        [-2.4968, -4.0299, -3.9613,  ..., -5.4281,  5.9724, 13.0153],\n",
      "        [-2.4968, -4.0299, -3.9613,  ..., -5.4281,  5.9724, 13.0153],\n",
      "        ...,\n",
      "        [-4.2083, -3.7669, -5.5767,  ..., 10.1434, -3.0422, -3.0821],\n",
      "        [-4.2954, -4.1024, -5.1665,  ...,  9.9238, -2.3790, -2.2760],\n",
      "        [-4.7188, -3.4889, -4.8762,  ..., 10.9664, -2.6114, -2.4921]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8940, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2219,   45, 2064,  ...,    4, 2947, 2414],\n",
      "        [1306, 5033, 4263,  ..., 3852, 3332, 4679],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1306, 5033, 4263,  ..., 3852, 3332, 4679],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4966, -4.0316, -3.9622,  ..., -5.4280,  5.9732, 13.0151],\n",
      "        [-2.4966, -4.0316, -3.9622,  ..., -5.4280,  5.9732, 13.0151],\n",
      "        [-2.4966, -4.0316, -3.9622,  ..., -5.4280,  5.9732, 13.0151],\n",
      "        ...,\n",
      "        [-4.3256, -3.8702, -5.3917,  ...,  9.1734, -2.7653, -2.7301],\n",
      "        [-3.7995, -3.9913, -4.5157,  ...,  7.2686, -3.0662, -3.3924],\n",
      "        [-4.2758, -3.9429, -4.7496,  ..., 11.1199, -3.4302, -3.1733]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0323, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4087, 1452, 2546,  ..., 1010,  969, 2378],\n",
      "        [5061, 4944, 4305,  ..., 2548, 1492,  764],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5061, 4944, 4305,  ..., 2548, 1492,  764],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4967, -4.0319, -3.9632,  ..., -5.4275,  5.9747, 13.0143],\n",
      "        [-2.4967, -4.0319, -3.9632,  ..., -5.4275,  5.9747, 13.0143],\n",
      "        [-2.4967, -4.0319, -3.9632,  ..., -5.4275,  5.9747, 13.0143],\n",
      "        ...,\n",
      "        [-4.2164, -4.3623, -5.3169,  ...,  8.9823, -2.7850, -2.7451],\n",
      "        [-4.2685, -3.8238, -5.1709,  ..., 10.2700, -2.8118, -2.7790],\n",
      "        [-3.9139, -3.6271, -4.7699,  ...,  7.7509, -3.2050, -3.3341]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0073, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4548,  159, 1166,  ...,  576, 1957, 2181],\n",
      "        [1251, 4193, 1081,  ..., 3379, 3504, 1843],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1251, 4193, 1081,  ..., 3379, 3504, 1843],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4971, -4.0325, -3.9644,  ..., -5.4265,  5.9784, 13.0109],\n",
      "        [-2.4971, -4.0325, -3.9644,  ..., -5.4265,  5.9784, 13.0109],\n",
      "        [-2.4971, -4.0325, -3.9644,  ..., -5.4265,  5.9784, 13.0109],\n",
      "        ...,\n",
      "        [-4.6424, -3.4925, -3.9398,  ..., 10.2388, -1.8508, -1.5823],\n",
      "        [-4.4470, -3.5966, -4.9771,  ..., 10.4237, -3.1525, -3.1875],\n",
      "        [-4.3251, -3.6864, -4.8696,  ..., 11.2687, -2.2128, -2.1892]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7032, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2378, 3980, 4586,  ...,  114, 4983, 2915],\n",
      "        [4305,  283, 2242,  ..., 2995, 4069, 2244],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4305,  283, 2242,  ..., 2995, 4069, 2244],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4968, -4.0332, -3.9656,  ..., -5.4260,  5.9796, 13.0108],\n",
      "        [-2.4968, -4.0332, -3.9656,  ..., -5.4260,  5.9796, 13.0108],\n",
      "        [-2.4968, -4.0332, -3.9656,  ..., -5.4260,  5.9796, 13.0108],\n",
      "        ...,\n",
      "        [-3.7607, -3.5452, -5.3586,  ...,  9.8598, -2.7986, -2.5961],\n",
      "        [-3.9249, -3.9882, -4.5257,  ...,  7.0567, -2.2514, -2.4580],\n",
      "        [-4.5771, -4.4540, -5.3609,  ..., 11.5619, -2.0557, -2.0105]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8295, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 996, 4426, 2991,  ..., 3542,  321, 5158],\n",
      "        [4467, 4265,  337,  ...,  843,  834, 3283],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4467, 4265,  337,  ...,  843,  834, 3283],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4968, -4.0340, -3.9670,  ..., -5.4260,  5.9792, 13.0122],\n",
      "        [-2.4968, -4.0340, -3.9670,  ..., -5.4260,  5.9792, 13.0122],\n",
      "        [-2.4968, -4.0340, -3.9670,  ..., -5.4260,  5.9792, 13.0122],\n",
      "        ...,\n",
      "        [-4.5158, -4.5610, -5.6912,  ..., 11.6325, -2.9006, -3.0065],\n",
      "        [-4.5726, -4.0709, -5.3143,  ..., 10.1128, -2.9527, -2.9586],\n",
      "        [-4.0223, -3.5701, -4.7995,  ..., 10.4623, -3.2351, -3.1495]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9530, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2244, 2915, 4207,  ..., 2809, 1144,  965],\n",
      "        [ 421, 2433,  677,  ..., 4346,  948, 4091],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 421, 2433,  677,  ..., 4346,  948, 4091],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4970, -4.0340, -3.9685,  ..., -5.4262,  5.9784, 13.0143],\n",
      "        [-2.4970, -4.0340, -3.9685,  ..., -5.4262,  5.9784, 13.0143],\n",
      "        [-2.4970, -4.0340, -3.9685,  ..., -5.4262,  5.9784, 13.0143],\n",
      "        ...,\n",
      "        [-4.0647, -3.8615, -5.6518,  ..., 10.7562, -3.2148, -3.2420],\n",
      "        [-4.7245, -3.7157, -4.5989,  ..., 10.2853, -3.3105, -3.2869],\n",
      "        [-4.2923, -3.8709, -4.8908,  ..., 10.7646, -3.4902, -3.2676]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0008, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  25, 1427, 2629,  ...,  321,  105, 4008],\n",
      "        [4548,  321, 3331,  ..., 2809,  947, 4813],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4548,  321, 3331,  ..., 2809,  947, 4813],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4974, -4.0343, -3.9701,  ..., -5.4263,  5.9784, 13.0155],\n",
      "        [-2.4974, -4.0343, -3.9701,  ..., -5.4263,  5.9784, 13.0155],\n",
      "        [-2.4974, -4.0343, -3.9701,  ..., -5.4263,  5.9784, 13.0155],\n",
      "        ...,\n",
      "        [-4.3742, -4.3287, -5.9774,  ..., 10.9085, -2.5164, -2.7822],\n",
      "        [-4.1010, -3.8049, -5.8009,  ..., 10.1456, -2.8331, -2.8739],\n",
      "        [-4.5768, -3.6926, -5.1604,  ..., 10.4098, -2.6619, -2.9090]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7816, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2809, 4831, 5016,  ..., 4439,  790, 1246],\n",
      "        [4346, 1987, 1192,  ..., 3653, 4069, 4168],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4346, 1987, 1192,  ..., 3653, 4069, 4168],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4980, -4.0338, -3.9717,  ..., -5.4269,  5.9771, 13.0183],\n",
      "        [-2.4980, -4.0338, -3.9717,  ..., -5.4269,  5.9771, 13.0183],\n",
      "        [-2.4980, -4.0338, -3.9717,  ..., -5.4269,  5.9771, 13.0183],\n",
      "        ...,\n",
      "        [-4.1687, -3.2351, -3.7624,  ...,  7.9018, -2.0426, -2.1031],\n",
      "        [-4.6126, -3.9905, -5.0806,  ..., 11.9224, -2.5267, -2.5647],\n",
      "        [-4.7876, -3.4607, -4.3154,  ..., 10.3160, -3.0299, -2.7187]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9712, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5139, 2554, 3898,  ..., 2763, 1010, 1968],\n",
      "        [2091, 4266, 2389,  ..., 3106,  179, 1654],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2091, 4266, 2389,  ..., 3106,  179, 1654],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4988, -4.0336, -3.9733,  ..., -5.4267,  5.9769, 13.0193],\n",
      "        [-2.4988, -4.0336, -3.9733,  ..., -5.4267,  5.9769, 13.0193],\n",
      "        [-2.4988, -4.0336, -3.9733,  ..., -5.4267,  5.9769, 13.0193],\n",
      "        ...,\n",
      "        [-4.2752, -3.4166, -4.2835,  ...,  9.5956, -3.1387, -2.8352],\n",
      "        [-4.4543, -3.6261, -4.5179,  ..., 10.2174, -3.0327, -2.6221],\n",
      "        [-3.7561, -4.4566, -4.9298,  ...,  7.3022, -2.9502, -3.2135]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8564, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4905, 2316,  105,  ..., 2961, 3277, 3862],\n",
      "        [3480, 1762, 5046,  ..., 3255, 4840,   44],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3480, 1762, 5046,  ..., 3255, 4840,   44],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.4999, -4.0337, -3.9749,  ..., -5.4262,  5.9761, 13.0210],\n",
      "        [-2.4999, -4.0337, -3.9749,  ..., -5.4262,  5.9761, 13.0210],\n",
      "        [-2.4999, -4.0337, -3.9749,  ..., -5.4262,  5.9761, 13.0210],\n",
      "        ...,\n",
      "        [-4.1184, -4.3123, -5.2531,  ..., 10.8702, -2.6853, -3.0658],\n",
      "        [-4.2037, -3.7705, -5.4755,  ...,  9.3096, -2.5306, -2.3339],\n",
      "        [-3.9422, -4.1878, -5.0494,  ...,  7.7232, -3.2398, -3.4112]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9037, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2347, 2164, 1240,  ..., 2313, 1158, 5051],\n",
      "        [  74, 4749, 3547,  ...,  891, 2763, 4559],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  74, 4749, 3547,  ...,  891, 2763, 4559],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5012, -4.0335, -3.9739,  ..., -5.4259,  5.9758, 13.0221],\n",
      "        [-2.5012, -4.0335, -3.9739,  ..., -5.4259,  5.9758, 13.0221],\n",
      "        [-2.5012, -4.0335, -3.9739,  ..., -5.4259,  5.9758, 13.0221],\n",
      "        ...,\n",
      "        [-3.8825, -4.0228, -6.0058,  ..., 10.4341, -2.6497, -2.7623],\n",
      "        [-3.9041, -4.2936, -5.5377,  ..., 10.5814, -2.7666, -3.1586],\n",
      "        [-4.3518, -4.0139, -5.4874,  ..., 11.1183, -2.6976, -2.7333]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8815, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3005,  466, 4052,  ..., 4986, 3383, 2991],\n",
      "        [1540, 3087, 2941,  ..., 1299, 2383, 4168],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1540, 3087, 2941,  ..., 1299, 2383, 4168],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5027, -4.0336, -3.9734,  ..., -5.4260,  5.9748, 13.0236],\n",
      "        [-2.5027, -4.0336, -3.9734,  ..., -5.4260,  5.9748, 13.0236],\n",
      "        [-2.5027, -4.0336, -3.9734,  ..., -5.4260,  5.9748, 13.0236],\n",
      "        ...,\n",
      "        [-4.4215, -4.3920, -5.3022,  ..., 10.3175, -2.3609, -2.0743],\n",
      "        [-4.7320, -3.9784, -4.9958,  ..., 10.6718, -2.2671, -2.1814],\n",
      "        [-4.7960, -3.7384, -4.3756,  ..., 10.7673, -3.1298, -2.8043]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8763, grad_fn=<NllLossBackward>)\n",
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花李。', '月下，一番花、一点春风。', '夜蓉雨。', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番花开酒。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3087, 5240, 1018,  ...,    4, 3693,    4],\n",
      "        [4467, 4838, 1877,  ..., 2091, 4124, 1358],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4467, 4838, 1877,  ..., 2091, 4124, 1358],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5043, -4.0338, -3.9729,  ..., -5.4258,  5.9730, 13.0258],\n",
      "        [-2.5043, -4.0338, -3.9729,  ..., -5.4258,  5.9730, 13.0258],\n",
      "        [-2.5043, -4.0338, -3.9729,  ..., -5.4258,  5.9730, 13.0258],\n",
      "        ...,\n",
      "        [-4.1559, -3.9139, -4.8203,  ..., 10.7441, -3.3182, -3.0101],\n",
      "        [-3.5706, -4.1370, -5.8525,  ...,  7.1965, -2.2153, -2.4905],\n",
      "        [-4.4259, -4.2507, -5.2818,  ...,  8.1341, -2.9686, -2.5482]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8835, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3656,  283, 2141,  ..., 4123, 2181, 3406],\n",
      "        [3642, 3279,  806,  ..., 4036, 1340,  321],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3642, 3279,  806,  ..., 4036, 1340,  321],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5059, -4.0336, -3.9727,  ..., -5.4260,  5.9713, 13.0280],\n",
      "        [-2.5059, -4.0336, -3.9727,  ..., -5.4260,  5.9713, 13.0280],\n",
      "        [-2.5059, -4.0336, -3.9727,  ..., -5.4260,  5.9713, 13.0280],\n",
      "        ...,\n",
      "        [-4.3925, -3.8928, -4.3958,  ..., 10.2790, -2.7793, -3.0220],\n",
      "        [-4.3261, -3.6617, -4.6973,  ..., 10.5344, -1.9889, -1.9557],\n",
      "        [-4.7052, -4.3726, -5.4579,  ..., 10.4613, -2.8328, -2.7633]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9687, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3237, 5295,  484,  ..., 1694,  321, 4470],\n",
      "        [3091, 5295, 1833,  ..., 2234, 3500, 3547],\n",
      "        [ 436, 5294,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3091, 5295, 1833,  ..., 2234, 3500, 3547],\n",
      "        [ 436, 5294,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5077, -4.0338, -3.9728,  ..., -5.4263,  5.9712, 13.0291],\n",
      "        [-2.5077, -4.0338, -3.9728,  ..., -5.4263,  5.9712, 13.0291],\n",
      "        [-2.5077, -4.0338, -3.9728,  ..., -5.4263,  5.9712, 13.0291],\n",
      "        ...,\n",
      "        [-3.7665, -4.0813, -5.8407,  ...,  9.2584, -2.9500, -3.0400],\n",
      "        [-4.5939, -3.6429, -4.9320,  ..., 11.0807, -3.0641, -2.9317],\n",
      "        [-4.6473, -3.9784, -5.5843,  ..., 11.3181, -3.3419, -3.2358]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9108, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4877, 5283, 4753,  ..., 3045, 4407, 3123],\n",
      "        [ 220, 1808, 5173,  ..., 3331, 5173, 2164],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 220, 1808, 5173,  ..., 3331, 5173, 2164],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5095, -4.0342, -3.9731,  ..., -5.4277,  5.9703, 13.0311],\n",
      "        [-2.5095, -4.0342, -3.9731,  ..., -5.4277,  5.9703, 13.0311],\n",
      "        [-2.5095, -4.0342, -3.9731,  ..., -5.4277,  5.9703, 13.0311],\n",
      "        ...,\n",
      "        [-4.0888, -4.2991, -5.8405,  ..., 11.1848, -2.6425, -2.8353],\n",
      "        [-3.8639, -3.9932, -5.2048,  ..., 11.1199, -2.9607, -3.0583],\n",
      "        [-4.4971, -4.3195, -5.6198,  ..., 11.6006, -2.5213, -2.4676]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8501, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1649, 4526,  481,  ..., 3500, 3092, 3814],\n",
      "        [2396, 4467, 2159,  ..., 3753, 3409, 1020],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2396, 4467, 2159,  ..., 3753, 3409, 1020],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5115, -4.0347, -3.9736,  ..., -5.4298,  5.9687, 13.0342],\n",
      "        [-2.5115, -4.0347, -3.9736,  ..., -5.4298,  5.9687, 13.0342],\n",
      "        [-2.5115, -4.0347, -3.9736,  ..., -5.4298,  5.9687, 13.0342],\n",
      "        ...,\n",
      "        [-4.5352, -3.5536, -4.8550,  ...,  9.6489, -3.2733, -3.1857],\n",
      "        [-4.2820, -3.9042, -5.7299,  ..., 10.3208, -3.1117, -2.9718],\n",
      "        [-4.1292, -4.2860, -5.2649,  ..., 10.5773, -2.7772, -2.8930]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8358, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4895,   84,  852,  ..., 2732,  639, 3365],\n",
      "        [1309, 4312, 2809,  ..., 4017, 3651, 4616],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1309, 4312, 2809,  ..., 4017, 3651, 4616],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5135, -4.0354, -3.9739,  ..., -5.4313,  5.9676, 13.0365],\n",
      "        [-2.5135, -4.0354, -3.9739,  ..., -5.4313,  5.9676, 13.0365],\n",
      "        [-2.5135, -4.0354, -3.9739,  ..., -5.4313,  5.9676, 13.0365],\n",
      "        ...,\n",
      "        [-4.5274, -3.9201, -5.1059,  ..., 12.3043, -2.9229, -2.4111],\n",
      "        [-4.1662, -3.7186, -5.4002,  ...,  9.8467, -2.5351, -2.4071],\n",
      "        [-4.3074, -4.3277, -5.3376,  ..., 11.4731, -2.6185, -2.6459]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9795, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1309,  321,    4,  ..., 1010, 3382, 2181],\n",
      "        [3500, 1423, 3535,  ..., 4465, 1192, 1054],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3500, 1423, 3535,  ..., 4465, 1192, 1054],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5157, -4.0363, -3.9743,  ..., -5.4319,  5.9676, 13.0369],\n",
      "        [-2.5157, -4.0363, -3.9743,  ..., -5.4319,  5.9676, 13.0369],\n",
      "        [-2.5157, -4.0363, -3.9743,  ..., -5.4319,  5.9676, 13.0369],\n",
      "        ...,\n",
      "        [-4.7434, -4.2397, -5.7045,  ..., 11.7702, -3.0153, -2.6620],\n",
      "        [-4.4917, -3.8120, -5.0045,  ..., 10.7473, -2.0441, -2.0910],\n",
      "        [-4.1322, -3.8339, -4.8806,  ...,  9.3451, -2.9522, -2.8909]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7933, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1401, 1131, 3513,  ..., 2915, 2166, 4521],\n",
      "        [2414,  649, 2941,  ..., 3500, 4675, 5147],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2414,  649, 2941,  ..., 3500, 4675, 5147],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5178, -4.0372, -3.9745,  ..., -5.4317,  5.9669, 13.0379],\n",
      "        [-2.5178, -4.0372, -3.9745,  ..., -5.4317,  5.9669, 13.0379],\n",
      "        [-2.5178, -4.0372, -3.9745,  ..., -5.4317,  5.9669, 13.0379],\n",
      "        ...,\n",
      "        [-4.5392, -3.9514, -5.6904,  ..., 11.1190, -2.8876, -2.6909],\n",
      "        [-4.1037, -3.3258, -4.2384,  ..., 10.2006, -3.0736, -3.0669],\n",
      "        [-4.4463, -3.7108, -5.3759,  ..., 11.2555, -2.3972, -2.4091]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9570, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4526, 2821, 5102,  ..., 4823, 4017, 4357],\n",
      "        [3508,   43,  861,  ..., 5058,  709, 1796],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3508,   43,  861,  ..., 5058,  709, 1796],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5199, -4.0384, -3.9748,  ..., -5.4320,  5.9667, 13.0385],\n",
      "        [-2.5199, -4.0384, -3.9748,  ..., -5.4320,  5.9667, 13.0385],\n",
      "        [-2.5199, -4.0384, -3.9748,  ..., -5.4320,  5.9667, 13.0385],\n",
      "        ...,\n",
      "        [-4.0804, -4.2643, -5.2925,  ..., 10.4868, -2.8379, -3.1293],\n",
      "        [-4.3805, -3.9935, -5.8754,  ..., 11.6451, -2.5784, -2.7239],\n",
      "        [-3.9099, -4.2597, -5.2247,  ..., 10.5315, -2.5487, -2.8724]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7568, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1661, 3831,  969,  ..., 2017, 1579, 3828],\n",
      "        [2288, 3510,  832,  ..., 2699, 4701, 4204],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2288, 3510,  832,  ..., 2699, 4701, 4204],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5222, -4.0389, -3.9754,  ..., -5.4335,  5.9637, 13.0427],\n",
      "        [-2.5222, -4.0389, -3.9754,  ..., -5.4335,  5.9637, 13.0427],\n",
      "        [-2.5222, -4.0389, -3.9754,  ..., -5.4335,  5.9637, 13.0427],\n",
      "        ...,\n",
      "        [-3.4868, -4.0563, -5.7926,  ...,  7.5433, -2.7662, -2.9128],\n",
      "        [-4.6521, -3.8197, -5.2525,  ..., 11.2000, -2.4292, -2.6857],\n",
      "        [-4.1688, -4.4378, -5.5314,  ..., 10.4881, -2.5618, -2.7722]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8319, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4181, 2089, 5074,  ..., 2484, 4265,  336],\n",
      "        [1724,  615, 2126,  ..., 2629, 4245, 2609],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1724,  615, 2126,  ..., 2629, 4245, 2609],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5245, -4.0398, -3.9765,  ..., -5.4367,  5.9603, 13.0481],\n",
      "        [-2.5245, -4.0398, -3.9765,  ..., -5.4367,  5.9603, 13.0481],\n",
      "        [-2.5245, -4.0398, -3.9765,  ..., -5.4367,  5.9603, 13.0481],\n",
      "        ...,\n",
      "        [-4.3761, -4.0351, -5.2458,  ..., 11.4523, -2.5776, -2.4906],\n",
      "        [-4.0474, -4.0171, -4.9823,  ...,  9.9681, -3.3075, -3.1301],\n",
      "        [-3.9673, -3.6981, -5.5859,  ...,  8.4222, -3.0145, -3.2106]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8969, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4470, 1212, 3428,  ..., 2369, 3123, 1888],\n",
      "        [   4,  622,  608,  ..., 1452, 2164, 3530],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [   4,  622,  608,  ..., 1452, 2164, 3530],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5268, -4.0409, -3.9776,  ..., -5.4395,  5.9583, 13.0521],\n",
      "        [-2.5268, -4.0409, -3.9776,  ..., -5.4395,  5.9583, 13.0521],\n",
      "        [-2.5268, -4.0409, -3.9776,  ..., -5.4395,  5.9583, 13.0521],\n",
      "        ...,\n",
      "        [-3.9607, -3.8574, -5.2184,  ...,  6.3294, -2.1280, -2.4000],\n",
      "        [-4.5568, -3.8434, -5.0107,  ...,  9.3689, -2.7131, -2.7366],\n",
      "        [-3.9861, -3.6661, -5.2333,  ...,  9.5694, -3.4199, -3.4779]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8468, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [   4, 2460, 1779,  ..., 2244, 3575, 3661],\n",
      "        [2546, 4665, 4716,  ..., 5181, 3665, 2369],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2546, 4665, 4716,  ..., 5181, 3665, 2369],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5279, -4.0421, -3.9786,  ..., -5.4402,  5.9567, 13.0546],\n",
      "        [-2.5279, -4.0421, -3.9786,  ..., -5.4402,  5.9567, 13.0546],\n",
      "        [-2.5279, -4.0421, -3.9786,  ..., -5.4402,  5.9567, 13.0546],\n",
      "        ...,\n",
      "        [-4.1493, -3.5971, -4.3855,  ...,  9.8701, -3.2767, -2.7507],\n",
      "        [-4.1885, -3.6165, -5.4331,  ..., 11.6270, -2.6177, -2.8261],\n",
      "        [-4.3524, -4.5210, -5.0448,  ..., 11.1342, -2.0528, -2.2443]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9181, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3235, 5081, 2181,  ..., 4823, 3382, 2161],\n",
      "        [ 408, 3400, 3665,  ..., 3521, 4414, 1259],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 408, 3400, 3665,  ..., 3521, 4414, 1259],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5291, -4.0426, -3.9795,  ..., -5.4398,  5.9563, 13.0550],\n",
      "        [-2.5291, -4.0426, -3.9795,  ..., -5.4398,  5.9563, 13.0550],\n",
      "        [-2.5291, -4.0426, -3.9795,  ..., -5.4398,  5.9563, 13.0550],\n",
      "        ...,\n",
      "        [-4.2743, -3.9438, -4.9211,  ..., 10.6515, -2.0182, -1.8215],\n",
      "        [-4.2815, -4.1816, -5.5743,  ..., 11.3707, -2.7317, -2.9140],\n",
      "        [-3.9381, -3.4543, -4.8348,  ...,  8.3602, -3.3777, -3.3527]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9834, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3503, 1968, 1779,  ..., 5240, 2697, 1661],\n",
      "        [2763, 1654, 3279,  ..., 3642, 4944,  513],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2763, 1654, 3279,  ..., 3642, 4944,  513],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5292, -4.0433, -3.9804,  ..., -5.4394,  5.9570, 13.0536],\n",
      "        [-2.5292, -4.0433, -3.9804,  ..., -5.4394,  5.9570, 13.0536],\n",
      "        [-2.5292, -4.0433, -3.9804,  ..., -5.4394,  5.9570, 13.0536],\n",
      "        ...,\n",
      "        [-4.5614, -4.7562, -5.0599,  ..., 11.0893, -2.1084, -2.0743],\n",
      "        [-4.2908, -4.1413, -4.5459,  ...,  9.8788, -2.2801, -2.3214],\n",
      "        [-4.5889, -3.5147, -4.5033,  ..., 11.7279, -2.6906, -2.4061]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8800, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  43, 1405, 5240,  ..., 4224, 1086, 1114],\n",
      "        [2343, 2848,  822,  ..., 1399, 4331, 2809],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2343, 2848,  822,  ..., 1399, 4331, 2809],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5296, -4.0441, -3.9814,  ..., -5.4396,  5.9580, 13.0521],\n",
      "        [-2.5296, -4.0441, -3.9814,  ..., -5.4396,  5.9580, 13.0521],\n",
      "        [-2.5296, -4.0441, -3.9814,  ..., -5.4396,  5.9580, 13.0521],\n",
      "        ...,\n",
      "        [-3.9965, -3.7537, -5.1730,  ..., 10.8901, -2.8793, -2.9593],\n",
      "        [-4.0234, -3.5871, -5.5924,  ..., 10.8874, -2.8354, -2.7021],\n",
      "        [-4.5696, -3.9197, -4.4035,  ..., 10.5721, -2.8340, -2.8146]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(2.0039, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3046,   43, 2082,  ..., 5183, 4467, 4983],\n",
      "        [4166, 1539,   56,  ..., 5183, 3087, 1081],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4166, 1539,   56,  ..., 5183, 3087, 1081],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5301, -4.0451, -3.9828,  ..., -5.4412,  5.9592, 13.0512],\n",
      "        [-2.5301, -4.0451, -3.9828,  ..., -5.4412,  5.9592, 13.0512],\n",
      "        [-2.5301, -4.0451, -3.9828,  ..., -5.4412,  5.9592, 13.0512],\n",
      "        ...,\n",
      "        [-4.7578, -4.4307, -4.8068,  ...,  7.7364, -0.3744,  0.0338],\n",
      "        [-3.8267, -4.0962, -5.0215,  ...,  8.2903, -3.1135, -3.4482],\n",
      "        [-4.2842, -3.6458, -4.9582,  ...,  9.7530, -2.6144, -2.8355]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8749, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 456, 4470, 2017,  ...,  321, 3400, 2844],\n",
      "        [3030, 4017, 2699,  ...,  283,  608, 3898],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3030, 4017, 2699,  ...,  283,  608, 3898],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5308, -4.0448, -3.9844,  ..., -5.4446,  5.9603, 13.0513],\n",
      "        [-2.5308, -4.0448, -3.9844,  ..., -5.4446,  5.9603, 13.0513],\n",
      "        [-2.5308, -4.0448, -3.9844,  ..., -5.4446,  5.9603, 13.0513],\n",
      "        ...,\n",
      "        [-4.6178, -4.2502, -5.6238,  ..., 11.3356, -2.4862, -2.4070],\n",
      "        [-4.4775, -4.7539, -5.6687,  ...,  8.9205, -2.6926, -2.5705],\n",
      "        [-4.5530, -3.7447, -4.1568,  ..., 10.0616, -2.7051, -2.4091]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7799, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  43, 1091, 3046,  ...,  411,  321, 4974],\n",
      "        [  74, 4107, 4166,  ..., 4331, 3358, 2773],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  74, 4107, 4166,  ..., 4331, 3358, 2773],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5316, -4.0439, -3.9859,  ..., -5.4479,  5.9607, 13.0520],\n",
      "        [-2.5316, -4.0439, -3.9859,  ..., -5.4479,  5.9607, 13.0520],\n",
      "        [-2.5316, -4.0439, -3.9859,  ..., -5.4479,  5.9607, 13.0520],\n",
      "        ...,\n",
      "        [-3.9000, -3.6063, -4.9454,  ...,  9.8869, -3.1949, -3.0409],\n",
      "        [-4.6034, -3.7266, -4.6144,  ..., 11.0299, -2.5483, -2.1249],\n",
      "        [-3.8568, -4.0327, -5.4477,  ..., 10.8580, -2.4747, -2.7366]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8716, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5294],\n",
      "        ...,\n",
      "        [3709, 2579, 3087,  ..., 4266, 3331,  436],\n",
      "        [2161, 4465, 4467,  ..., 4679,  817, 3382],\n",
      "        [ 436,  436,  436,  ...,  436,  436, 1144]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5294],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5009],\n",
      "        ...,\n",
      "        [2161, 4465, 4467,  ..., 4679,  817, 3382],\n",
      "        [ 436,  436,  436,  ...,  436,  436, 1144],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5326, -4.0433, -3.9871,  ..., -5.4505,  5.9613, 13.0526],\n",
      "        [-2.5326, -4.0433, -3.9871,  ..., -5.4505,  5.9613, 13.0526],\n",
      "        [-2.5326, -4.0433, -3.9871,  ..., -5.4505,  5.9613, 13.0526],\n",
      "        ...,\n",
      "        [-4.1762, -4.3760, -6.0833,  ..., 11.5450, -2.8055, -2.8179],\n",
      "        [-3.7083, -3.6572, -4.8614,  ...,  5.4909, -3.4157, -3.7803],\n",
      "        [-4.1283, -2.9124, -3.7162,  ...,  4.1322, -3.5532, -2.4759]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8537, grad_fn=<NllLossBackward>)\n",
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花李。', '月下，一番花下、一番春色。', '夜蓉雨。', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番花开舞。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 712, 1309,  307,  ..., 1025, 4825,  277],\n",
      "        [3837, 3383, 2412,  ..., 4493, 1232, 3048],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3837, 3383, 2412,  ..., 4493, 1232, 3048],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5324, -4.0427, -3.9881,  ..., -5.4519,  5.9625, 13.0515],\n",
      "        [-2.5324, -4.0427, -3.9881,  ..., -5.4519,  5.9625, 13.0515],\n",
      "        [-2.5324, -4.0427, -3.9881,  ..., -5.4519,  5.9625, 13.0515],\n",
      "        ...,\n",
      "        [-4.2658, -3.7028, -4.5866,  ..., 10.7987, -3.2540, -2.9614],\n",
      "        [-3.9583, -4.0062, -5.3907,  ..., 11.5088, -2.6852, -2.7617],\n",
      "        [-4.3720, -3.6507, -5.5335,  ..., 10.7927, -2.8615, -2.5292]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9305, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 321, 2502,  201,  ..., 3390, 4145, 2181],\n",
      "        [2936, 4091, 2059,  ..., 2320, 2773, 3669],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2936, 4091, 2059,  ..., 2320, 2773, 3669],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5325, -4.0424, -3.9891,  ..., -5.4526,  5.9635, 13.0503],\n",
      "        [-2.5325, -4.0424, -3.9891,  ..., -5.4526,  5.9635, 13.0503],\n",
      "        [-2.5325, -4.0424, -3.9891,  ..., -5.4526,  5.9635, 13.0503],\n",
      "        ...,\n",
      "        [-3.6328, -3.9552, -4.9813,  ...,  7.3160, -3.3947, -3.7071],\n",
      "        [-4.1201, -3.8491, -5.7544,  ..., 10.9824, -2.5712, -2.7333],\n",
      "        [-4.2256, -3.0995, -4.4380,  ...,  9.6616, -1.5243, -1.4488]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8679, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1240,  432, 3934,  ..., 3393, 4809, 4044],\n",
      "        [5181, 2136,   43,  ..., 3250,   86, 3828],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5181, 2136,   43,  ..., 3250,   86, 3828],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5329, -4.0414, -3.9902,  ..., -5.4539,  5.9634, 13.0502],\n",
      "        [-2.5329, -4.0414, -3.9902,  ..., -5.4539,  5.9634, 13.0502],\n",
      "        [-2.5329, -4.0414, -3.9902,  ..., -5.4539,  5.9634, 13.0502],\n",
      "        ...,\n",
      "        [-4.0779, -3.7883, -5.2399,  ...,  6.6735, -2.9410, -3.2112],\n",
      "        [-3.8876, -3.6730, -4.9681,  ...,  8.8107, -3.1631, -3.3534],\n",
      "        [-3.9888, -4.1412, -5.5123,  ..., 10.1707, -2.8658, -3.0804]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8545, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3331,  969, 1661,  ..., 1271, 3008, 4753],\n",
      "        [2792, 5243,  120,  ...,  283,  468, 4224],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2792, 5243,  120,  ...,  283,  468, 4224],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5325, -4.0407, -3.9916,  ..., -5.4562,  5.9614, 13.0527],\n",
      "        [-2.5325, -4.0407, -3.9916,  ..., -5.4562,  5.9614, 13.0527],\n",
      "        [-2.5325, -4.0407, -3.9916,  ..., -5.4562,  5.9614, 13.0527],\n",
      "        ...,\n",
      "        [-4.4677, -3.8831, -5.2975,  ..., 10.4855, -1.9228, -2.0852],\n",
      "        [-3.9006, -3.5544, -5.2581,  ...,  9.2892, -2.6824, -2.8615],\n",
      "        [-4.0177, -3.9133, -5.2435,  ...,  9.9426, -3.3924, -3.4896]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8982, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5071, 4368,  321,  ...,  712, 4623,   76],\n",
      "        [ 159, 4179, 2349,  ..., 2256, 2369, 3283],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 159, 4179, 2349,  ..., 2256, 2369, 3283],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5327, -4.0404, -3.9936,  ..., -5.4590,  5.9590, 13.0563],\n",
      "        [-2.5327, -4.0404, -3.9936,  ..., -5.4590,  5.9590, 13.0563],\n",
      "        [-2.5327, -4.0404, -3.9936,  ..., -5.4590,  5.9590, 13.0563],\n",
      "        ...,\n",
      "        [-4.3002, -4.0561, -4.5705,  ...,  9.5241, -2.9388, -3.3673],\n",
      "        [-4.7397, -3.5720, -4.3798,  ..., 10.4023, -2.7133, -2.5207],\n",
      "        [-3.9125, -3.3634, -4.7603,  ..., 10.2146, -3.1099, -3.1103]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8659, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3382, 4895,  248,  ..., 4265, 3277, 4933],\n",
      "        [4069,  878, 3911,  ...,  298, 2064,  321],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4069,  878, 3911,  ...,  298, 2064,  321],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5334, -4.0405, -3.9958,  ..., -5.4627,  5.9554, 13.0617],\n",
      "        [-2.5334, -4.0405, -3.9958,  ..., -5.4627,  5.9554, 13.0617],\n",
      "        [-2.5334, -4.0405, -3.9958,  ..., -5.4627,  5.9554, 13.0617],\n",
      "        ...,\n",
      "        [-4.2055, -4.4830, -5.5455,  ...,  8.7839, -3.0002, -3.0791],\n",
      "        [-3.8015, -3.5047, -5.5323,  ...,  7.9949, -2.6303, -2.7921],\n",
      "        [-4.8203, -3.9185, -4.5937,  ..., 10.9397, -2.4409, -2.1370]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9590, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 831, 2915,  157,  ..., 3542, 3642,  982],\n",
      "        [2961, 2809, 2414,  ...,  179, 3806,  321],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2961, 2809, 2414,  ...,  179, 3806,  321],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5345, -4.0410, -3.9981,  ..., -5.4656,  5.9531, 13.0658],\n",
      "        [-2.5345, -4.0410, -3.9981,  ..., -5.4656,  5.9531, 13.0658],\n",
      "        [-2.5345, -4.0410, -3.9981,  ..., -5.4656,  5.9531, 13.0658],\n",
      "        ...,\n",
      "        [-4.2466, -3.4789, -4.5333,  ...,  9.9699, -3.2799, -3.1718],\n",
      "        [-4.5324, -3.5558, -4.6596,  ..., 11.7669, -2.6234, -2.2298],\n",
      "        [-4.2988, -4.1309, -5.5931,  ..., 11.1227, -2.9702, -3.0338]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8327, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  43, 2991,   20,  ..., 3092, 3894, 4192],\n",
      "        [4467, 1618,   20,  ..., 3409, 3898, 3258],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4467, 1618,   20,  ..., 3409, 3898, 3258],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5361, -4.0417, -4.0005,  ..., -5.4667,  5.9507, 13.0694],\n",
      "        [-2.5361, -4.0417, -4.0005,  ..., -5.4667,  5.9507, 13.0694],\n",
      "        [-2.5361, -4.0417, -4.0005,  ..., -5.4667,  5.9507, 13.0694],\n",
      "        ...,\n",
      "        [-2.8732, -4.0502, -5.6981,  ...,  4.7052, -2.5205, -2.6066],\n",
      "        [-4.6209, -4.3343, -4.9858,  ..., 11.3907, -1.8983, -1.8502],\n",
      "        [-4.3980, -3.7749, -5.2572,  ..., 12.0808, -2.8896, -2.7644]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9742, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 321, 1947, 2516,  ..., 2789, 4467, 5027],\n",
      "        [2047, 3722, 4512,  ...,  825, 3087, 2624],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2047, 3722, 4512,  ...,  825, 3087, 2624],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5377, -4.0426, -4.0027,  ..., -5.4676,  5.9488, 13.0719],\n",
      "        [-2.5377, -4.0426, -4.0027,  ..., -5.4676,  5.9488, 13.0719],\n",
      "        [-2.5377, -4.0426, -4.0027,  ..., -5.4676,  5.9488, 13.0719],\n",
      "        ...,\n",
      "        [-4.5072, -3.9880, -5.7018,  ..., 12.1322, -2.8382, -2.9259],\n",
      "        [-4.3480, -3.9174, -5.1420,  ..., 11.2308, -3.5551, -3.6247],\n",
      "        [-4.3772, -4.0933, -5.3315,  ..., 10.3686, -3.3777, -3.3570]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7382, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2941, 5081, 3045,  ...,  131, 4753, 2516],\n",
      "        [ 380,  468, 1309,  ..., 2136, 4679, 2632],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 380,  468, 1309,  ..., 2136, 4679, 2632],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5394, -4.0429, -4.0048,  ..., -5.4684,  5.9449, 13.0766],\n",
      "        [-2.5394, -4.0429, -4.0048,  ..., -5.4684,  5.9449, 13.0766],\n",
      "        [-2.5394, -4.0429, -4.0048,  ..., -5.4684,  5.9449, 13.0766],\n",
      "        ...,\n",
      "        [-4.2848, -3.6669, -5.0192,  ..., 10.9267, -3.2286, -2.8979],\n",
      "        [-4.4307, -3.9772, -5.5264,  ..., 11.4218, -2.9136, -2.8002],\n",
      "        [-4.7478, -3.6886, -4.3080,  ..., 10.0948, -3.2344, -2.9702]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8039, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 792, 2378,  604,  ..., 4943, 4125, 4263],\n",
      "        [2763, 4421, 5275,  ..., 3382,  745, 2732],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2763, 4421, 5275,  ..., 3382,  745, 2732],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5413, -4.0434, -4.0068,  ..., -5.4697,  5.9409, 13.0812],\n",
      "        [-2.5413, -4.0434, -4.0068,  ..., -5.4697,  5.9409, 13.0812],\n",
      "        [-2.5413, -4.0434, -4.0068,  ..., -5.4697,  5.9409, 13.0812],\n",
      "        ...,\n",
      "        [-4.3976, -3.6497, -4.9443,  ..., 10.9557, -2.8772, -2.9143],\n",
      "        [-4.8173, -3.7799, -4.6985,  ..., 11.7071, -2.9025, -2.6182],\n",
      "        [-4.3208, -3.6549, -4.5478,  ..., 10.6244, -3.5299, -3.4491]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8319, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2554, 4793,  607,  ..., 4263, 2531, 1054],\n",
      "        [4266,   56, 4650,  ..., 2732, 3505, 4266],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4266,   56, 4650,  ..., 2732, 3505, 4266],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5432, -4.0441, -4.0088,  ..., -5.4716,  5.9371, 13.0858],\n",
      "        [-2.5432, -4.0441, -4.0088,  ..., -5.4716,  5.9371, 13.0858],\n",
      "        [-2.5432, -4.0441, -4.0088,  ..., -5.4716,  5.9371, 13.0858],\n",
      "        ...,\n",
      "        [-4.3510, -3.9825, -5.2695,  ..., 10.0351, -3.2108, -3.3878],\n",
      "        [-4.0742, -3.7912, -5.3408,  ..., 11.1534, -3.1475, -3.0060],\n",
      "        [-4.6427, -3.7540, -5.4338,  ..., 11.6191, -2.9058, -2.9229]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8602, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4822,  341,   15,  ..., 3854, 1452, 1502],\n",
      "        [ 283,   16, 3366,  ..., 1158, 2792,  277],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 283,   16, 3366,  ..., 1158, 2792,  277],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5452, -4.0447, -4.0109,  ..., -5.4733,  5.9344, 13.0892],\n",
      "        [-2.5452, -4.0447, -4.0109,  ..., -5.4733,  5.9344, 13.0892],\n",
      "        [-2.5452, -4.0447, -4.0109,  ..., -5.4733,  5.9344, 13.0892],\n",
      "        ...,\n",
      "        [-3.9962, -4.1252, -5.5604,  ..., 10.8979, -3.1456, -3.3539],\n",
      "        [-4.0261, -3.8954, -5.4220,  ..., 10.5034, -3.1300, -3.1231],\n",
      "        [-4.6573, -4.2420, -5.3470,  ..., 11.8810, -1.9193, -2.0371]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8675, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  30, 3730,  421,  ..., 4525, 1232, 3573],\n",
      "        [4678, 3379,  421,  ..., 4746,  692, 3500],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4678, 3379,  421,  ..., 4746,  692, 3500],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5472, -4.0456, -4.0129,  ..., -5.4750,  5.9326, 13.0916],\n",
      "        [-2.5472, -4.0456, -4.0129,  ..., -5.4750,  5.9326, 13.0916],\n",
      "        [-2.5472, -4.0456, -4.0129,  ..., -5.4750,  5.9326, 13.0916],\n",
      "        ...,\n",
      "        [-3.9002, -3.5339, -3.4895,  ...,  6.6170, -2.0097, -2.1690],\n",
      "        [-4.0362, -3.6187, -5.0846,  ..., 10.2218, -2.7691, -2.4454],\n",
      "        [-4.5315, -3.8011, -5.0856,  ...,  8.9730, -3.1709, -3.4002]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9535, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4096,  192, 5183,  ..., 4899, 1272,  760],\n",
      "        [4200, 3634, 5183,  ..., 3289, 1787, 3331],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4200, 3634, 5183,  ..., 3289, 1787, 3331],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5492, -4.0465, -4.0150,  ..., -5.4759,  5.9323, 13.0920],\n",
      "        [-2.5492, -4.0465, -4.0150,  ..., -5.4759,  5.9323, 13.0920],\n",
      "        [-2.5492, -4.0465, -4.0150,  ..., -5.4759,  5.9323, 13.0920],\n",
      "        ...,\n",
      "        [-4.6537, -3.5716, -4.3275,  ..., 11.0264, -2.7147, -2.5067],\n",
      "        [-4.1406, -3.8227, -5.5498,  ..., 10.8128, -2.6118, -2.9958],\n",
      "        [-4.6064, -3.9593, -5.1015,  ..., 10.8171, -2.7908, -2.5944]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9568, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3092,  639, 3331,  ..., 3598, 1309, 3299],\n",
      "        [4022, 1452,  466,  ..., 3911, 3087,  192],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4022, 1452,  466,  ..., 3911, 3087,  192],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5514, -4.0476, -4.0132,  ..., -5.4753,  5.9351, 13.0888],\n",
      "        [-2.5514, -4.0476, -4.0132,  ..., -5.4753,  5.9351, 13.0888],\n",
      "        [-2.5514, -4.0476, -4.0132,  ..., -5.4753,  5.9351, 13.0888],\n",
      "        ...,\n",
      "        [-4.4533, -3.6407, -4.6838,  ..., 10.4416, -2.8513, -2.6236],\n",
      "        [-4.2390, -4.1471, -5.3286,  ..., 11.2811, -2.6432, -2.4613],\n",
      "        [-4.1744, -3.6461, -5.2914,  ...,  9.3047, -2.5910, -2.7712]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8724, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2809, 2167, 4265,  ..., 2991, 4346, 3513],\n",
      "        [ 806,  965, 3107,  ..., 1010, 4854, 1922],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 806,  965, 3107,  ..., 1010, 4854, 1922],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5536, -4.0489, -4.0117,  ..., -5.4751,  5.9380, 13.0855],\n",
      "        [-2.5536, -4.0489, -4.0117,  ..., -5.4751,  5.9380, 13.0855],\n",
      "        [-2.5536, -4.0489, -4.0117,  ..., -5.4751,  5.9380, 13.0855],\n",
      "        ...,\n",
      "        [-4.4525, -3.6404, -5.0558,  ..., 11.5662, -2.7774, -2.7837],\n",
      "        [-4.0066, -3.5150, -5.1645,  ...,  9.6722, -3.0091, -3.1145],\n",
      "        [-4.6500, -4.4273, -6.0608,  ..., 10.5307, -2.6321, -2.7139]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8081, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1661, 3480, 2991,  ..., 2198,   15, 3428],\n",
      "        [3032, 2732, 4813,  ..., 3598, 1989, 2349],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3032, 2732, 4813,  ..., 3598, 1989, 2349],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5559, -4.0503, -4.0106,  ..., -5.4760,  5.9406, 13.0832],\n",
      "        [-2.5559, -4.0503, -4.0106,  ..., -5.4760,  5.9406, 13.0832],\n",
      "        [-2.5559, -4.0503, -4.0106,  ..., -5.4760,  5.9406, 13.0832],\n",
      "        ...,\n",
      "        [-4.8299, -4.3445, -5.1954,  ..., 11.8077, -2.7439, -2.8866],\n",
      "        [-2.5142, -3.8786, -6.1752,  ...,  3.7466, -1.5396, -1.9528],\n",
      "        [-3.9933, -3.8214, -5.4176,  ...,  9.2994, -2.8476, -3.0594]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9724, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1579, 1315, 1131,  ...,  672,   43, 2791],\n",
      "        [2058, 3061, 2058,  ..., 3428, 4825, 4331],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2058, 3061, 2058,  ..., 3428, 4825, 4331],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5582, -4.0519, -4.0101,  ..., -5.4781,  5.9442, 13.0802],\n",
      "        [-2.5582, -4.0519, -4.0101,  ..., -5.4781,  5.9442, 13.0802],\n",
      "        [-2.5582, -4.0519, -4.0101,  ..., -5.4781,  5.9442, 13.0802],\n",
      "        ...,\n",
      "        [-4.3990, -3.8988, -5.5950,  ..., 11.4862, -2.9151, -2.5990],\n",
      "        [-3.9071, -3.9752, -6.0034,  ...,  9.5904, -2.8186, -2.8262],\n",
      "        [-4.1467, -3.4662, -4.6905,  ...,  8.7954, -3.3680, -3.2440]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8979, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3849, 4460, 5262,  ..., 3752,  321, 4526],\n",
      "        [2412, 4224, 3304,  ..., 1042, 2392,  639],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2412, 4224, 3304,  ..., 1042, 2392,  639],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5586, -4.0536, -4.0096,  ..., -5.4792,  5.9477, 13.0769],\n",
      "        [-2.5586, -4.0536, -4.0096,  ..., -5.4792,  5.9477, 13.0769],\n",
      "        [-2.5586, -4.0536, -4.0096,  ..., -5.4792,  5.9477, 13.0769],\n",
      "        ...,\n",
      "        [-4.3802, -3.7646, -4.7838,  ..., 10.0698, -1.8267, -1.8585],\n",
      "        [-4.0263, -3.6744, -4.9376,  ...,  8.6708, -3.4577, -3.5378],\n",
      "        [-4.7880, -3.8896, -5.3435,  ..., 11.1976, -2.6141, -2.5256]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0340, grad_fn=<NllLossBackward>)\n",
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花李。', '月下，一番花下、一番春色。', '夜蓉雨。', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番花开酒。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2719, 3828,  890,  ..., 1888, 4087, 1192],\n",
      "        [ 601,  620,  965,  ..., 1502,  411,   81],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 601,  620,  965,  ..., 1502,  411,   81],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5593, -4.0554, -4.0093,  ..., -5.4800,  5.9536, 13.0713],\n",
      "        [-2.5593, -4.0554, -4.0093,  ..., -5.4800,  5.9536, 13.0713],\n",
      "        [-2.5593, -4.0554, -4.0093,  ..., -5.4800,  5.9536, 13.0713],\n",
      "        ...,\n",
      "        [-4.3597, -3.6698, -4.4130,  ...,  9.8789, -3.0647, -2.4204],\n",
      "        [-4.5157, -3.9355, -5.5544,  ..., 11.2012, -3.0028, -2.9612],\n",
      "        [-4.3593, -3.9237, -4.4992,  ..., 11.2373, -3.3353, -2.8244]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8746, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2979, 3542, 2562,  ..., 2947, 2414, 4594],\n",
      "        [4346,  321, 3933,  ...,  806, 5173, 2671],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4346,  321, 3933,  ...,  806, 5173, 2671],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5601, -4.0562, -4.0089,  ..., -5.4800,  5.9593, 13.0662],\n",
      "        [-2.5601, -4.0562, -4.0089,  ..., -5.4800,  5.9593, 13.0662],\n",
      "        [-2.5601, -4.0562, -4.0089,  ..., -5.4800,  5.9593, 13.0662],\n",
      "        ...,\n",
      "        [-4.4377, -3.7485, -4.9266,  ..., 10.0909, -3.1065, -3.4459],\n",
      "        [-4.3770, -4.0528, -5.3143,  ..., 12.1952, -3.0046, -2.9818],\n",
      "        [-4.8468, -3.7542, -4.6793,  ..., 11.8765, -2.6569, -2.5507]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0883, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4470,  144, 1192,  ..., 2895, 3400, 1452],\n",
      "        [3061, 2924, 4331,  ..., 2895, 2742, 1779],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3061, 2924, 4331,  ..., 2895, 2742, 1779],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5611, -4.0570, -4.0085,  ..., -5.4795,  5.9664, 13.0594],\n",
      "        [-2.5611, -4.0570, -4.0085,  ..., -5.4795,  5.9664, 13.0594],\n",
      "        [-2.5611, -4.0570, -4.0085,  ..., -5.4795,  5.9664, 13.0594],\n",
      "        ...,\n",
      "        [-3.2757, -4.0868, -4.9606,  ...,  7.4963, -3.0614, -3.4715],\n",
      "        [-4.4835, -4.4493, -5.4834,  ..., 11.1912, -2.7089, -2.5578],\n",
      "        [-3.8944, -3.8196, -5.5755,  ..., 10.7514, -3.0537, -3.2410]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9395, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2629, 3806, 2383,  ..., 2159, 4467,  832],\n",
      "        [3795, 1748, 2161,  ...,  825, 3087, 4348],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3795, 1748, 2161,  ...,  825, 3087, 4348],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5623, -4.0581, -4.0082,  ..., -5.4788,  5.9737, 13.0526],\n",
      "        [-2.5623, -4.0581, -4.0082,  ..., -5.4788,  5.9737, 13.0526],\n",
      "        [-2.5623, -4.0581, -4.0082,  ..., -5.4788,  5.9737, 13.0526],\n",
      "        ...,\n",
      "        [-4.4399, -4.3060, -5.6556,  ..., 11.9977, -3.0103, -3.0474],\n",
      "        [-4.2394, -3.8571, -5.4943,  ..., 11.7439, -2.9634, -2.8419],\n",
      "        [-4.5045, -3.5687, -4.6123,  ...,  9.9454, -3.6019, -3.2836]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7546, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1054, 1514, 5295,  ..., 2273, 5203, 2405],\n",
      "        [1741,  447, 5295,  ..., 1831, 2393, 4878],\n",
      "        [ 436,  436, 5294,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1741,  447, 5295,  ..., 1831, 2393, 4878],\n",
      "        [ 436,  436, 5294,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5637, -4.0594, -4.0080,  ..., -5.4781,  5.9774, 13.0498],\n",
      "        [-2.5637, -4.0594, -4.0080,  ..., -5.4781,  5.9774, 13.0498],\n",
      "        [-2.5637, -4.0594, -4.0080,  ..., -5.4781,  5.9774, 13.0498],\n",
      "        ...,\n",
      "        [-3.8788, -3.8771, -4.8844,  ..., 10.5833, -3.1759, -2.7741],\n",
      "        [-3.9475, -4.1322, -5.5548,  ..., 10.5765, -2.5576, -2.9030],\n",
      "        [-4.2639, -3.3393, -4.5762,  ..., 11.8468, -2.6781, -2.4767]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8729, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2397,  283, 5183,  ..., 1362, 2460, 4895],\n",
      "        [2915, 3664, 5183,  ...,  745, 1524,   75],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2915, 3664, 5183,  ...,  745, 1524,   75],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5639, -4.0608, -4.0079,  ..., -5.4781,  5.9785, 13.0493],\n",
      "        [-2.5639, -4.0608, -4.0079,  ..., -5.4781,  5.9785, 13.0493],\n",
      "        [-2.5639, -4.0608, -4.0079,  ..., -5.4781,  5.9785, 13.0493],\n",
      "        ...,\n",
      "        [-4.3686, -3.7681, -4.8504,  ..., 11.1440, -2.2776, -1.9250],\n",
      "        [-4.3280, -4.0306, -5.1296,  ...,  9.3810, -3.3556, -3.1803],\n",
      "        [-4.2919, -4.3911, -5.9760,  ..., 11.1804, -2.7130, -2.8016]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9436, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1069, 4894, 2809,  ..., 3021,  366, 1301],\n",
      "        [2829, 3500, 4679,  ..., 1693, 1166,  851],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2829, 3500, 4679,  ..., 1693, 1166,  851],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5643, -4.0623, -4.0079,  ..., -5.4782,  5.9789, 13.0495],\n",
      "        [-2.5643, -4.0623, -4.0079,  ..., -5.4782,  5.9789, 13.0495],\n",
      "        [-2.5643, -4.0623, -4.0079,  ..., -5.4782,  5.9789, 13.0495],\n",
      "        ...,\n",
      "        [-4.2341, -3.8829, -5.2157,  ..., 11.1488, -2.9504, -2.7727],\n",
      "        [-4.2558, -3.8470, -5.6621,  ..., 11.4756, -2.6567, -2.4711],\n",
      "        [-4.3612, -3.8290, -5.9509,  ..., 10.9887, -2.2167, -2.3914]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0526, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4495, 4123, 1192,  ..., 2671, 4712,  366],\n",
      "        [1983,  832, 3820,  ..., 3256, 4467,  825],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1983,  832, 3820,  ..., 3256, 4467,  825],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5652, -4.0633, -4.0084,  ..., -5.4788,  5.9803, 13.0495],\n",
      "        [-2.5652, -4.0633, -4.0084,  ..., -5.4788,  5.9803, 13.0495],\n",
      "        [-2.5652, -4.0633, -4.0084,  ..., -5.4788,  5.9803, 13.0495],\n",
      "        ...,\n",
      "        [-4.4291, -4.0120, -5.5024,  ...,  9.6144, -3.1860, -3.0455],\n",
      "        [-4.5204, -3.6601, -4.8682,  ..., 11.6450, -2.7972, -2.8323],\n",
      "        [-4.4593, -4.4643, -5.7057,  ..., 10.8480, -3.0114, -3.1722]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9771, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1158, 3383, 5157,  ...,  245, 2159, 2579],\n",
      "        [1096, 2383, 2022,  ..., 4489, 3480,  321],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1096, 2383, 2022,  ..., 4489, 3480,  321],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5662, -4.0645, -4.0091,  ..., -5.4799,  5.9816, 13.0496],\n",
      "        [-2.5662, -4.0645, -4.0091,  ..., -5.4799,  5.9816, 13.0496],\n",
      "        [-2.5662, -4.0645, -4.0091,  ..., -5.4799,  5.9816, 13.0496],\n",
      "        ...,\n",
      "        [-4.2063, -3.8400, -5.5591,  ..., 10.3060, -2.9837, -2.8779],\n",
      "        [-4.0030, -4.1290, -5.5743,  ...,  9.7901, -3.0622, -3.3073],\n",
      "        [-4.3163, -3.7877, -4.7384,  ...,  8.1216, -2.7233, -2.9131]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8785, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1246,  996, 1482,  ..., 4716, 2942, 1888],\n",
      "        [5017, 5275,  620,  ..., 4036, 5225, 3530],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5017, 5275,  620,  ..., 4036, 5225, 3530],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5674, -4.0649, -4.0097,  ..., -5.4801,  5.9811, 13.0511],\n",
      "        [-2.5674, -4.0649, -4.0097,  ..., -5.4801,  5.9811, 13.0511],\n",
      "        [-2.5674, -4.0649, -4.0097,  ..., -5.4801,  5.9811, 13.0511],\n",
      "        ...,\n",
      "        [-4.3359, -3.5665, -4.5062,  ..., 10.7403, -2.9721, -2.6760],\n",
      "        [-4.1762, -3.9039, -5.3685,  ..., 10.1950, -3.2597, -3.2136],\n",
      "        [-4.2136, -3.7732, -5.2559,  ..., 10.9546, -3.3959, -3.4300]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9221, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3806, 3292, 1988,  ..., 2373, 3290, 4266],\n",
      "        [4894, 2396, 3384,  ..., 2273, 4265, 3061],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4894, 2396, 3384,  ..., 2273, 4265, 3061],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5688, -4.0654, -4.0104,  ..., -5.4802,  5.9795, 13.0534],\n",
      "        [-2.5688, -4.0654, -4.0104,  ..., -5.4802,  5.9795, 13.0534],\n",
      "        [-2.5688, -4.0654, -4.0104,  ..., -5.4802,  5.9795, 13.0534],\n",
      "        ...,\n",
      "        [-4.3108, -4.5801, -5.7017,  ..., 10.1825, -2.7570, -2.6848],\n",
      "        [-4.0107, -4.1843, -6.1556,  ..., 11.1826, -3.0691, -3.2893],\n",
      "        [-4.5002, -3.6164, -4.3893,  ..., 11.3087, -2.0945, -1.9497]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8379, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2087, 4052,  358,  ..., 1399, 2256, 4560],\n",
      "        [ 617,  745, 4265,  ..., 3331, 1091, 4062],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 617,  745, 4265,  ..., 3331, 1091, 4062],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5702, -4.0662, -4.0110,  ..., -5.4793,  5.9769, 13.0565],\n",
      "        [-2.5702, -4.0662, -4.0110,  ..., -5.4793,  5.9769, 13.0565],\n",
      "        [-2.5702, -4.0662, -4.0110,  ..., -5.4793,  5.9769, 13.0565],\n",
      "        ...,\n",
      "        [-4.0605, -3.9233, -5.5383,  ...,  9.6628, -2.6335, -3.1511],\n",
      "        [-3.6981, -3.9503, -5.1283,  ...,  6.4167, -3.4361, -3.7205],\n",
      "        [-4.1739, -4.1280, -5.4356,  ..., 10.2596, -2.9208, -3.0335]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8849, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  56, 1888, 2460,  ..., 2909, 1309, 2378],\n",
      "        [1715, 4539,  969,  ..., 2909, 3898,   97],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1715, 4539,  969,  ..., 2909, 3898,   97],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5719, -4.0659, -4.0116,  ..., -5.4782,  5.9740, 13.0598],\n",
      "        [-2.5719, -4.0659, -4.0116,  ..., -5.4782,  5.9740, 13.0598],\n",
      "        [-2.5719, -4.0659, -4.0116,  ..., -5.4782,  5.9740, 13.0598],\n",
      "        ...,\n",
      "        [-4.4938, -4.2647, -5.6767,  ..., 10.6004, -2.7588, -2.9906],\n",
      "        [-3.4062, -3.7210, -4.6944,  ...,  8.7928, -2.5247, -2.9919],\n",
      "        [-4.4781, -4.6315, -5.2623,  ...,  9.0578, -2.6689, -2.8385]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8973, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2844, 4470, 3331,  ..., 5016, 2629, 1661],\n",
      "        [5284, 4295, 4944,  ..., 4266, 4750, 4679],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5284, 4295, 4944,  ..., 4266, 4750, 4679],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5727, -4.0660, -4.0125,  ..., -5.4783,  5.9708, 13.0644],\n",
      "        [-2.5727, -4.0660, -4.0125,  ..., -5.4783,  5.9708, 13.0644],\n",
      "        [-2.5727, -4.0660, -4.0125,  ..., -5.4783,  5.9708, 13.0644],\n",
      "        ...,\n",
      "        [-4.3138, -3.8382, -5.7259,  ..., 12.0982, -2.5564, -2.7490],\n",
      "        [-4.4611, -3.6574, -4.6579,  ..., 11.3581, -2.6010, -2.2811],\n",
      "        [-4.2038, -4.2630, -5.7143,  ..., 11.1165, -2.9647, -2.9951]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8831, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2198,  321, 2414,  ..., 3061, 3814, 4970],\n",
      "        [4670,  285, 2995,  ...,   35, 1020,  131],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4670,  285, 2995,  ...,   35, 1020,  131],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5721, -4.0656, -4.0137,  ..., -5.4788,  5.9671, 13.0692],\n",
      "        [-2.5721, -4.0656, -4.0137,  ..., -5.4788,  5.9671, 13.0692],\n",
      "        [-2.5721, -4.0656, -4.0137,  ..., -5.4788,  5.9671, 13.0692],\n",
      "        ...,\n",
      "        [-4.5648, -3.5548, -5.1051,  ..., 11.5283, -2.8211, -2.4835],\n",
      "        [-3.6108, -3.0827, -4.7334,  ...,  6.8407, -2.8045, -3.0249],\n",
      "        [-4.5773, -4.1307, -5.1548,  ...,  9.2936, -2.7637, -2.2178]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9380, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 394, 2167, 2396,  ..., 1018, 2349, 3669],\n",
      "        [2691, 2369, 5027,  ..., 1711, 2059, 2602],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2691, 2369, 5027,  ..., 1711, 2059, 2602],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5719, -4.0655, -4.0148,  ..., -5.4787,  5.9633, 13.0736],\n",
      "        [-2.5719, -4.0655, -4.0148,  ..., -5.4787,  5.9633, 13.0736],\n",
      "        [-2.5719, -4.0655, -4.0148,  ..., -5.4787,  5.9633, 13.0736],\n",
      "        ...,\n",
      "        [-4.3762, -3.6235, -4.5251,  ..., 10.0879, -2.9165, -2.3907],\n",
      "        [-4.5577, -3.7723, -4.5847,  ..., 11.4066, -3.4325, -2.7967],\n",
      "        [-4.1512, -4.0760, -4.5676,  ..., 10.1516, -1.7775, -2.1637]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8769, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 893, 1452, 3040,  ..., 1271,  712, 2273],\n",
      "        [3406, 4623, 1376,  ..., 4679, 3365, 3772],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3406, 4623, 1376,  ..., 4679, 3365, 3772],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5719, -4.0649, -4.0159,  ..., -5.4784,  5.9583, 13.0790],\n",
      "        [-2.5719, -4.0649, -4.0159,  ..., -5.4784,  5.9583, 13.0790],\n",
      "        [-2.5719, -4.0649, -4.0159,  ..., -5.4784,  5.9583, 13.0790],\n",
      "        ...,\n",
      "        [-2.7955, -4.0322, -5.5163,  ...,  3.8512, -2.4477, -2.6207],\n",
      "        [-4.0286, -3.8694, -5.1875,  ...,  8.2085, -3.1600, -3.1186],\n",
      "        [-4.0900, -3.9497, -5.1384,  ...,  9.8808, -3.0578, -3.1822]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9849, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2603, 2586, 3814,  ...,  114,  408, 3292],\n",
      "        [3121, 2058, 1020,  ..., 2934, 1366, 4653],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3121, 2058, 1020,  ..., 2934, 1366, 4653],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5722, -4.0628, -4.0169,  ..., -5.4787,  5.9553, 13.0820],\n",
      "        [-2.5722, -4.0628, -4.0169,  ..., -5.4787,  5.9553, 13.0820],\n",
      "        [-2.5722, -4.0628, -4.0169,  ..., -5.4787,  5.9553, 13.0820],\n",
      "        ...,\n",
      "        [-4.1620, -4.2848, -5.8859,  ...,  9.2655, -2.8347, -2.5088],\n",
      "        [-3.9374, -3.9343, -5.1481,  ...,  9.8439, -3.3102, -3.3936],\n",
      "        [-4.2399, -3.7483, -5.2092,  ..., 10.3407, -3.1821, -3.1183]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7859, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2732, 2267, 2930,  ..., 2256, 1126, 4265],\n",
      "        [3480, 1360, 2624,  ..., 4487, 1399, 1980],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3480, 1360, 2624,  ..., 4487, 1399, 1980],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5727, -4.0603, -4.0178,  ..., -5.4788,  5.9503, 13.0873],\n",
      "        [-2.5727, -4.0603, -4.0178,  ..., -5.4788,  5.9503, 13.0873],\n",
      "        [-2.5727, -4.0603, -4.0178,  ..., -5.4788,  5.9503, 13.0873],\n",
      "        ...,\n",
      "        [-4.3509, -4.4806, -5.9817,  ..., 11.4874, -2.5694, -2.5011],\n",
      "        [-4.5284, -4.2144, -5.7734,  ..., 11.6269, -2.4747, -2.5322],\n",
      "        [-4.4404, -3.8052, -5.3434,  ..., 10.4344, -3.4094, -3.4446]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9715, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2599, 2369, 4370,  ..., 2629,  366,  593],\n",
      "        [1752, 4168, 4679,  ...,  768, 4176, 1384],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1752, 4168, 4679,  ...,  768, 4176, 1384],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5736, -4.0583, -4.0189,  ..., -5.4784,  5.9473, 13.0910],\n",
      "        [-2.5736, -4.0583, -4.0189,  ..., -5.4784,  5.9473, 13.0910],\n",
      "        [-2.5736, -4.0583, -4.0189,  ..., -5.4784,  5.9473, 13.0910],\n",
      "        ...,\n",
      "        [-4.2152, -3.9785, -5.4579,  ..., 10.1476, -2.8112, -3.1614],\n",
      "        [-4.6049, -3.7853, -4.8741,  ..., 11.2928, -2.6921, -2.2846],\n",
      "        [-4.2868, -4.3412, -5.8356,  ..., 11.0707, -2.9645, -3.0968]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7382, grad_fn=<NllLossBackward>)\n",
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花李。', '月下，一番花下、一番春色。', '夜蓉雨。', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番花开酒。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  35,  363, 1086,  ..., 1639, 4866, 3712],\n",
      "        [ 792, 5243, 2773,  ..., 2629,  321, 4679],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 792, 5243, 2773,  ..., 2629,  321, 4679],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5746, -4.0567, -4.0200,  ..., -5.4783,  5.9438, 13.0953],\n",
      "        [-2.5746, -4.0567, -4.0200,  ..., -5.4783,  5.9438, 13.0953],\n",
      "        [-2.5746, -4.0567, -4.0200,  ..., -5.4783,  5.9438, 13.0953],\n",
      "        ...,\n",
      "        [-3.9313, -4.3643, -6.0743,  ..., 11.3789, -2.9623, -2.9818],\n",
      "        [-4.3620, -3.7635, -4.6437,  ...,  9.6011, -2.4961, -2.8419],\n",
      "        [-4.1997, -4.1112, -5.6415,  ...,  9.9334, -2.8723, -2.7679]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9011, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1192, 2779, 2629,  ..., 1192, 1913, 2343],\n",
      "        [3279, 2425, 1081,  ..., 1597, 1120, 1017],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3279, 2425, 1081,  ..., 1597, 1120, 1017],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5757, -4.0555, -4.0211,  ..., -5.4786,  5.9418, 13.0984],\n",
      "        [-2.5757, -4.0555, -4.0211,  ..., -5.4786,  5.9418, 13.0984],\n",
      "        [-2.5757, -4.0555, -4.0211,  ..., -5.4786,  5.9418, 13.0984],\n",
      "        ...,\n",
      "        [-4.7513, -3.6908, -4.8055,  ..., 11.7911, -3.0983, -2.9550],\n",
      "        [-3.4371, -3.9000, -5.2211,  ...,  8.1050, -3.1293, -2.8634],\n",
      "        [-4.1265, -3.6564, -5.0874,  ..., 11.2919, -3.1332, -2.9813]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9712, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3563, 2369,   96,  ..., 3885, 2979, 2383],\n",
      "        [1502,  843, 4644,  ..., 1535,   53, 3583],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1502,  843, 4644,  ..., 1535,   53, 3583],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5770, -4.0546, -4.0195,  ..., -5.4794,  5.9415, 13.0992],\n",
      "        [-2.5770, -4.0546, -4.0195,  ..., -5.4794,  5.9415, 13.0992],\n",
      "        [-2.5770, -4.0546, -4.0195,  ..., -5.4794,  5.9415, 13.0992],\n",
      "        ...,\n",
      "        [-4.2261, -3.4937, -4.7335,  ..., 10.8528, -3.5566, -3.5973],\n",
      "        [-4.1720, -4.1263, -5.6213,  ..., 11.5849, -3.0467, -3.0651],\n",
      "        [-4.9631, -3.7143, -4.3423,  ..., 10.3203, -2.3551, -2.1475]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8246, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2926, 2045, 1579,  ..., 4944, 3878, 4470],\n",
      "        [5009, 1081, 2058,  ..., 4052, 4944, 3668],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5009, 1081, 2058,  ..., 4052, 4944, 3668],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5783, -4.0538, -4.0180,  ..., -5.4804,  5.9414, 13.1000],\n",
      "        [-2.5783, -4.0538, -4.0180,  ..., -5.4804,  5.9414, 13.1000],\n",
      "        [-2.5783, -4.0538, -4.0180,  ..., -5.4804,  5.9414, 13.1000],\n",
      "        ...,\n",
      "        [-4.0360, -3.8497, -5.6163,  ..., 10.4369, -3.0085, -3.0289],\n",
      "        [-3.7898, -3.8813, -5.8206,  ...,  9.3362, -2.6106, -2.6277],\n",
      "        [-3.9775, -3.8669, -5.4051,  ..., 10.7211, -3.3833, -3.5016]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0260, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1452, 1748, 1271,  ..., 4882, 3480, 3542],\n",
      "        [ 745, 2913, 2000,  ..., 4525, 1787,  965],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 745, 2913, 2000,  ..., 4525, 1787,  965],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5798, -4.0528, -4.0167,  ..., -5.4810,  5.9437, 13.0978],\n",
      "        [-2.5798, -4.0528, -4.0167,  ..., -5.4810,  5.9437, 13.0978],\n",
      "        [-2.5798, -4.0528, -4.0167,  ..., -5.4810,  5.9437, 13.0978],\n",
      "        ...,\n",
      "        [-3.3579, -4.4270, -5.6574,  ...,  4.6812, -2.2109, -2.6633],\n",
      "        [-4.2566, -3.5019, -4.4750,  ...,  8.4586, -2.6677, -2.5068],\n",
      "        [-4.3713, -4.2764, -5.8899,  ..., 11.7649, -2.9065, -3.0769]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8650, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5159, 3547, 2013,  ..., 2486,  337, 1579],\n",
      "        [ 574, 4812, 4348,  ..., 1318, 3217, 2058],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 574, 4812, 4348,  ..., 1318, 3217, 2058],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5813, -4.0522, -4.0157,  ..., -5.4811,  5.9448, 13.0963],\n",
      "        [-2.5813, -4.0522, -4.0157,  ..., -5.4811,  5.9448, 13.0963],\n",
      "        [-2.5813, -4.0522, -4.0157,  ..., -5.4811,  5.9448, 13.0963],\n",
      "        ...,\n",
      "        [-4.3355, -4.3109, -4.9521,  ...,  9.8441, -2.8332, -2.7675],\n",
      "        [-4.2998, -3.8968, -5.1928,  ..., 11.0249, -3.2697, -3.2812],\n",
      "        [-4.6203, -3.8692, -5.2777,  ..., 10.8315, -3.0409, -2.8878]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9120, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3665, 4484, 1010,  ..., 2616, 4970, 1844],\n",
      "        [5201, 2785, 2763,  ..., 1042, 2320, 1844],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5201, 2785, 2763,  ..., 1042, 2320, 1844],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5830, -4.0505, -4.0148,  ..., -5.4814,  5.9453, 13.0956],\n",
      "        [-2.5830, -4.0505, -4.0148,  ..., -5.4814,  5.9453, 13.0956],\n",
      "        [-2.5830, -4.0505, -4.0148,  ..., -5.4814,  5.9453, 13.0956],\n",
      "        ...,\n",
      "        [-4.2846, -4.4205, -5.6768,  ..., 11.4668, -2.7182, -2.8889],\n",
      "        [-4.4435, -3.8829, -5.1870,  ..., 10.4882, -3.3314, -3.1694],\n",
      "        [-4.1283, -4.2836, -5.6641,  ..., 10.7030, -2.6451, -2.9353]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9000, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4321, 1158, 1192,  ..., 2383, 2064, 1539],\n",
      "        [ 366, 1828, 4838,  ..., 3575,  129, 4534],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 366, 1828, 4838,  ..., 3575,  129, 4534],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5848, -4.0492, -4.0143,  ..., -5.4826,  5.9456, 13.0955],\n",
      "        [-2.5848, -4.0492, -4.0143,  ..., -5.4826,  5.9456, 13.0955],\n",
      "        [-2.5848, -4.0492, -4.0143,  ..., -5.4826,  5.9456, 13.0955],\n",
      "        ...,\n",
      "        [-3.9533, -4.1722, -5.7214,  ...,  8.0264, -2.6733, -2.9179],\n",
      "        [-4.3398, -4.5066, -5.7526,  ..., 10.0110, -3.1967, -3.3894],\n",
      "        [-4.1017, -3.7710, -5.3089,  ..., 10.5383, -2.9122, -3.0933]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9383, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1331, 3693,  509,  ..., 4265, 3598, 4265],\n",
      "        [4753, 3693,   43,  ..., 3273, 3030, 3521],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4753, 3693,   43,  ..., 3273, 3030, 3521],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5849, -4.0477, -4.0113,  ..., -5.4843,  5.9456, 13.0959],\n",
      "        [-2.5849, -4.0477, -4.0113,  ..., -5.4843,  5.9456, 13.0959],\n",
      "        [-2.5849, -4.0477, -4.0113,  ..., -5.4843,  5.9456, 13.0959],\n",
      "        ...,\n",
      "        [-4.0110, -3.5342, -4.4294,  ...,  9.8665, -3.3477, -3.0709],\n",
      "        [-4.3403, -3.7089, -5.7217,  ...,  9.3630, -2.7374, -2.9274],\n",
      "        [-4.3273, -3.8309, -6.0170,  ..., 10.6119, -2.3161, -2.5596]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9596, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2414,  890, 2742,  ..., 1661, 1405,  965],\n",
      "        [2219,  524,  657,  ..., 3382,   51, 3331],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2219,  524,  657,  ..., 3382,   51, 3331],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5842, -4.0458, -4.0085,  ..., -5.4854,  5.9465, 13.0950],\n",
      "        [-2.5842, -4.0458, -4.0085,  ..., -5.4854,  5.9465, 13.0950],\n",
      "        [-2.5842, -4.0458, -4.0085,  ..., -5.4854,  5.9465, 13.0950],\n",
      "        ...,\n",
      "        [-4.3999, -4.0047, -5.2184,  ..., 11.5076, -2.3889, -2.5588],\n",
      "        [-4.3797, -3.9728, -5.5296,  ..., 12.2185, -2.8271, -2.8619],\n",
      "        [-4.8477, -3.9247, -5.2701,  ..., 12.0479, -3.0174, -3.0037]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7553, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [   4,  301,  851,  ..., 5183, 3668, 3795],\n",
      "        [4548, 5128, 3568,  ..., 5183, 3509, 5230],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4548, 5128, 3568,  ..., 5183, 3509, 5230],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5838, -4.0444, -4.0060,  ..., -5.4862,  5.9457, 13.0957],\n",
      "        [-2.5838, -4.0444, -4.0060,  ..., -5.4862,  5.9457, 13.0957],\n",
      "        [-2.5838, -4.0444, -4.0060,  ..., -5.4862,  5.9457, 13.0957],\n",
      "        ...,\n",
      "        [-4.9077, -4.3904, -5.2580,  ...,  8.9009, -1.2032, -1.3239],\n",
      "        [-4.5701, -4.2045, -5.2722,  ..., 11.2764, -2.8188, -2.7033],\n",
      "        [-5.0717, -3.9071, -5.1839,  ..., 11.4392, -2.7623, -2.5805]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8385, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3949, 2383, 2732,  ...,  388, 2017, 5077],\n",
      "        [ 321, 3575, 4450,  ..., 2089, 2699, 2399],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 321, 3575, 4450,  ..., 2089, 2699, 2399],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5825, -4.0434, -4.0038,  ..., -5.4872,  5.9437, 13.0978],\n",
      "        [-2.5825, -4.0434, -4.0038,  ..., -5.4872,  5.9437, 13.0978],\n",
      "        [-2.5825, -4.0434, -4.0038,  ..., -5.4872,  5.9437, 13.0978],\n",
      "        ...,\n",
      "        [-4.9488, -3.7782, -4.7819,  ..., 10.8966, -2.9814, -2.8786],\n",
      "        [-4.5673, -4.0470, -5.8563,  ..., 12.1868, -2.4074, -2.4678],\n",
      "        [-3.6631, -3.4800, -4.6728,  ...,  8.8010, -3.5652, -3.6068]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8925, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5241,  114, 2779,  ...,  379,  995,  215],\n",
      "        [4679, 3417, 1004,  ..., 2848, 5009, 2732],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4679, 3417, 1004,  ..., 2848, 5009, 2732],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5815, -4.0427, -4.0019,  ..., -5.4881,  5.9412, 13.1002],\n",
      "        [-2.5815, -4.0427, -4.0019,  ..., -5.4881,  5.9412, 13.1002],\n",
      "        [-2.5815, -4.0427, -4.0019,  ..., -5.4881,  5.9412, 13.1002],\n",
      "        ...,\n",
      "        [-4.3401, -3.9645, -6.0460,  ..., 10.8903, -3.0785, -2.9740],\n",
      "        [-4.1419, -3.6050, -5.2294,  ..., 10.6832, -3.2973, -3.0927],\n",
      "        [-3.8506, -3.9958, -5.3986,  ...,  5.1334, -2.1038, -2.1242]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8084, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 339, 2838, 3096,  ..., 4021,  432, 3710],\n",
      "        [  49, 1232, 4746,  ..., 1230, 1452, 4416],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  49, 1232, 4746,  ..., 1230, 1452, 4416],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5808, -4.0424, -4.0001,  ..., -5.4895,  5.9379, 13.1038],\n",
      "        [-2.5808, -4.0424, -4.0001,  ..., -5.4895,  5.9379, 13.1038],\n",
      "        [-2.5808, -4.0424, -4.0001,  ..., -5.4895,  5.9379, 13.1038],\n",
      "        ...,\n",
      "        [-4.7415, -3.9630, -4.9808,  ..., 11.9628, -3.3150, -2.9821],\n",
      "        [-3.8609, -3.6607, -4.3976,  ...,  8.9744, -3.0767, -3.4207],\n",
      "        [-3.6341, -3.8746, -4.5858,  ...,  5.3080, -2.3104, -2.9290]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9362, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2622, 4305, 1888,  ..., 4905, 4947, 4158],\n",
      "        [3665, 1959, 1502,  ..., 3290, 2389, 1680],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3665, 1959, 1502,  ..., 3290, 2389, 1680],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5804, -4.0423, -3.9986,  ..., -5.4914,  5.9365, 13.1059],\n",
      "        [-2.5804, -4.0423, -3.9986,  ..., -5.4914,  5.9365, 13.1059],\n",
      "        [-2.5804, -4.0423, -3.9986,  ..., -5.4914,  5.9365, 13.1059],\n",
      "        ...,\n",
      "        [-4.5338, -4.2192, -5.6149,  ..., 12.1187, -2.9131, -2.7976],\n",
      "        [-4.4351, -4.3026, -5.6165,  ..., 11.1903, -3.0413, -3.1116],\n",
      "        [-4.0369, -3.9551, -5.6307,  ..., 10.6711, -3.2321, -3.5276]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8665, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1649, 4793, 2793,  ..., 2141,  114, 2460],\n",
      "        [1693, 5027, 3417,  ..., 1064, 1194, 4811],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1693, 5027, 3417,  ..., 1064, 1194, 4811],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5803, -4.0425, -3.9975,  ..., -5.4939,  5.9341, 13.1089],\n",
      "        [-2.5803, -4.0425, -3.9975,  ..., -5.4939,  5.9341, 13.1089],\n",
      "        [-2.5803, -4.0425, -3.9975,  ..., -5.4939,  5.9341, 13.1089],\n",
      "        ...,\n",
      "        [-4.4893, -3.8223, -5.1364,  ..., 10.8142, -3.3251, -3.0482],\n",
      "        [-3.3552, -3.6953, -5.5081,  ...,  8.3578, -2.9057, -3.3742],\n",
      "        [-3.5918, -3.8153, -5.2368,  ...,  5.9924, -2.0370, -2.1007]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7880, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3898,  527,  672,  ..., 3318,   20, 3844],\n",
      "        [4305, 3500, 2349,  ..., 2369, 4037, 3844],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4305, 3500, 2349,  ..., 2369, 4037, 3844],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5804, -4.0429, -3.9934,  ..., -5.4956,  5.9303, 13.1132],\n",
      "        [-2.5804, -4.0429, -3.9934,  ..., -5.4956,  5.9303, 13.1132],\n",
      "        [-2.5804, -4.0429, -3.9934,  ..., -5.4956,  5.9303, 13.1132],\n",
      "        ...,\n",
      "        [-4.5023, -3.8112, -4.2584,  ...,  9.8336, -3.0780, -3.1946],\n",
      "        [-4.0651, -3.8961, -5.6221,  ...,  9.2447, -3.1382, -3.2202],\n",
      "        [-4.4108, -3.9517, -5.4746,  ...,  7.8072, -2.6969, -2.7314]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0123, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 745, 4305, 4346,  ..., 5102,  262,  321],\n",
      "        [4340, 3409, 4957,  ..., 4052, 1164, 2934],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4340, 3409, 4957,  ..., 4052, 1164, 2934],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5791, -4.0436, -3.9884,  ..., -5.4969,  5.9292, 13.1144],\n",
      "        [-2.5791, -4.0436, -3.9884,  ..., -5.4969,  5.9292, 13.1144],\n",
      "        [-2.5791, -4.0436, -3.9884,  ..., -5.4969,  5.9292, 13.1144],\n",
      "        ...,\n",
      "        [-3.9931, -3.6721, -5.4092,  ..., 10.7699, -2.9678, -3.1069],\n",
      "        [-4.3811, -3.8426, -4.4106,  ..., 10.4079, -3.1691, -2.6224],\n",
      "        [-4.3658, -3.8617, -4.8043,  ..., 10.8510, -3.4838, -3.4404]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9230, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 148, 5108, 2653,  ..., 3022, 1301,  366],\n",
      "        [1638, 3505, 3705,  ..., 1427, 3087, 3355],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1638, 3505, 3705,  ..., 1427, 3087, 3355],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5783, -4.0441, -3.9843,  ..., -5.4972,  5.9294, 13.1142],\n",
      "        [-2.5783, -4.0441, -3.9843,  ..., -5.4972,  5.9294, 13.1142],\n",
      "        [-2.5783, -4.0441, -3.9843,  ..., -5.4972,  5.9294, 13.1142],\n",
      "        ...,\n",
      "        [-4.4922, -3.7611, -5.2795,  ..., 10.7240, -3.5314, -3.3957],\n",
      "        [-4.3129, -4.0996, -4.9169,  ..., 11.8504, -3.2099, -2.8533],\n",
      "        [-4.5814, -4.3211, -5.3680,  ..., 10.8900, -2.3885, -2.3383]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9322, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 712,  851, 3878,  ...,  325, 3171, 3563],\n",
      "        [4031, 1452,  740,  ..., 2058, 1240,  466],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4031, 1452,  740,  ..., 2058, 1240,  466],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5778, -4.0450, -3.9808,  ..., -5.4979,  5.9299, 13.1141],\n",
      "        [-2.5778, -4.0450, -3.9808,  ..., -5.4979,  5.9299, 13.1141],\n",
      "        [-2.5778, -4.0450, -3.9808,  ..., -5.4979,  5.9299, 13.1141],\n",
      "        ...,\n",
      "        [-4.1234, -3.8196, -5.7868,  ...,  9.3703, -3.2247, -3.3460],\n",
      "        [-4.3292, -4.3497, -5.9105,  ..., 11.9524, -2.7059, -2.7863],\n",
      "        [-4.1293, -3.7702, -5.1636,  ..., 10.2611, -3.2337, -3.2522]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8517, grad_fn=<NllLossBackward>)\n",
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花李。', '月下，一番花下、一番春色。', '夜蓉雨。', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番花开舞。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3568, 4439, 4110,  ..., 4708,  513,  955],\n",
      "        [2732, 5117, 1457,  ..., 3800, 4487, 1100],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2732, 5117, 1457,  ..., 3800, 4487, 1100],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5775, -4.0448, -3.9762,  ..., -5.4997,  5.9297, 13.1151],\n",
      "        [-2.5775, -4.0448, -3.9762,  ..., -5.4997,  5.9297, 13.1151],\n",
      "        [-2.5775, -4.0448, -3.9762,  ..., -5.4997,  5.9297, 13.1151],\n",
      "        ...,\n",
      "        [-4.8036, -3.6822, -4.5391,  ...,  9.7939, -3.4379, -3.2296],\n",
      "        [-4.5344, -3.6231, -4.7208,  ..., 11.8155, -2.9881, -2.8900],\n",
      "        [-4.6853, -3.5139, -4.4752,  ..., 10.8316, -2.6562, -2.5527]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7714, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4204, 5214, 1158,  ..., 3021, 2256, 2947],\n",
      "        [1911, 3085, 1959,  ..., 3729, 3404, 4866],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1911, 3085, 1959,  ..., 3729, 3404, 4866],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5759, -4.0449, -3.9723,  ..., -5.5027,  5.9274, 13.1191],\n",
      "        [-2.5759, -4.0449, -3.9723,  ..., -5.5027,  5.9274, 13.1191],\n",
      "        [-2.5759, -4.0449, -3.9723,  ..., -5.5027,  5.9274, 13.1191],\n",
      "        ...,\n",
      "        [-4.2130, -3.8203, -5.3830,  ..., 10.6571, -3.0363, -2.8189],\n",
      "        [-3.8655, -3.7244, -4.7982,  ...,  9.0182, -3.2446, -3.2998],\n",
      "        [-4.5872, -3.8739, -4.6480,  ..., 11.6946, -2.6343, -2.4454]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9373, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2915,  432, 1452,  ..., 2942, 4654, 4368],\n",
      "        [3670, 5027,  531,  ..., 2347, 2157, 2349],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3670, 5027,  531,  ..., 2347, 2157, 2349],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5747, -4.0452, -3.9688,  ..., -5.5047,  5.9264, 13.1214],\n",
      "        [-2.5747, -4.0452, -3.9688,  ..., -5.5047,  5.9264, 13.1214],\n",
      "        [-2.5747, -4.0452, -3.9688,  ..., -5.5047,  5.9264, 13.1214],\n",
      "        ...,\n",
      "        [-4.3312, -3.5409, -5.2838,  ...,  9.1436, -2.2479, -2.2931],\n",
      "        [-4.0661, -4.0633, -5.8446,  ...,  8.0959, -2.2950, -2.4071],\n",
      "        [-4.8080, -4.2638, -4.9416,  ..., 11.0122, -3.1807, -2.8994]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9828, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [   4,    4,  712,  ..., 3331, 5081, 4297],\n",
      "        [ 657, 4548, 4870,  ..., 2227, 1452,  709],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 657, 4548, 4870,  ..., 2227, 1452,  709],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5740, -4.0458, -3.9655,  ..., -5.5052,  5.9271, 13.1211],\n",
      "        [-2.5740, -4.0458, -3.9655,  ..., -5.5052,  5.9271, 13.1211],\n",
      "        [-2.5740, -4.0458, -3.9655,  ..., -5.5052,  5.9271, 13.1211],\n",
      "        ...,\n",
      "        [-4.1872, -4.3948, -5.5784,  ..., 10.6105, -2.7972, -3.1415],\n",
      "        [-3.9481, -4.3022, -5.7612,  ..., 10.6543, -2.6272, -2.7124],\n",
      "        [-4.3028, -3.8452, -5.3302,  ..., 11.9638, -2.6669, -2.7360]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8806, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3878, 1266, 2414,  ..., 4716, 4168, 2961],\n",
      "        [4340, 3021, 3228,  ..., 3048,  965, 4204],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4340, 3021, 3228,  ..., 3048,  965, 4204],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5737, -4.0450, -3.9626,  ..., -5.5064,  5.9291, 13.1198],\n",
      "        [-2.5737, -4.0450, -3.9626,  ..., -5.5064,  5.9291, 13.1198],\n",
      "        [-2.5737, -4.0450, -3.9626,  ..., -5.5064,  5.9291, 13.1198],\n",
      "        ...,\n",
      "        [-4.3125, -4.1523, -5.8764,  ..., 11.8719, -2.9389, -3.0340],\n",
      "        [-4.3310, -4.3883, -4.9854,  ..., 11.5703, -2.9086, -3.0667],\n",
      "        [-3.5012, -3.7701, -5.0769,  ...,  8.5344, -3.2598, -3.7029]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7759, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 965, 2789, 2414,  ..., 4326, 2472, 1309],\n",
      "        [ 509, 1750, 2017,  ...,  982, 2822, 4895],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 509, 1750, 2017,  ...,  982, 2822, 4895],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5736, -4.0446, -3.9599,  ..., -5.5077,  5.9304, 13.1190],\n",
      "        [-2.5736, -4.0446, -3.9599,  ..., -5.5077,  5.9304, 13.1190],\n",
      "        [-2.5736, -4.0446, -3.9599,  ..., -5.5077,  5.9304, 13.1190],\n",
      "        ...,\n",
      "        [-4.7087, -3.6916, -4.6370,  ..., 10.8346, -3.1536, -2.8892],\n",
      "        [-4.6475, -3.8174, -4.5790,  ..., 11.6493, -2.6748, -2.4866],\n",
      "        [-4.2122, -3.8212, -5.3866,  ...,  9.8849, -2.9373, -3.0528]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9544, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1054, 4526,  851,  ...,  790, 2991, 4723],\n",
      "        [1614,  379, 3252,  ...,  974, 3022, 4465],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1614,  379, 3252,  ...,  974, 3022, 4465],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5736, -4.0430, -3.9577,  ..., -5.5100,  5.9318, 13.1183],\n",
      "        [-2.5736, -4.0430, -3.9577,  ..., -5.5100,  5.9318, 13.1183],\n",
      "        [-2.5736, -4.0430, -3.9577,  ..., -5.5100,  5.9318, 13.1183],\n",
      "        ...,\n",
      "        [-3.5539, -3.8323, -4.3908,  ...,  4.4838, -2.2239, -2.4553],\n",
      "        [-4.2403, -3.6659, -4.7595,  ...,  8.7675, -3.3450, -3.3714],\n",
      "        [-4.6160, -4.0677, -4.7587,  ..., 11.1952, -3.2421, -2.8975]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7590, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3258, 5203, 3321,  ..., 3712, 5240, 1131],\n",
      "        [  35, 3030,  995,  ...,  105, 2773, 4439],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  35, 3030,  995,  ...,  105, 2773, 4439],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5739, -4.0406, -3.9558,  ..., -5.5132,  5.9300, 13.1212],\n",
      "        [-2.5739, -4.0406, -3.9558,  ..., -5.5132,  5.9300, 13.1212],\n",
      "        [-2.5739, -4.0406, -3.9558,  ..., -5.5132,  5.9300, 13.1212],\n",
      "        ...,\n",
      "        [-3.9873, -4.3551, -5.4158,  ..., 10.8361, -2.6585, -2.8608],\n",
      "        [-3.7881, -3.9298, -5.5631,  ..., 10.4519, -3.0873, -3.2161],\n",
      "        [-4.8096, -4.0245, -5.1507,  ..., 11.5965, -2.8978, -2.7343]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7097, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4890, 1004, 3814,  ..., 3175, 3500,  996],\n",
      "        [2579, 4913, 1020,  ..., 3175, 1427, 1150],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2579, 4913, 1020,  ..., 3175, 1427, 1150],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5744, -4.0386, -3.9540,  ..., -5.5162,  5.9267, 13.1258],\n",
      "        [-2.5744, -4.0386, -3.9540,  ..., -5.5162,  5.9267, 13.1258],\n",
      "        [-2.5744, -4.0386, -3.9540,  ..., -5.5162,  5.9267, 13.1258],\n",
      "        ...,\n",
      "        [-4.3539, -3.6629, -5.1191,  ..., 10.2037, -2.2002, -2.0409],\n",
      "        [-4.7335, -4.1163, -5.5714,  ..., 11.7481, -3.2188, -3.0939],\n",
      "        [-4.6182, -4.4246, -5.6428,  ..., 11.9539, -2.5546, -2.5764]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9330, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2378, 1111, 1158,  ..., 3331, 3283, 3152],\n",
      "        [4467, 1522, 5107,  ..., 2809, 4193, 4987],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4467, 1522, 5107,  ..., 2809, 4193, 4987],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5753, -4.0369, -3.9525,  ..., -5.5176,  5.9244, 13.1288],\n",
      "        [-2.5753, -4.0369, -3.9525,  ..., -5.5176,  5.9244, 13.1288],\n",
      "        [-2.5753, -4.0369, -3.9525,  ..., -5.5176,  5.9244, 13.1288],\n",
      "        ...,\n",
      "        [-3.9303, -4.2303, -5.5197,  ...,  9.8601, -2.7877, -3.0702],\n",
      "        [-3.9103, -3.4392, -5.0818,  ..., 10.0121, -3.8058, -3.9076],\n",
      "        [-4.0220, -3.7453, -5.7199,  ...,  7.6159, -2.3996, -2.6436]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7713, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4737,  301, 4052,  ..., 4753, 3428,  522],\n",
      "        [4957, 3021, 1240,  ..., 3049, 5033, 2243],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4957, 3021, 1240,  ..., 3049, 5033, 2243],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5764, -4.0345, -3.9509,  ..., -5.5168,  5.9215, 13.1317],\n",
      "        [-2.5764, -4.0345, -3.9509,  ..., -5.5168,  5.9215, 13.1317],\n",
      "        [-2.5764, -4.0345, -3.9509,  ..., -5.5168,  5.9215, 13.1317],\n",
      "        ...,\n",
      "        [-4.0217, -3.8744, -5.5470,  ..., 11.0365, -3.0643, -3.2820],\n",
      "        [-4.8054, -3.9150, -5.2309,  ..., 11.2986, -3.0826, -3.0789],\n",
      "        [-4.2896, -3.6566, -5.0563,  ...,  8.2606, -2.4680, -2.2415]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8628, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3933,  832, 3878,  ..., 4905,  411,  159],\n",
      "        [3286, 3092, 3008,  ..., 3584, 5189, 1460],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3286, 3092, 3008,  ..., 3584, 5189, 1460],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5754, -4.0325, -3.9495,  ..., -5.5159,  5.9184, 13.1344],\n",
      "        [-2.5754, -4.0325, -3.9495,  ..., -5.5159,  5.9184, 13.1344],\n",
      "        [-2.5754, -4.0325, -3.9495,  ..., -5.5159,  5.9184, 13.1344],\n",
      "        ...,\n",
      "        [-3.1628, -3.9328, -5.6980,  ...,  5.9876, -2.7470, -3.1859],\n",
      "        [-4.4684, -3.6325, -4.8931,  ..., 11.2675, -3.1379, -2.6768],\n",
      "        [-4.2035, -3.4839, -4.1965,  ...,  8.7575, -3.3934, -3.2514]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8691, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5275, 3400,  593,  ..., 2941, 4052, 4032],\n",
      "        [2058, 2058, 2058,  ...,  965, 1281, 4176],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2058, 2058, 2058,  ...,  965, 1281, 4176],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5746, -4.0308, -3.9485,  ..., -5.5165,  5.9150, 13.1376],\n",
      "        [-2.5746, -4.0308, -3.9485,  ..., -5.5165,  5.9150, 13.1376],\n",
      "        [-2.5746, -4.0308, -3.9485,  ..., -5.5165,  5.9150, 13.1376],\n",
      "        ...,\n",
      "        [-4.2905, -3.5751, -4.1178,  ..., 10.8158, -2.8388, -2.6997],\n",
      "        [-4.8595, -3.7644, -4.3235,  ..., 11.2091, -2.9991, -2.3867],\n",
      "        [-4.5013, -3.7141, -5.1051,  ..., 11.5508, -2.7737, -2.6609]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(2.0052, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2907, 1116, 3383,  ..., 1016, 5236, 2947],\n",
      "        [4838, 4052, 5088,  ..., 4753,  740, 1947],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4838, 4052, 5088,  ..., 4753,  740, 1947],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5742, -4.0286, -3.9481,  ..., -5.5185,  5.9132, 13.1397],\n",
      "        [-2.5742, -4.0286, -3.9481,  ..., -5.5185,  5.9132, 13.1397],\n",
      "        [-2.5742, -4.0286, -3.9481,  ..., -5.5185,  5.9132, 13.1397],\n",
      "        ...,\n",
      "        [-4.9010, -3.7796, -4.9149,  ..., 11.5557, -2.7523, -2.3610],\n",
      "        [-3.6598, -3.6966, -5.1038,  ...,  9.1361, -2.8429, -2.8413],\n",
      "        [-4.8647, -3.9713, -5.5912,  ..., 12.5392, -2.6794, -2.6814]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9694, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5295, 4880, 1271,  ..., 2691, 2947, 2809],\n",
      "        [5295, 1212, 2181,  ..., 3544, 4087, 4753],\n",
      "        [5294,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5295, 1212, 2181,  ..., 3544, 4087, 4753],\n",
      "        [5294,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5741, -4.0269, -3.9478,  ..., -5.5207,  5.9139, 13.1398],\n",
      "        [-2.5741, -4.0269, -3.9478,  ..., -5.5207,  5.9139, 13.1398],\n",
      "        [-2.5741, -4.0269, -3.9478,  ..., -5.5207,  5.9139, 13.1398],\n",
      "        ...,\n",
      "        [-4.5954, -3.6912, -5.3670,  ..., 11.1468, -2.3653, -2.4505],\n",
      "        [-4.4695, -4.5349, -5.9659,  ..., 11.4720, -2.9623, -2.9974],\n",
      "        [-4.7499, -3.7934, -4.6206,  ..., 11.6049, -2.3378, -2.1124]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8504, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3010, 3985, 2349,  ...,  574, 4530, 4750],\n",
      "        [ 683, 2608, 2059,  ..., 1192,  923, 2997],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 683, 2608, 2059,  ..., 1192,  923, 2997],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5743, -4.0251, -3.9474,  ..., -5.5209,  5.9169, 13.1368],\n",
      "        [-2.5743, -4.0251, -3.9474,  ..., -5.5209,  5.9169, 13.1368],\n",
      "        [-2.5743, -4.0251, -3.9474,  ..., -5.5209,  5.9169, 13.1368],\n",
      "        ...,\n",
      "        [-4.1621, -4.2992, -5.4351,  ..., 10.7737, -2.6671, -2.9853],\n",
      "        [-4.4337, -3.6700, -4.9326,  ..., 11.2536, -2.9781, -3.0726],\n",
      "        [-4.1440, -3.6585, -5.0126,  ..., 10.2404, -2.4693, -2.2866]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7581, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2414,  337, 1076,  ..., 4265, 2830, 5017],\n",
      "        [3021,  754, 1959,  ..., 3256, 1910, 4467],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3021,  754, 1959,  ..., 3256, 1910, 4467],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5734, -4.0236, -3.9468,  ..., -5.5197,  5.9188, 13.1346],\n",
      "        [-2.5734, -4.0236, -3.9468,  ..., -5.5197,  5.9188, 13.1346],\n",
      "        [-2.5734, -4.0236, -3.9468,  ..., -5.5197,  5.9188, 13.1346],\n",
      "        ...,\n",
      "        [-3.7522, -4.1715, -5.0953,  ...,  9.4710, -3.4376, -3.4435],\n",
      "        [-4.0812, -4.2746, -5.2621,  ..., 10.4794, -3.1174, -3.0122],\n",
      "        [-4.0999, -4.0690, -5.2221,  ..., 12.2014, -2.1976, -2.3103]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7678, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4526, 3693, 4533,  ..., 1158, 2159, 1271],\n",
      "        [1521, 3367,   49,  ..., 1448, 3668, 2934],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1521, 3367,   49,  ..., 1448, 3668, 2934],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5729, -4.0225, -3.9461,  ..., -5.5193,  5.9200, 13.1334],\n",
      "        [-2.5729, -4.0225, -3.9461,  ..., -5.5193,  5.9200, 13.1334],\n",
      "        [-2.5729, -4.0225, -3.9461,  ..., -5.5193,  5.9200, 13.1334],\n",
      "        ...,\n",
      "        [-2.5228, -3.9196, -5.5519,  ...,  4.0708, -2.2309, -2.4777],\n",
      "        [-4.2645, -3.9754, -5.3355,  ..., 10.5780, -3.0248, -2.9007],\n",
      "        [-3.9213, -3.9413, -5.5187,  ..., 10.4342, -3.0636, -3.2403]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9659, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2242, 5143, 1437,  ..., 1427,  321, 4899],\n",
      "        [2667,  325, 3880,  ..., 1526, 4465, 3505],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2667,  325, 3880,  ..., 1526, 4465, 3505],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5725, -4.0219, -3.9458,  ..., -5.5202,  5.9218, 13.1321],\n",
      "        [-2.5725, -4.0219, -3.9458,  ..., -5.5202,  5.9218, 13.1321],\n",
      "        [-2.5725, -4.0219, -3.9458,  ..., -5.5202,  5.9218, 13.1321],\n",
      "        ...,\n",
      "        [-4.7533, -3.9751, -4.8375,  ..., 11.1725, -2.6589, -2.7901],\n",
      "        [-4.2330, -4.0842, -5.2547,  ..., 11.1220, -3.2885, -3.3162],\n",
      "        [-3.9615, -4.3678, -5.7044,  ..., 10.4172, -2.8698, -2.8890]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0274, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3828, 2402,  572,  ...,  851, 2378, 4305],\n",
      "        [ 348, 4711, 3325,  ..., 1353, 4346, 1010],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 348, 4711, 3325,  ..., 1353, 4346, 1010],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5724, -4.0216, -3.9459,  ..., -5.5230,  5.9244, 13.1304],\n",
      "        [-2.5724, -4.0216, -3.9459,  ..., -5.5230,  5.9244, 13.1304],\n",
      "        [-2.5724, -4.0216, -3.9459,  ..., -5.5230,  5.9244, 13.1304],\n",
      "        ...,\n",
      "        [-3.6936, -3.7281, -4.6232,  ...,  9.0063, -3.3814, -3.4586],\n",
      "        [-4.0445, -3.8876, -4.7840,  ...,  7.7749, -3.4298, -3.4687],\n",
      "        [-4.2800, -3.4393, -4.5226,  ...,  8.8017, -2.9182, -3.3614]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8183, grad_fn=<NllLossBackward>)\n",
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花李。', '月下，一番花、一点春风。', '夜蓉雨。', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番花开舞。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1081, 3846, 4062,  ..., 3331,  965, 1618],\n",
      "        [2732,  890,  705,  ...,  861, 4052, 2369],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2732,  890,  705,  ...,  861, 4052, 2369],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5727, -4.0217, -3.9461,  ..., -5.5253,  5.9253, 13.1303],\n",
      "        [-2.5727, -4.0217, -3.9461,  ..., -5.5253,  5.9253, 13.1303],\n",
      "        [-2.5727, -4.0217, -3.9461,  ..., -5.5253,  5.9253, 13.1303],\n",
      "        ...,\n",
      "        [-4.4251, -4.0068, -5.0936,  ...,  9.9010, -3.2381, -3.3381],\n",
      "        [-4.7131, -3.6914, -5.0624,  ..., 11.4492, -2.4677, -2.2201],\n",
      "        [-4.4874, -4.0256, -5.1347,  ..., 11.0661, -3.1016, -3.2160]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9094, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 403,  321,  745,  ..., 4467, 4166, 3197],\n",
      "        [5275, 3500, 3771,  ..., 3898, 3046, 2871],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5275, 3500, 3771,  ..., 3898, 3046, 2871],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5732, -4.0221, -3.9464,  ..., -5.5264,  5.9259, 13.1301],\n",
      "        [-2.5732, -4.0221, -3.9464,  ..., -5.5264,  5.9259, 13.1301],\n",
      "        [-2.5732, -4.0221, -3.9464,  ..., -5.5264,  5.9259, 13.1301],\n",
      "        ...,\n",
      "        [-4.4343, -3.5380, -5.0059,  ..., 11.2147, -3.1446, -3.1174],\n",
      "        [-4.1006, -4.2518, -5.4660,  ..., 10.3139, -2.9139, -2.9401],\n",
      "        [-4.5496, -3.7681, -4.3084,  ..., 10.9944, -3.4719, -3.3090]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9298, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3021,  283,  307,  ..., 4577, 4569, 5211],\n",
      "        [ 562, 2058, 3331,  ..., 2795, 5225, 2412],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 562, 2058, 3331,  ..., 2795, 5225, 2412],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5726, -4.0227, -3.9468,  ..., -5.5264,  5.9265, 13.1300],\n",
      "        [-2.5726, -4.0227, -3.9468,  ..., -5.5264,  5.9265, 13.1300],\n",
      "        [-2.5726, -4.0227, -3.9468,  ..., -5.5264,  5.9265, 13.1300],\n",
      "        ...,\n",
      "        [-4.2652, -4.7806, -5.5256,  ..., 11.6249, -2.5865, -2.6579],\n",
      "        [-4.5483, -3.3068, -5.0292,  ...,  9.7052, -2.7491, -2.3066],\n",
      "        [-4.6216, -3.4064, -4.4263,  ...,  9.1809, -2.6315, -2.4036]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8482, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2405, 5138, 1271,  ..., 4087, 1282,  712],\n",
      "        [2577, 1654, 4737,  ..., 1197,  681, 2399],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2577, 1654, 4737,  ..., 1197,  681, 2399],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5714, -4.0224, -3.9473,  ..., -5.5267,  5.9259, 13.1315],\n",
      "        [-2.5714, -4.0224, -3.9473,  ..., -5.5267,  5.9259, 13.1315],\n",
      "        [-2.5714, -4.0224, -3.9473,  ..., -5.5267,  5.9259, 13.1315],\n",
      "        ...,\n",
      "        [-4.4054, -3.9197, -5.4291,  ..., 10.6714, -3.4715, -3.5025],\n",
      "        [-4.2227, -3.7766, -5.6508,  ..., 11.3912, -3.3176, -3.3349],\n",
      "        [-4.2507, -4.3501, -5.4309,  ...,  9.4717, -3.3300, -3.1050]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9459, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2904,   35, 1246,  ..., 2809,  822, 3682],\n",
      "        [ 789, 3061, 4470,  ..., 3061,  918,  952],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 789, 3061, 4470,  ..., 3061,  918,  952],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5704, -4.0215, -3.9478,  ..., -5.5271,  5.9258, 13.1324],\n",
      "        [-2.5704, -4.0215, -3.9478,  ..., -5.5271,  5.9258, 13.1324],\n",
      "        [-2.5704, -4.0215, -3.9478,  ..., -5.5271,  5.9258, 13.1324],\n",
      "        ...,\n",
      "        [-3.9948, -3.7905, -5.4376,  ...,  9.8326, -3.3403, -3.6946],\n",
      "        [-2.2744, -3.8862, -5.4503,  ...,  4.2475, -2.2591, -2.6483],\n",
      "        [-3.7713, -4.3561, -5.7801,  ...,  8.6998, -3.0660, -3.0386]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7898, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3428, 4840, 5295,  ..., 1888, 3854, 4348],\n",
      "        [2080, 1694, 5295,  ..., 3909, 2992,  831],\n",
      "        [ 436,  436, 5294,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2080, 1694, 5295,  ..., 3909, 2992,  831],\n",
      "        [ 436,  436, 5294,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5699, -4.0210, -3.9481,  ..., -5.5272,  5.9235, 13.1354],\n",
      "        [-2.5699, -4.0210, -3.9481,  ..., -5.5272,  5.9235, 13.1354],\n",
      "        [-2.5699, -4.0210, -3.9481,  ..., -5.5272,  5.9235, 13.1354],\n",
      "        ...,\n",
      "        [-4.5599, -3.7635, -4.4935,  ..., 11.8633, -2.5495, -2.2509],\n",
      "        [-4.2362, -3.6046, -5.4685,  ..., 11.1740, -3.0806, -2.9053],\n",
      "        [-4.2752, -4.2314, -5.6501,  ..., 12.2299, -2.4816, -2.6139]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9211, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  25, 1427, 3107,  ..., 3061, 5208,  105],\n",
      "        [2412,  321, 2904,  ..., 2602, 1323, 1914],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2412,  321, 2904,  ..., 2602, 1323, 1914],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5697, -4.0197, -3.9486,  ..., -5.5272,  5.9205, 13.1388],\n",
      "        [-2.5697, -4.0197, -3.9486,  ..., -5.5272,  5.9205, 13.1388],\n",
      "        [-2.5697, -4.0197, -3.9486,  ..., -5.5272,  5.9205, 13.1388],\n",
      "        ...,\n",
      "        [-4.5631, -3.8647, -5.2300,  ..., 11.8336, -3.1396, -3.1418],\n",
      "        [-4.4634, -3.6158, -4.0874,  ..., 11.5643, -3.1922, -2.6514],\n",
      "        [-4.1496, -4.3574, -5.3577,  ..., 10.3629, -3.1953, -3.3009]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(2.0541, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4828, 3021, 5091,  ..., 1705,  369, 3428],\n",
      "        [2936, 2773,  283,  ..., 1212, 1081, 5032],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2936, 2773,  283,  ..., 1212, 1081, 5032],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5698, -4.0189, -3.9492,  ..., -5.5269,  5.9205, 13.1390],\n",
      "        [-2.5698, -4.0189, -3.9492,  ..., -5.5269,  5.9205, 13.1390],\n",
      "        [-2.5698, -4.0189, -3.9492,  ..., -5.5269,  5.9205, 13.1390],\n",
      "        ...,\n",
      "        [-4.5333, -3.8875, -5.2527,  ..., 10.6741, -2.7811, -2.7307],\n",
      "        [-4.4098, -3.7240, -5.2198,  ..., 11.4301, -2.9412, -2.5624],\n",
      "        [-4.5099, -4.1303, -5.5551,  ..., 10.2921, -3.2842, -3.0881]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8576, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2757, 2166, 1192,  ...,   43,  803, 3087],\n",
      "        [1686, 2495, 3438,  ...,  527, 2531, 1017],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1686, 2495, 3438,  ...,  527, 2531, 1017],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5703, -4.0184, -3.9479,  ..., -5.5269,  5.9204, 13.1391],\n",
      "        [-2.5703, -4.0184, -3.9479,  ..., -5.5269,  5.9204, 13.1391],\n",
      "        [-2.5703, -4.0184, -3.9479,  ..., -5.5269,  5.9204, 13.1391],\n",
      "        ...,\n",
      "        [-5.0105, -3.6138, -4.6995,  ..., 10.7694, -2.6870, -2.4310],\n",
      "        [-4.0993, -4.2918, -5.5196,  ..., 10.1872, -3.1575, -3.2309],\n",
      "        [-3.9319, -3.6964, -5.2339,  ..., 10.3326, -3.3858, -3.2011]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9107, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3400, 4877,  786,  ...,   35,  593,  832],\n",
      "        [2058, 1054,  325,  ..., 3021,  705, 3092],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2058, 1054,  325,  ..., 3021,  705, 3092],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5709, -4.0175, -3.9469,  ..., -5.5285,  5.9211, 13.1382],\n",
      "        [-2.5709, -4.0175, -3.9469,  ..., -5.5285,  5.9211, 13.1382],\n",
      "        [-2.5709, -4.0175, -3.9469,  ..., -5.5285,  5.9211, 13.1382],\n",
      "        ...,\n",
      "        [-4.0767, -3.9520, -5.6379,  ..., 12.0159, -3.1812, -3.0520],\n",
      "        [-4.0152, -3.8707, -4.8539,  ...,  8.9768, -3.3804, -3.4670],\n",
      "        [-4.5418, -3.8391, -5.2151,  ..., 10.2596, -2.9453, -3.1177]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9041, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5295, 5081, 2590,  ..., 4265, 4062, 4478],\n",
      "        [5295, 3092, 3705,  ..., 4746, 3008, 2164],\n",
      "        [5294,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5295, 3092, 3705,  ..., 4746, 3008, 2164],\n",
      "        [5294,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5722, -4.0169, -3.9466,  ..., -5.5302,  5.9223, 13.1377],\n",
      "        [-2.5722, -4.0169, -3.9466,  ..., -5.5302,  5.9223, 13.1377],\n",
      "        [-2.5722, -4.0169, -3.9466,  ..., -5.5302,  5.9223, 13.1377],\n",
      "        ...,\n",
      "        [-4.2313, -4.1718, -5.4962,  ..., 10.7721, -3.1653, -3.2463],\n",
      "        [-3.7461, -3.7070, -5.2439,  ...,  9.4785, -2.9465, -3.3196],\n",
      "        [-4.5600, -3.6025, -5.1924,  ..., 10.8714, -2.8767, -3.0881]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9889, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 475,  574, 4905,  ..., 1108,  151, 4799],\n",
      "        [1787, 1935, 3021,  ..., 2002, 2652, 4031],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1787, 1935, 3021,  ..., 2002, 2652, 4031],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5725, -4.0167, -3.9465,  ..., -5.5323,  5.9242, 13.1360],\n",
      "        [-2.5725, -4.0167, -3.9465,  ..., -5.5323,  5.9242, 13.1360],\n",
      "        [-2.5725, -4.0167, -3.9465,  ..., -5.5323,  5.9242, 13.1360],\n",
      "        ...,\n",
      "        [-4.1923, -3.7738, -5.4296,  ..., 10.9222, -3.3599, -3.3413],\n",
      "        [-4.3087, -3.6913, -4.3093,  ..., 10.3893, -3.4708, -3.2290],\n",
      "        [-4.3315, -4.1742, -4.5967,  ..., 10.0200, -2.6662, -2.7325]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7979, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4728, 1542, 4393,  ...,  321,  852, 2778],\n",
      "        [3185, 4746, 1435,  ..., 5002, 2873, 4813],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3185, 4746, 1435,  ..., 5002, 2873, 4813],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5731, -4.0167, -3.9462,  ..., -5.5325,  5.9255, 13.1347],\n",
      "        [-2.5731, -4.0167, -3.9462,  ..., -5.5325,  5.9255, 13.1347],\n",
      "        [-2.5731, -4.0167, -3.9462,  ..., -5.5325,  5.9255, 13.1347],\n",
      "        ...,\n",
      "        [-4.3147, -4.1721, -4.5116,  ..., 10.3453, -2.0088, -2.2166],\n",
      "        [-4.0443, -3.9551, -5.6680,  ..., 10.9277, -3.2776, -3.3732],\n",
      "        [-3.0330, -3.4986, -5.1239,  ...,  3.1964, -1.9270, -2.3165]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8545, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2900, 2181, 4987,  ...,  643, 3705,  712],\n",
      "        [5081, 2792, 3279,  ..., 3495, 1251, 1062],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5081, 2792, 3279,  ..., 3495, 1251, 1062],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5738, -4.0169, -3.9459,  ..., -5.5328,  5.9260, 13.1342],\n",
      "        [-2.5738, -4.0169, -3.9459,  ..., -5.5328,  5.9260, 13.1342],\n",
      "        [-2.5738, -4.0169, -3.9459,  ..., -5.5328,  5.9260, 13.1342],\n",
      "        ...,\n",
      "        [-4.8872, -4.0142, -5.0867,  ..., 11.9012, -3.1295, -3.0345],\n",
      "        [-4.0073, -3.6600, -4.6638,  ...,  8.7512, -3.6532, -3.6234],\n",
      "        [-3.9741, -4.2027, -5.6874,  ...,  8.8954, -3.0015, -3.3397]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7784, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4348, 2181, 5295,  ..., 4775, 4903, 1463],\n",
      "        [4348,  283, 5295,  ..., 1940, 1263, 3670],\n",
      "        [ 436,  436, 5294,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4348,  283, 5295,  ..., 1940, 1263, 3670],\n",
      "        [ 436,  436, 5294,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5747, -4.0173, -3.9457,  ..., -5.5339,  5.9236, 13.1371],\n",
      "        [-2.5747, -4.0173, -3.9457,  ..., -5.5339,  5.9236, 13.1371],\n",
      "        [-2.5747, -4.0173, -3.9457,  ..., -5.5339,  5.9236, 13.1371],\n",
      "        ...,\n",
      "        [-4.3088, -3.5110, -4.9375,  ...,  9.7445, -3.3063, -3.2832],\n",
      "        [-4.5659, -4.0911, -4.9280,  ..., 11.0875, -2.2970, -2.0378],\n",
      "        [-4.3489, -3.3291, -4.3250,  ...,  8.4205, -2.7169, -2.7665]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9052, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  56, 3712, 3428,  ..., 3410, 2784, 2309],\n",
      "        [1771,  562, 2844,  ..., 4825, 3505, 2924],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1771,  562, 2844,  ..., 4825, 3505, 2924],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5757, -4.0180, -3.9456,  ..., -5.5359,  5.9194, 13.1423],\n",
      "        [-2.5757, -4.0180, -3.9456,  ..., -5.5359,  5.9194, 13.1423],\n",
      "        [-2.5757, -4.0180, -3.9456,  ..., -5.5359,  5.9194, 13.1423],\n",
      "        ...,\n",
      "        [-4.1057, -4.0798, -5.3608,  ..., 10.2424, -3.4626, -3.4717],\n",
      "        [-4.6655, -3.9293, -5.1875,  ..., 11.0089, -2.9060, -2.5767],\n",
      "        [-4.5001, -4.5318, -5.9938,  ..., 11.6566, -2.8975, -3.0168]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8407, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2674, 3555,  969,  ..., 2085, 3530, 2308],\n",
      "        [3807, 2661, 5253,  ..., 2091, 2181, 1452],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3807, 2661, 5253,  ..., 2091, 2181, 1452],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5768, -4.0179, -3.9455,  ..., -5.5372,  5.9150, 13.1473],\n",
      "        [-2.5768, -4.0179, -3.9455,  ..., -5.5372,  5.9150, 13.1473],\n",
      "        [-2.5768, -4.0179, -3.9455,  ..., -5.5372,  5.9150, 13.1473],\n",
      "        ...,\n",
      "        [-4.4827, -3.7443, -4.9424,  ..., 11.0947, -2.6383, -2.6822],\n",
      "        [-4.2225, -4.2501, -5.8874,  ..., 12.4812, -2.6519, -2.7416],\n",
      "        [-4.3703, -4.0598, -5.6610,  ..., 11.6799, -2.3910, -2.5939]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8305, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3390,  371, 3400,  ..., 5275, 4426, 2449],\n",
      "        [4299, 1535, 1748,  ..., 4627, 2181,  409],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4299, 1535, 1748,  ..., 4627, 2181,  409],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5782, -4.0181, -3.9457,  ..., -5.5384,  5.9107, 13.1523],\n",
      "        [-2.5782, -4.0181, -3.9457,  ..., -5.5384,  5.9107, 13.1523],\n",
      "        [-2.5782, -4.0181, -3.9457,  ..., -5.5384,  5.9107, 13.1523],\n",
      "        ...,\n",
      "        [-4.5521, -4.4153, -5.1696,  ...,  9.9743, -2.4060, -2.3459],\n",
      "        [-4.5650, -3.9404, -5.4488,  ..., 11.1437, -2.6482, -2.3780],\n",
      "        [-4.4412, -3.5657, -4.2697,  ..., 10.2009, -2.5649, -2.1924]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0376, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3183, 3854,    4,  ..., 3730, 4052, 5243],\n",
      "        [4390,  574, 5159,  ..., 3379, 1210, 4465],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4390,  574, 5159,  ..., 3379, 1210, 4465],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5797, -4.0185, -3.9440,  ..., -5.5391,  5.9097, 13.1539],\n",
      "        [-2.5797, -4.0185, -3.9440,  ..., -5.5391,  5.9097, 13.1539],\n",
      "        [-2.5797, -4.0185, -3.9440,  ..., -5.5391,  5.9097, 13.1539],\n",
      "        ...,\n",
      "        [-4.3709, -4.3248, -4.6488,  ..., 10.3860, -1.8486, -1.8444],\n",
      "        [-4.2224, -3.8561, -5.2336,  ...,  9.5153, -2.8416, -2.9256],\n",
      "        [-4.5584, -4.3065, -5.2696,  ..., 10.7245, -3.0660, -3.0216]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0133, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1579,  639, 1114,  ..., 5114, 1971, 2979],\n",
      "        [ 843,  513, 2809,  ..., 4265,  833,  825],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 843,  513, 2809,  ..., 4265,  833,  825],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5815, -4.0182, -3.9426,  ..., -5.5395,  5.9114, 13.1529],\n",
      "        [-2.5815, -4.0182, -3.9426,  ..., -5.5395,  5.9114, 13.1529],\n",
      "        [-2.5815, -4.0182, -3.9426,  ..., -5.5395,  5.9114, 13.1529],\n",
      "        ...,\n",
      "        [-4.5418, -4.0662, -5.8443,  ..., 11.1153, -2.4660, -2.5886],\n",
      "        [-4.3091, -3.9374, -5.4618,  ..., 10.8708, -3.2925, -3.3978],\n",
      "        [-3.8651, -4.0006, -5.4149,  ..., 10.3138, -2.4366, -2.7597]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8670, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 151, 1565, 2947,  ..., 2059, 5102, 4266],\n",
      "        [  29, 3049, 2526,  ..., 3061, 4052, 4944],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  29, 3049, 2526,  ..., 3061, 4052, 4944],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5834, -4.0182, -3.9414,  ..., -5.5396,  5.9135, 13.1517],\n",
      "        [-2.5834, -4.0182, -3.9414,  ..., -5.5396,  5.9135, 13.1517],\n",
      "        [-2.5834, -4.0182, -3.9414,  ..., -5.5396,  5.9135, 13.1517],\n",
      "        ...,\n",
      "        [-4.5631, -4.4164, -5.4926,  ..., 12.0239, -2.5157, -2.5988],\n",
      "        [-4.4603, -4.6679, -6.1238,  ..., 12.2899, -2.6137, -2.4381],\n",
      "        [-4.0172, -4.2658, -5.6440,  ..., 11.1477, -3.0021, -3.0998]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9611, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 831,  267, 3331,  ..., 1240, 2156, 2942],\n",
      "        [2136, 2821, 1401,  ..., 2181, 5173, 5225],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2136, 2821, 1401,  ..., 2181, 5173, 5225],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5854, -4.0186, -3.9389,  ..., -5.5398,  5.9161, 13.1503],\n",
      "        [-2.5854, -4.0186, -3.9389,  ..., -5.5398,  5.9161, 13.1503],\n",
      "        [-2.5854, -4.0186, -3.9389,  ..., -5.5398,  5.9161, 13.1503],\n",
      "        ...,\n",
      "        [-4.4470, -4.1518, -5.6799,  ..., 11.8014, -2.9306, -3.1635],\n",
      "        [-4.0577, -4.0272, -5.4120,  ..., 11.3381, -3.1626, -3.1456],\n",
      "        [-4.9055, -3.8822, -4.6731,  ..., 10.9115, -3.0438, -2.9142]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7897, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3004, 2838, 3331,  ..., 1639,  403, 1382],\n",
      "        [1463, 4346,  572,  ..., 2629, 4305, 3609],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1463, 4346,  572,  ..., 2629, 4305, 3609],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5874, -4.0191, -3.9367,  ..., -5.5411,  5.9178, 13.1502],\n",
      "        [-2.5874, -4.0191, -3.9367,  ..., -5.5411,  5.9178, 13.1502],\n",
      "        [-2.5874, -4.0191, -3.9367,  ..., -5.5411,  5.9178, 13.1502],\n",
      "        ...,\n",
      "        [-3.9732, -4.0344, -5.5972,  ..., 11.4878, -2.9182, -3.0159],\n",
      "        [-4.2894, -3.8726, -5.4200,  ...,  9.0298, -2.2009, -2.4557],\n",
      "        [-4.4110, -3.8860, -5.0110,  ..., 10.2419, -3.3180, -3.3341]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8105, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3010, 5102,  321,  ..., 3321, 3173,  321],\n",
      "        [ 604, 4052,  230,  ...,   74, 2888, 2667],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 604, 4052,  230,  ...,   74, 2888, 2667],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5898, -4.0198, -3.9351,  ..., -5.5424,  5.9195, 13.1504],\n",
      "        [-2.5898, -4.0198, -3.9351,  ..., -5.5424,  5.9195, 13.1504],\n",
      "        [-2.5898, -4.0198, -3.9351,  ..., -5.5424,  5.9195, 13.1504],\n",
      "        ...,\n",
      "        [-3.9132, -4.1555, -5.4425,  ...,  9.1699, -3.0766, -3.0539],\n",
      "        [-4.8048, -3.4280, -4.1167,  ..., 10.4405, -3.1191, -2.7776],\n",
      "        [-4.6299, -3.7954, -5.2597,  ..., 11.1372, -2.9218, -2.8116]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9189, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4828, 1473, 4753,  ..., 1272, 1131,  977],\n",
      "        [1064,  105, 1253,  ..., 4726, 4825, 3909],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1064,  105, 1253,  ..., 4726, 4825, 3909],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5917, -4.0196, -3.9335,  ..., -5.5424,  5.9222, 13.1483],\n",
      "        [-2.5917, -4.0196, -3.9335,  ..., -5.5424,  5.9222, 13.1483],\n",
      "        [-2.5917, -4.0196, -3.9335,  ..., -5.5424,  5.9222, 13.1483],\n",
      "        ...,\n",
      "        [-4.2162, -3.8165, -5.3224,  ...,  8.9916, -2.4652, -2.6503],\n",
      "        [-4.3623, -4.0983, -5.9692,  ...,  9.9693, -3.0001, -2.9272],\n",
      "        [-4.8157, -3.8208, -4.7081,  ..., 11.3894, -2.7344, -2.5646]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8839, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 105, 5295, 4712,  ..., 4265,  803, 4052],\n",
      "        [1271, 5295, 4623,  ...,  740, 3555, 2369],\n",
      "        [ 436, 5294,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1271, 5295, 4623,  ...,  740, 3555, 2369],\n",
      "        [ 436, 5294,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5919, -4.0194, -3.9321,  ..., -5.5419,  5.9238, 13.1466],\n",
      "        [-2.5919, -4.0194, -3.9321,  ..., -5.5419,  5.9238, 13.1466],\n",
      "        [-2.5919, -4.0194, -3.9321,  ..., -5.5419,  5.9238, 13.1466],\n",
      "        ...,\n",
      "        [-4.4484, -4.0809, -5.0055,  ..., 11.1413, -3.0652, -3.1220],\n",
      "        [-4.8985, -3.6669, -4.7808,  ...,  9.7297, -2.9166, -2.5050],\n",
      "        [-4.8235, -3.8217, -4.8169,  ..., 11.3890, -2.9660, -2.8611]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9220, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3166, 1888,  831,  ...,  192, 1621, 5027],\n",
      "        [2936, 5081, 4265,  ...,   26, 2773, 4465],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2936, 5081, 4265,  ...,   26, 2773, 4465],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5912, -4.0194, -3.9310,  ..., -5.5431,  5.9244, 13.1461],\n",
      "        [-2.5912, -4.0194, -3.9310,  ..., -5.5431,  5.9244, 13.1461],\n",
      "        [-2.5912, -4.0194, -3.9310,  ..., -5.5431,  5.9244, 13.1461],\n",
      "        ...,\n",
      "        [-4.1056, -4.2374, -4.8270,  ..., 10.4109, -2.5101, -2.4524],\n",
      "        [-4.1006, -3.6754, -5.3404,  ..., 10.1881, -3.3754, -3.6844],\n",
      "        [-4.3565, -4.3501, -5.2312,  ..., 11.1870, -3.4143, -3.5379]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9895, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1010,  969, 4825,  ..., 2343, 5027, 2870],\n",
      "        [2809, 4944, 1282,  ..., 5157, 4987, 1771],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2809, 4944, 1282,  ..., 5157, 4987, 1771],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5907, -4.0196, -3.9302,  ..., -5.5455,  5.9244, 13.1463],\n",
      "        [-2.5907, -4.0196, -3.9302,  ..., -5.5455,  5.9244, 13.1463],\n",
      "        [-2.5907, -4.0196, -3.9302,  ..., -5.5455,  5.9244, 13.1463],\n",
      "        ...,\n",
      "        [-4.4881, -4.0115, -4.5391,  ..., 10.9532, -2.0664, -1.9694],\n",
      "        [-4.3152, -4.4072, -5.0674,  ..., 10.2784, -2.5742, -2.8789],\n",
      "        [-4.1861, -4.1952, -5.4748,  ..., 10.9400, -2.7672, -2.9874]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9951, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3955, 3656, 3828,  ...,  321, 4516, 3506],\n",
      "        [ 298, 3466, 2127,  ..., 1251, 5260, 2773],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 298, 3466, 2127,  ..., 1251, 5260, 2773],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5905, -4.0180, -3.9297,  ..., -5.5480,  5.9240, 13.1468],\n",
      "        [-2.5905, -4.0180, -3.9297,  ..., -5.5480,  5.9240, 13.1468],\n",
      "        [-2.5905, -4.0180, -3.9297,  ..., -5.5480,  5.9240, 13.1468],\n",
      "        ...,\n",
      "        [-4.5141, -3.7062, -5.1447,  ..., 10.3312, -3.0100, -2.9330],\n",
      "        [-4.4181, -4.2947, -5.6903,  ..., 11.4154, -2.8976, -2.7811],\n",
      "        [-3.7766, -4.3155, -6.0501,  ..., 10.5199, -3.0142, -3.1451]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8498, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5183, 1694, 2089,  ...,  969, 1134, 4526],\n",
      "        [5183,  940, 1323,  ..., 3321,  922, 2987],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5183,  940, 1323,  ..., 3321,  922, 2987],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5906, -4.0168, -3.9292,  ..., -5.5500,  5.9238, 13.1473],\n",
      "        [-2.5906, -4.0168, -3.9292,  ..., -5.5500,  5.9238, 13.1473],\n",
      "        [-2.5906, -4.0168, -3.9292,  ..., -5.5500,  5.9238, 13.1473],\n",
      "        ...,\n",
      "        [-4.6461, -4.6856, -6.0928,  ..., 10.3597, -2.6822, -2.7266],\n",
      "        [-4.6843, -3.7314, -4.4064,  ..., 10.7244, -3.1016, -2.9662],\n",
      "        [-4.5866, -3.6101, -5.1264,  ..., 11.3247, -2.6938, -2.7142]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9079, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4052, 2733,  593,  ..., 2237, 3331, 5208],\n",
      "        [3909,   74, 2637,  ...,  822, 3321, 1323],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3909,   74, 2637,  ...,  822, 3321, 1323],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5910, -4.0157, -3.9285,  ..., -5.5502,  5.9231, 13.1479],\n",
      "        [-2.5910, -4.0157, -3.9285,  ..., -5.5502,  5.9231, 13.1479],\n",
      "        [-2.5910, -4.0157, -3.9285,  ..., -5.5502,  5.9231, 13.1479],\n",
      "        ...,\n",
      "        [-4.4338, -4.3318, -5.0705,  ..., 11.6209, -2.0332, -1.9213],\n",
      "        [-4.7445, -4.1071, -5.6710,  ..., 11.6813, -2.7303, -2.8855],\n",
      "        [-4.4731, -3.6167, -4.1019,  ..., 11.5247, -3.2415, -2.7228]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8494, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3417, 4017, 4470,  ..., 3732, 3382, 4944],\n",
      "        [1601, 3087,  401,  ..., 3331, 1452, 4052],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1601, 3087,  401,  ..., 3331, 1452, 4052],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5916, -4.0150, -3.9257,  ..., -5.5495,  5.9220, 13.1485],\n",
      "        [-2.5916, -4.0150, -3.9257,  ..., -5.5495,  5.9220, 13.1485],\n",
      "        [-2.5916, -4.0150, -3.9257,  ..., -5.5495,  5.9220, 13.1485],\n",
      "        ...,\n",
      "        [-4.5786, -3.7228, -4.6283,  ..., 10.2338, -2.9368, -2.9601],\n",
      "        [-4.2222, -4.2487, -5.6186,  ..., 11.0820, -2.7839, -2.9931],\n",
      "        [-4.1527, -3.8992, -5.6536,  ..., 11.2288, -3.0052, -3.0323]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9829, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4265, 2022, 3331,  ..., 1844,  792,  114],\n",
      "        [3273, 2127, 2913,  ..., 1844, 4329, 4839],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3273, 2127, 2913,  ..., 1844, 4329, 4839],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5924, -4.0147, -3.9233,  ..., -5.5497,  5.9209, 13.1495],\n",
      "        [-2.5924, -4.0147, -3.9233,  ..., -5.5497,  5.9209, 13.1495],\n",
      "        [-2.5924, -4.0147, -3.9233,  ..., -5.5497,  5.9209, 13.1495],\n",
      "        ...,\n",
      "        [-4.4649, -3.8021, -5.3841,  ..., 11.2882, -2.9329, -2.9955],\n",
      "        [-4.3881, -4.0381, -5.1846,  ..., 11.4175, -3.2513, -3.1414],\n",
      "        [-2.5767, -4.0814, -5.3704,  ...,  4.1508, -1.4404, -2.1132]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9108, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 489, 3689,  363,  ..., 4147,  574,    4],\n",
      "        [4894, 5147, 5243,  ..., 3466, 3665, 3555],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4894, 5147, 5243,  ..., 3466, 3665, 3555],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5934, -4.0145, -3.9202,  ..., -5.5521,  5.9184, 13.1529],\n",
      "        [-2.5934, -4.0145, -3.9202,  ..., -5.5521,  5.9184, 13.1529],\n",
      "        [-2.5934, -4.0145, -3.9202,  ..., -5.5521,  5.9184, 13.1529],\n",
      "        ...,\n",
      "        [-4.6726, -4.0086, -5.4079,  ..., 11.5000, -3.1839, -2.9973],\n",
      "        [-4.0195, -4.0668, -5.3591,  ..., 10.6642, -2.6593, -2.9212],\n",
      "        [-4.8036, -3.9852, -4.9159,  ..., 10.5169, -3.1560, -3.0104]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0236, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2159,  649, 4712,  ...,  215, 1694, 3724],\n",
      "        [4648,  825, 3326,  ..., 2732, 3566, 2301],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4648,  825, 3326,  ..., 2732, 3566, 2301],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5945, -4.0146, -3.9175,  ..., -5.5550,  5.9167, 13.1553],\n",
      "        [-2.5945, -4.0146, -3.9175,  ..., -5.5550,  5.9167, 13.1553],\n",
      "        [-2.5945, -4.0146, -3.9175,  ..., -5.5550,  5.9167, 13.1553],\n",
      "        ...,\n",
      "        [-3.8802, -4.0396, -5.3236,  ...,  5.2581, -2.2133, -2.2708],\n",
      "        [-4.0366, -4.0494, -5.8180,  ...,  9.4938, -2.9121, -3.0736],\n",
      "        [-4.7150, -3.5389, -4.4100,  ...,  8.1043, -3.2460, -3.2585]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(2.0288, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2159, 1212, 4899,  ..., 3828, 2732, 3828],\n",
      "        [4648, 2715, 1779,  ..., 4987, 3279, 1570],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4648, 2715, 1779,  ..., 4987, 3279, 1570],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5959, -4.0147, -3.9152,  ..., -5.5568,  5.9174, 13.1538],\n",
      "        [-2.5959, -4.0147, -3.9152,  ..., -5.5568,  5.9174, 13.1538],\n",
      "        [-2.5959, -4.0147, -3.9152,  ..., -5.5568,  5.9174, 13.1538],\n",
      "        ...,\n",
      "        [-4.2085, -4.2340, -5.6744,  ..., 10.7381, -2.6733, -2.7702],\n",
      "        [-4.4361, -4.8071, -6.1522,  ..., 11.8451, -2.8471, -2.9270],\n",
      "        [-4.1452, -3.8552, -4.5561,  ...,  7.4054, -2.7012, -3.2245]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0562, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2516, 5001, 1309,  ..., 4181, 2935, 1878],\n",
      "        [1694, 2763, 2164,  ..., 1724, 1166, 4161],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1694, 2763, 2164,  ..., 1724, 1166, 4161],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5979, -4.0149, -3.9112,  ..., -5.5569,  5.9205, 13.1495],\n",
      "        [-2.5979, -4.0149, -3.9112,  ..., -5.5569,  5.9205, 13.1495],\n",
      "        [-2.5979, -4.0149, -3.9112,  ..., -5.5569,  5.9205, 13.1495],\n",
      "        ...,\n",
      "        [-3.9781, -3.9844, -4.7447,  ...,  9.1483, -3.0327, -3.0424],\n",
      "        [-4.1697, -4.5004, -5.7056,  ..., 10.9104, -3.1497, -3.1373],\n",
      "        [-4.6777, -3.8651, -5.3787,  ..., 12.1711, -2.7076, -2.7890]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9700, grad_fn=<NllLossBackward>)\n",
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花李。', '月下，一番花、一点春风。', '夜蓉雨。', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番花开舞。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3828, 1767,  114,  ..., 2624,    4, 2227],\n",
      "        [3800, 1054, 3820,  ...,  878,  657, 1348],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3800, 1054, 3820,  ...,  878,  657, 1348],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6003, -4.0153, -3.9078,  ..., -5.5574,  5.9231, 13.1468],\n",
      "        [-2.6003, -4.0153, -3.9078,  ..., -5.5574,  5.9231, 13.1468],\n",
      "        [-2.6003, -4.0153, -3.9078,  ..., -5.5574,  5.9231, 13.1468],\n",
      "        ...,\n",
      "        [-4.5120, -4.2744, -5.1151,  ..., 11.4669, -3.0618, -3.0773],\n",
      "        [-4.0753, -4.4308, -5.3362,  ..., 10.5905, -2.7399, -2.9896],\n",
      "        [-3.8965, -4.2202, -6.0233,  ...,  9.3499, -2.5687, -2.8787]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8814, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5295, 4813, 4467,  ..., 2821, 3382, 2369],\n",
      "        [5295, 4487, 3087,  ..., 4963, 1452, 4746],\n",
      "        [5294,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5295, 4487, 3087,  ..., 4963, 1452, 4746],\n",
      "        [5294,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6002, -4.0152, -3.9051,  ..., -5.5603,  5.9232, 13.1484],\n",
      "        [-2.6002, -4.0152, -3.9051,  ..., -5.5603,  5.9232, 13.1484],\n",
      "        [-2.6002, -4.0152, -3.9051,  ..., -5.5603,  5.9232, 13.1484],\n",
      "        ...,\n",
      "        [-4.1672, -4.3488, -5.7640,  ..., 10.4121, -2.6773, -2.5429],\n",
      "        [-4.4223, -4.0393, -5.8559,  ..., 11.4559, -2.2544, -2.2982],\n",
      "        [-4.0156, -3.7514, -3.3457,  ...,  8.4318, -1.9127, -1.9841]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7555, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1452, 3390, 4032,  ..., 4533, 5295, 1579],\n",
      "        [4331, 4363, 4176,  ...,  745, 5295, 2058],\n",
      "        [ 436,  436,  436,  ...,  436, 5294,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4331, 4363, 4176,  ...,  745, 5295, 2058],\n",
      "        [ 436,  436,  436,  ...,  436, 5294,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6002, -4.0155, -3.9028,  ..., -5.5646,  5.9202, 13.1541],\n",
      "        [-2.6002, -4.0155, -3.9028,  ..., -5.5646,  5.9202, 13.1541],\n",
      "        [-2.6002, -4.0155, -3.9028,  ..., -5.5646,  5.9202, 13.1541],\n",
      "        ...,\n",
      "        [-4.4131, -4.5844, -5.1701,  ..., 10.2605, -1.1168, -1.1942],\n",
      "        [-3.3795, -4.0629, -5.9383,  ...,  7.7264, -0.2311, -0.1833],\n",
      "        [-4.3066, -4.3486, -5.7657,  ..., 11.3148, -3.0451, -3.2192]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9291, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2777, 2947,  496,  ..., 1081, 2763, 5289],\n",
      "        [2777,  385,  851,  ..., 2732,  681, 4331],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2777,  385,  851,  ..., 2732,  681, 4331],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5993, -4.0150, -3.9008,  ..., -5.5680,  5.9168, 13.1592],\n",
      "        [-2.5993, -4.0150, -3.9008,  ..., -5.5680,  5.9168, 13.1592],\n",
      "        [-2.5993, -4.0150, -3.9008,  ..., -5.5680,  5.9168, 13.1592],\n",
      "        ...,\n",
      "        [-4.2800, -3.9801, -5.0670,  ..., 10.1873, -3.3166, -3.2095],\n",
      "        [-4.7732, -3.9184, -5.5632,  ..., 12.5003, -2.9053, -2.8456],\n",
      "        [-3.8653, -3.9122, -5.3314,  ...,  9.3114, -2.8441, -2.6005]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9028, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1912,  272, 3668,  ...,  366, 3178, 5295],\n",
      "        [2749, 4679, 3061,  ..., 3355, 4069, 5295],\n",
      "        [ 436,  436,  436,  ...,  436,  436, 5294]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2749, 4679, 3061,  ..., 3355, 4069, 5295],\n",
      "        [ 436,  436,  436,  ...,  436,  436, 5294],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5990, -4.0146, -3.8991,  ..., -5.5693,  5.9145, 13.1627],\n",
      "        [-2.5990, -4.0146, -3.8991,  ..., -5.5693,  5.9145, 13.1627],\n",
      "        [-2.5990, -4.0146, -3.8991,  ..., -5.5693,  5.9145, 13.1627],\n",
      "        ...,\n",
      "        [-4.0361, -4.2271, -5.4547,  ..., 10.5516, -2.4024, -2.6156],\n",
      "        [-4.4588, -3.6514, -4.5077,  ...,  9.5742, -3.4198, -3.3337],\n",
      "        [-3.3672, -4.0513, -5.9243,  ...,  7.6950, -0.2423, -0.1816]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7653, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4052,    4, 2017,  ..., 2440, 3321, 4838],\n",
      "        [1922, 1516,  321,  ..., 3771, 3922, 4414],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1922, 1516,  321,  ..., 3771, 3922, 4414],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5991, -4.0146, -3.8976,  ..., -5.5697,  5.9117, 13.1668],\n",
      "        [-2.5991, -4.0146, -3.8976,  ..., -5.5697,  5.9117, 13.1668],\n",
      "        [-2.5991, -4.0146, -3.8976,  ..., -5.5697,  5.9117, 13.1668],\n",
      "        ...,\n",
      "        [-4.2855, -3.9162, -5.0659,  ...,  9.2628, -3.1358, -3.1836],\n",
      "        [-4.2432, -4.2586, -5.7063,  ...,  9.3759, -2.5337, -2.8946],\n",
      "        [-4.8676, -4.1741, -5.0539,  ..., 11.6972, -3.2365, -3.2144]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8135, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [   4, 1081, 4750,  ...,  215, 2397, 3770],\n",
      "        [1358, 2732, 2997,  ..., 1251, 2058, 3630],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1358, 2732, 2997,  ..., 1251, 2058, 3630],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5994, -4.0149, -3.8949,  ..., -5.5705,  5.9083, 13.1716],\n",
      "        [-2.5994, -4.0149, -3.8949,  ..., -5.5705,  5.9083, 13.1716],\n",
      "        [-2.5994, -4.0149, -3.8949,  ..., -5.5705,  5.9083, 13.1716],\n",
      "        ...,\n",
      "        [-4.3634, -3.8636, -4.3154,  ...,  9.4631, -3.5887, -3.5411],\n",
      "        [-4.2618, -3.9821, -5.5205,  ..., 10.6723, -3.2661, -3.3166],\n",
      "        [-4.4941, -3.8037, -5.5780,  ..., 11.1503, -3.1676, -3.0248]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9277, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1694, 1976, 1192,  ..., 2915,  825,  899],\n",
      "        [ 366, 1010,  380,  ..., 4467, 2936, 1911],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 366, 1010,  380,  ..., 4467, 2936, 1911],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5999, -4.0153, -3.8926,  ..., -5.5723,  5.9046, 13.1767],\n",
      "        [-2.5999, -4.0153, -3.8926,  ..., -5.5723,  5.9046, 13.1767],\n",
      "        [-2.5999, -4.0153, -3.8926,  ..., -5.5723,  5.9046, 13.1767],\n",
      "        ...,\n",
      "        [-3.9942, -3.7266, -5.6167,  ..., 10.5813, -3.2034, -3.4584],\n",
      "        [-3.9900, -4.2492, -5.4463,  ..., 10.5462, -3.0150, -3.1049],\n",
      "        [-4.5448, -3.7656, -4.6251,  ..., 11.5989, -3.4183, -3.4536]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8509, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1929, 1579, 4032,  ..., 3661, 5051, 3854],\n",
      "        [ 321, 1427,  644,  ..., 3061, 4559,  114],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 321, 1427,  644,  ..., 3061, 4559,  114],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6005, -4.0158, -3.8907,  ..., -5.5755,  5.9012, 13.1818],\n",
      "        [-2.6005, -4.0158, -3.8907,  ..., -5.5755,  5.9012, 13.1818],\n",
      "        [-2.6005, -4.0158, -3.8907,  ..., -5.5755,  5.9012, 13.1818],\n",
      "        ...,\n",
      "        [-4.6184, -4.3599, -4.7544,  ..., 11.3325, -2.0997, -2.1281],\n",
      "        [-4.4681, -4.1202, -5.4209,  ..., 11.0803, -2.7917, -2.7957],\n",
      "        [-4.1648, -4.4248, -5.8990,  ..., 11.8253, -2.6220, -2.5907]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8510, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2961,  969,  851,  ..., 4937,   25,  283],\n",
      "        [4204, 2829, 3008,  ...,  509, 3092,  321],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4204, 2829, 3008,  ...,  509, 3092,  321],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6013, -4.0163, -3.8892,  ..., -5.5773,  5.8980, 13.1856],\n",
      "        [-2.6013, -4.0163, -3.8892,  ..., -5.5773,  5.8980, 13.1856],\n",
      "        [-2.6013, -4.0163, -3.8892,  ..., -5.5773,  5.8980, 13.1856],\n",
      "        ...,\n",
      "        [-2.8214, -4.3602, -5.6050,  ...,  3.2255, -1.5411, -2.0281],\n",
      "        [-4.5694, -4.2411, -5.5546,  ..., 12.1347, -3.0244, -2.9887],\n",
      "        [-4.3564, -4.1741, -5.8402,  ..., 11.4992, -2.9801, -3.1877]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8116, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4533, 1452, 3195,  ..., 1399,  563, 1661],\n",
      "        [2809, 5188, 4800,  ..., 2809,  369, 3030],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2809, 5188, 4800,  ..., 2809,  369, 3030],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6024, -4.0170, -3.8876,  ..., -5.5770,  5.8964, 13.1870],\n",
      "        [-2.6024, -4.0170, -3.8876,  ..., -5.5770,  5.8964, 13.1870],\n",
      "        [-2.6024, -4.0170, -3.8876,  ..., -5.5770,  5.8964, 13.1870],\n",
      "        ...,\n",
      "        [-4.3397, -3.8855, -5.4034,  ..., 10.8369, -2.8635, -2.8200],\n",
      "        [-4.3406, -4.1064, -5.4830,  ..., 10.3927, -2.7015, -2.8601],\n",
      "        [-4.5519, -3.9168, -4.9198,  ..., 11.4560, -2.9648, -2.8670]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8667, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 996, 1192, 2579,  ..., 2763, 2417, 1820],\n",
      "        [4069, 1831,  321,  ..., 3503, 1457, 1721],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4069, 1831,  321,  ..., 3503, 1457, 1721],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6035, -4.0180, -3.8862,  ..., -5.5755,  5.8961, 13.1869],\n",
      "        [-2.6035, -4.0180, -3.8862,  ..., -5.5755,  5.8961, 13.1869],\n",
      "        [-2.6035, -4.0180, -3.8862,  ..., -5.5755,  5.8961, 13.1869],\n",
      "        ...,\n",
      "        [-4.1894, -3.7974, -5.4253,  ..., 10.8454, -3.3776, -3.3383],\n",
      "        [-4.1158, -4.1229, -4.9348,  ..., 10.4407, -2.9263, -3.3008],\n",
      "        [-4.4764, -3.8589, -4.6546,  ..., 10.9769, -3.0958, -2.5891]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8108, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1158, 3542, 4383,  ...,  593, 1888, 4087],\n",
      "        [1096,  965, 3365,  ...,  352, 5081,  411],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1096,  965, 3365,  ...,  352, 5081,  411],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6048, -4.0193, -3.8852,  ..., -5.5754,  5.8952, 13.1884],\n",
      "        [-2.6048, -4.0193, -3.8852,  ..., -5.5754,  5.8952, 13.1884],\n",
      "        [-2.6048, -4.0193, -3.8852,  ..., -5.5754,  5.8952, 13.1884],\n",
      "        ...,\n",
      "        [-4.3528, -3.1536, -3.5064,  ...,  8.8009, -2.6329, -2.4732],\n",
      "        [-4.0889, -4.1344, -5.2488,  ..., 11.2756, -3.2310, -3.3554],\n",
      "        [-4.6502, -3.8725, -4.9903,  ..., 10.7254, -2.6953, -2.7621]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8537, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1767, 2349, 2603,  ..., 2369,  403, 1192],\n",
      "        [1358, 3909,  672,  ..., 1977, 5157, 4331],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1358, 3909,  672,  ..., 1977, 5157, 4331],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6049, -4.0207, -3.8844,  ..., -5.5757,  5.8953, 13.1893],\n",
      "        [-2.6049, -4.0207, -3.8844,  ..., -5.5757,  5.8953, 13.1893],\n",
      "        [-2.6049, -4.0207, -3.8844,  ..., -5.5757,  5.8953, 13.1893],\n",
      "        ...,\n",
      "        [-4.5484, -4.1418, -4.6035,  ..., 10.4618, -3.3058, -2.9757],\n",
      "        [-4.3895, -3.7193, -5.1422,  ..., 11.3926, -3.0342, -2.7911],\n",
      "        [-4.1846, -3.6296, -4.3379,  ...,  9.9522, -3.2185, -2.8873]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7391, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1661,  105, 3729,  ..., 3417, 3030, 4265],\n",
      "        [2314, 2083, 3729,  ..., 2793,  639, 3087],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2314, 2083, 3729,  ..., 2793,  639, 3087],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6052, -4.0224, -3.8838,  ..., -5.5770,  5.8948, 13.1916],\n",
      "        [-2.6052, -4.0224, -3.8838,  ..., -5.5770,  5.8948, 13.1916],\n",
      "        [-2.6052, -4.0224, -3.8838,  ..., -5.5770,  5.8948, 13.1916],\n",
      "        ...,\n",
      "        [-4.4857, -4.5598, -5.4087,  ..., 10.2493, -1.6841, -2.1520],\n",
      "        [-4.2350, -4.1066, -5.2743,  ..., 11.4665, -2.4627, -2.6161],\n",
      "        [-4.4178, -4.1596, -5.5233,  ..., 11.6084, -3.3604, -3.4384]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8794, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3878, 2773, 2616,  ..., 1309,  458, 2629],\n",
      "        [2795, 2997, 1042,  ..., 4003, 3273, 3795],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2795, 2997, 1042,  ..., 4003, 3273, 3795],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6058, -4.0237, -3.8829,  ..., -5.5773,  5.8953, 13.1920],\n",
      "        [-2.6058, -4.0237, -3.8829,  ..., -5.5773,  5.8953, 13.1920],\n",
      "        [-2.6058, -4.0237, -3.8829,  ..., -5.5773,  5.8953, 13.1920],\n",
      "        ...,\n",
      "        [-4.5962, -3.6620, -4.5255,  ..., 12.0509, -2.8052, -2.6378],\n",
      "        [-4.3650, -3.4286, -4.8567,  ..., 10.8089, -3.0433, -3.0341],\n",
      "        [-4.3069, -4.2673, -5.2126,  ..., 10.4307, -2.6296, -2.7059]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8521, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1382,  563, 1399,  ..., 5295, 3733, 4368],\n",
      "        [4853, 3331, 3331,  ..., 5295,  306, 3500],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4853, 3331, 3331,  ..., 5295,  306, 3500],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6069, -4.0250, -3.8826,  ..., -5.5768,  5.8965, 13.1915],\n",
      "        [-2.6069, -4.0250, -3.8826,  ..., -5.5768,  5.8965, 13.1915],\n",
      "        [-2.6069, -4.0250, -3.8826,  ..., -5.5768,  5.8965, 13.1915],\n",
      "        ...,\n",
      "        [-3.3848, -4.0540, -5.9314,  ...,  7.7987, -0.2659, -0.1770],\n",
      "        [-4.3675, -4.3680, -4.9021,  ..., 11.2288, -2.4502, -2.3448],\n",
      "        [-4.3066, -3.8359, -5.5557,  ..., 10.1953, -3.2096, -3.3327]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8153, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3786, 4969, 4440,  ..., 4266, 5128,  307],\n",
      "        [3771, 4969,  321,  ..., 1945, 3771, 3331],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3771, 4969,  321,  ..., 1945, 3771, 3331],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6081, -4.0255, -3.8824,  ..., -5.5757,  5.8978, 13.1905],\n",
      "        [-2.6081, -4.0255, -3.8824,  ..., -5.5757,  5.8978, 13.1905],\n",
      "        [-2.6081, -4.0255, -3.8824,  ..., -5.5757,  5.8978, 13.1905],\n",
      "        ...,\n",
      "        [-3.8956, -4.0143, -5.6760,  ...,  8.8343, -2.3255, -2.5782],\n",
      "        [-4.5094, -4.6323, -5.7716,  ..., 12.5981, -2.9726, -2.9106],\n",
      "        [-4.5438, -4.4519, -6.0168,  ..., 12.5840, -2.8102, -2.8999]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9121, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 509,  574, 2093,  ..., 2739, 2915, 1888],\n",
      "        [2866, 2393, 3847,  ..., 2739, 1849, 3087],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2866, 2393, 3847,  ..., 2739, 1849, 3087],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6095, -4.0262, -3.8825,  ..., -5.5758,  5.8995, 13.1894],\n",
      "        [-2.6095, -4.0262, -3.8825,  ..., -5.5758,  5.8995, 13.1894],\n",
      "        [-2.6095, -4.0262, -3.8825,  ..., -5.5758,  5.8995, 13.1894],\n",
      "        ...,\n",
      "        [-4.4486, -4.2843, -5.6725,  ..., 11.3074, -3.1002, -3.3768],\n",
      "        [-4.3301, -4.0616, -5.0287,  ..., 10.8033, -2.9512, -3.1728],\n",
      "        [-4.3220, -4.1924, -5.6559,  ..., 11.8534, -2.7353, -2.5669]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8031, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2870,  965,  403,  ..., 2033,  712, 2378],\n",
      "        [1884, 1846, 1384,  ..., 4915, 1447, 5032],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1884, 1846, 1384,  ..., 4915, 1447, 5032],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6097, -4.0256, -3.8800,  ..., -5.5767,  5.9003, 13.1891],\n",
      "        [-2.6097, -4.0256, -3.8800,  ..., -5.5767,  5.9003, 13.1891],\n",
      "        [-2.6097, -4.0256, -3.8800,  ..., -5.5767,  5.9003, 13.1891],\n",
      "        ...,\n",
      "        [-4.6724, -3.3078, -3.9603,  ...,  8.6271, -2.6039, -2.7236],\n",
      "        [-4.6490, -4.5020, -5.5312,  ..., 11.3230, -2.6028, -2.4565],\n",
      "        [-4.6449, -4.4073, -5.7111,  ..., 11.7915, -2.7489, -2.8181]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8813, grad_fn=<NllLossBackward>)\n",
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花李。', '月下，一番春风雨。', '夜蓉雨                                                                                                                                                                                                     ', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番花开舞。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1401, 3197, 3575,  ..., 5295, 4383, 3563],\n",
      "        [2915, 2848, 4052,  ..., 5295,   56, 3439],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2915, 2848, 4052,  ..., 5295,   56, 3439],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6102, -4.0244, -3.8777,  ..., -5.5766,  5.9022, 13.1870],\n",
      "        [-2.6102, -4.0244, -3.8777,  ..., -5.5766,  5.9022, 13.1870],\n",
      "        [-2.6102, -4.0244, -3.8777,  ..., -5.5766,  5.9022, 13.1870],\n",
      "        ...,\n",
      "        [-3.3947, -4.0565, -5.9296,  ...,  7.7945, -0.2653, -0.1847],\n",
      "        [-3.9102, -3.7230, -4.7144,  ...,  9.8950, -3.0369, -2.9670],\n",
      "        [-4.6651, -3.4528, -4.6563,  ..., 10.8846, -2.9424, -2.7153]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8318, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5183, 2181, 4753,  ..., 1947, 3689, 3087],\n",
      "        [4244, 2168,  806,  ..., 4585,   43, 3500],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4244, 2168,  806,  ..., 4585,   43, 3500],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6109, -4.0231, -3.8756,  ..., -5.5756,  5.9043, 13.1845],\n",
      "        [-2.6109, -4.0231, -3.8756,  ..., -5.5756,  5.9043, 13.1845],\n",
      "        [-2.6109, -4.0231, -3.8756,  ..., -5.5756,  5.9043, 13.1845],\n",
      "        ...,\n",
      "        [-4.3142, -3.9259, -5.1956,  ..., 10.7163, -3.1399, -3.0441],\n",
      "        [-4.1244, -3.7996, -5.3256,  ...,  8.6202, -2.4200, -2.5101],\n",
      "        [-4.3593, -3.9451, -5.6514,  ..., 10.9285, -3.1674, -3.2738]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.6845, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4087, 5183, 4123,  ..., 3205, 4470, 1146],\n",
      "        [4052, 5183, 2022,  ...,  851, 3547, 5054],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4052, 5183, 2022,  ...,  851, 3547, 5054],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6115, -4.0216, -3.8736,  ..., -5.5757,  5.9041, 13.1847],\n",
      "        [-2.6115, -4.0216, -3.8736,  ..., -5.5757,  5.9041, 13.1847],\n",
      "        [-2.6115, -4.0216, -3.8736,  ..., -5.5757,  5.9041, 13.1847],\n",
      "        ...,\n",
      "        [-4.1801, -4.2991, -5.4559,  ..., 10.9292, -2.7193, -3.0101],\n",
      "        [-4.6760, -4.0531, -5.5214,  ..., 11.5632, -3.4878, -3.3986],\n",
      "        [-3.8200, -3.8683, -5.1298,  ...,  8.9910, -3.5704, -3.8104]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8264, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2785, 2378, 3331,  ..., 1639,  750, 2704],\n",
      "        [1957,  526, 1831,  ..., 2992, 1271, 4052],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1957,  526, 1831,  ..., 2992, 1271, 4052],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6122, -4.0204, -3.8716,  ..., -5.5764,  5.9032, 13.1859],\n",
      "        [-2.6122, -4.0204, -3.8716,  ..., -5.5764,  5.9032, 13.1859],\n",
      "        [-2.6122, -4.0204, -3.8716,  ..., -5.5764,  5.9032, 13.1859],\n",
      "        ...,\n",
      "        [-4.2670, -3.6957, -4.3158,  ..., 11.0701, -2.3378, -2.2957],\n",
      "        [-4.4128, -4.0189, -5.0638,  ..., 10.9768, -2.9798, -2.9189],\n",
      "        [-4.6681, -3.6214, -4.3206,  ..., 11.6747, -2.4663, -2.4162]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7465, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3366, 5033, 4025,  ..., 5275, 4041, 1399],\n",
      "        [2602, 4346,  841,  ..., 2058, 1584, 3634],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2602, 4346,  841,  ..., 2058, 1584, 3634],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6131, -4.0197, -3.8700,  ..., -5.5769,  5.9006, 13.1894],\n",
      "        [-2.6131, -4.0197, -3.8700,  ..., -5.5769,  5.9006, 13.1894],\n",
      "        [-2.6131, -4.0197, -3.8700,  ..., -5.5769,  5.9006, 13.1894],\n",
      "        ...,\n",
      "        [-4.5117, -4.0524, -5.4144,  ..., 10.3628, -3.3999, -3.3408],\n",
      "        [-4.1978, -4.0584, -4.5535,  ...,  9.3451, -3.0164, -3.0895],\n",
      "        [-4.0123, -3.7296, -4.6688,  ...,  9.2277, -3.2667, -3.2304]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7724, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4265, 1579, 2807,  ..., 1550, 1922,  380],\n",
      "        [ 965,  466, 2181,  ...,  989, 1940, 4944],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 965,  466, 2181,  ...,  989, 1940, 4944],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6141, -4.0192, -3.8685,  ..., -5.5767,  5.8981, 13.1928],\n",
      "        [-2.6141, -4.0192, -3.8685,  ..., -5.5767,  5.8981, 13.1928],\n",
      "        [-2.6141, -4.0192, -3.8685,  ..., -5.5767,  5.8981, 13.1928],\n",
      "        ...,\n",
      "        [-4.2528, -3.8905, -5.1592,  ..., 11.2220, -3.5029, -3.6241],\n",
      "        [-4.6954, -4.5851, -5.6514,  ..., 10.8876, -2.9840, -2.8241],\n",
      "        [-4.1052, -4.3020, -5.7804,  ..., 11.7264, -2.9285, -2.7903]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.6734, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4305,  745,  745,  ..., 2629, 3521,  513],\n",
      "        [2486,  740, 3771,  ..., 5000, 4069, 1192],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2486,  740, 3771,  ..., 5000, 4069, 1192],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6144, -4.0190, -3.8659,  ..., -5.5766,  5.8935, 13.1982],\n",
      "        [-2.6144, -4.0190, -3.8659,  ..., -5.5766,  5.8935, 13.1982],\n",
      "        [-2.6144, -4.0190, -3.8659,  ..., -5.5766,  5.8935, 13.1982],\n",
      "        ...,\n",
      "        [-4.5919, -3.6349, -4.4370,  ..., 10.5111, -3.2854, -3.1069],\n",
      "        [-4.5533, -3.9108, -5.3374,  ..., 10.5331, -2.6883, -2.3103],\n",
      "        [-4.4186, -4.3289, -5.6091,  ..., 10.8949, -2.5809, -2.7302]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8217, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5295, 3196,  639,  ..., 2763,  709,  831],\n",
      "        [5295, 4551,   43,  ..., 4533, 4363, 4265],\n",
      "        [5294,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5295, 4551,   43,  ..., 4533, 4363, 4265],\n",
      "        [5294,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6131, -4.0191, -3.8635,  ..., -5.5761,  5.8909, 13.2015],\n",
      "        [-2.6131, -4.0191, -3.8635,  ..., -5.5761,  5.8909, 13.2015],\n",
      "        [-2.6131, -4.0191, -3.8635,  ..., -5.5761,  5.8909, 13.2015],\n",
      "        ...,\n",
      "        [-4.3346, -3.9268, -4.7369,  ..., 11.1257, -2.7937, -2.7039],\n",
      "        [-4.3557, -3.9393, -5.3554,  ..., 10.4595, -3.4690, -3.4688],\n",
      "        [-4.5466, -3.6773, -5.6061,  ..., 11.6294, -2.7575, -2.8476]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8409, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 832, 2369, 3878,  ..., 1192, 1968, 1976],\n",
      "        [3092, 4988,  129,  ...,  851, 1654,  321],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3092, 4988,  129,  ...,  851, 1654,  321],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6123, -4.0196, -3.8614,  ..., -5.5758,  5.8894, 13.2035],\n",
      "        [-2.6123, -4.0196, -3.8614,  ..., -5.5758,  5.8894, 13.2035],\n",
      "        [-2.6123, -4.0196, -3.8614,  ..., -5.5758,  5.8894, 13.2035],\n",
      "        ...,\n",
      "        [-4.6392, -3.5278, -4.5768,  ..., 11.6519, -3.0518, -2.8937],\n",
      "        [-4.6801, -3.8924, -5.0007,  ..., 11.2171, -2.9094, -2.9383],\n",
      "        [-4.1379, -4.5354, -5.3558,  ...,  8.1625, -2.7573, -3.2092]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8558, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4987, 2629, 4168,  ..., 1401, 4357, 3500],\n",
      "        [2152,  314, 4987,  ..., 2414, 1796, 2389],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2152,  314, 4987,  ..., 2414, 1796, 2389],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6117, -4.0198, -3.8597,  ..., -5.5775,  5.8888, 13.2049],\n",
      "        [-2.6117, -4.0198, -3.8597,  ..., -5.5775,  5.8888, 13.2049],\n",
      "        [-2.6117, -4.0198, -3.8597,  ..., -5.5775,  5.8888, 13.2049],\n",
      "        ...,\n",
      "        [-4.1217, -4.1589, -5.3067,  ..., 10.2072, -3.3168, -3.5132],\n",
      "        [-3.9635, -4.3420, -5.1607,  ..., 10.6148, -2.5415, -2.8667],\n",
      "        [-4.3739, -4.4165, -4.8820,  ..., 10.2046, -3.4057, -3.1894]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8445, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1452, 4340, 1427,  ..., 3714, 3978,  740],\n",
      "        [ 964, 1654, 2586,  ...,   71, 3074, 3321],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 964, 1654, 2586,  ...,   71, 3074, 3321],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6113, -4.0202, -3.8583,  ..., -5.5798,  5.8895, 13.2052],\n",
      "        [-2.6113, -4.0202, -3.8583,  ..., -5.5798,  5.8895, 13.2052],\n",
      "        [-2.6113, -4.0202, -3.8583,  ..., -5.5798,  5.8895, 13.2052],\n",
      "        ...,\n",
      "        [-4.0173, -3.9284, -5.2946,  ...,  8.9013, -3.1440, -3.3728],\n",
      "        [-4.4330, -3.9102, -5.2468,  ..., 11.4679, -3.3154, -3.1208],\n",
      "        [-4.0663, -4.3325, -5.8414,  ..., 11.2374, -3.0007, -3.2148]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7740, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3417,  325, 4465,  ..., 4265,  790,  996],\n",
      "        [2793, 1427, 2333,  ...,  825, 4091, 1150],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2793, 1427, 2333,  ...,  825, 4091, 1150],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6112, -4.0204, -3.8570,  ..., -5.5816,  5.8914, 13.2040],\n",
      "        [-2.6112, -4.0204, -3.8570,  ..., -5.5816,  5.8914, 13.2040],\n",
      "        [-2.6112, -4.0204, -3.8570,  ..., -5.5816,  5.8914, 13.2040],\n",
      "        ...,\n",
      "        [-4.6897, -3.8823, -5.3877,  ..., 11.6940, -3.2185, -3.2842],\n",
      "        [-4.1543, -3.6385, -4.7703,  ...,  7.4813, -3.6068, -3.5756],\n",
      "        [-4.8378, -4.4460, -5.1632,  ..., 11.1434, -2.7385, -2.5588]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9100, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2947, 4021, 2602,  ..., 3611,    4,  574],\n",
      "        [ 783, 1437, 2927,  ..., 2309, 3563, 3527],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 783, 1437, 2927,  ..., 2309, 3563, 3527],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6114, -4.0207, -3.8560,  ..., -5.5820,  5.8951, 13.1996],\n",
      "        [-2.6114, -4.0207, -3.8560,  ..., -5.5820,  5.8951, 13.1996],\n",
      "        [-2.6114, -4.0207, -3.8560,  ..., -5.5820,  5.8951, 13.1996],\n",
      "        ...,\n",
      "        [-4.0688, -3.9404, -5.1539,  ..., 10.2523, -3.0139, -3.2226],\n",
      "        [-4.3741, -4.0792, -5.3245,  ..., 10.8880, -2.7423, -2.9563],\n",
      "        [-4.1105, -4.1200, -5.7517,  ...,  9.4804, -2.3615, -2.4705]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9772, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [   4, 2244,   15,  ...,  709, 3661, 4101],\n",
      "        [3852,  321, 1796,  ..., 3609, 2369, 4069],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3852,  321, 1796,  ..., 3609, 2369, 4069],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6119, -4.0210, -3.8552,  ..., -5.5830,  5.9006, 13.1931],\n",
      "        [-2.6119, -4.0210, -3.8552,  ..., -5.5830,  5.9006, 13.1931],\n",
      "        [-2.6119, -4.0210, -3.8552,  ..., -5.5830,  5.9006, 13.1931],\n",
      "        ...,\n",
      "        [-3.9632, -3.9113, -5.2467,  ..., 10.5904, -3.4031, -3.5780],\n",
      "        [-4.4324, -4.2418, -4.8838,  ...,  9.4592, -1.9442, -2.3601],\n",
      "        [-4.1290, -3.6447, -5.1709,  ..., 10.1700, -3.6043, -3.8505]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7551, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 712, 4825, 4125,  ..., 4017, 4823,  969],\n",
      "        [3328, 4937,  745,  ..., 1271, 5058,  832],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3328, 4937,  745,  ..., 1271, 5058,  832],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6110, -4.0206, -3.8546,  ..., -5.5849,  5.9047, 13.1885],\n",
      "        [-2.6110, -4.0206, -3.8546,  ..., -5.5849,  5.9047, 13.1885],\n",
      "        [-2.6110, -4.0206, -3.8546,  ..., -5.5849,  5.9047, 13.1885],\n",
      "        ...,\n",
      "        [-4.1274, -3.4116, -5.0055,  ...,  9.5272, -3.2215, -3.4253],\n",
      "        [-3.7844, -4.1174, -5.3841,  ..., 10.2649, -2.3616, -2.5694],\n",
      "        [-4.4270, -3.9836, -5.4360,  ..., 10.3716, -3.0378, -3.2011]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9743, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1767, 5295, 3771,  ..., 1922, 3331,  806],\n",
      "        [1579, 5295, 2773,  ..., 4987,  861, 3186],\n",
      "        [ 436, 5294,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1579, 5295, 2773,  ..., 4987,  861, 3186],\n",
      "        [ 436, 5294,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6089, -4.0192, -3.8543,  ..., -5.5879,  5.9102, 13.1829],\n",
      "        [-2.6089, -4.0192, -3.8543,  ..., -5.5879,  5.9102, 13.1829],\n",
      "        [-2.6089, -4.0192, -3.8543,  ..., -5.5879,  5.9102, 13.1829],\n",
      "        ...,\n",
      "        [-4.1943, -4.7785, -6.1044,  ..., 10.4702, -3.0104, -3.0546],\n",
      "        [-4.0820, -4.2338, -5.3372,  ..., 10.9729, -2.7222, -2.9689],\n",
      "        [-4.1123, -3.7771, -5.4806,  ...,  9.7776, -3.0981, -2.9658]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8307, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 105, 2809, 1108,  ..., 4087,  576, 3597],\n",
      "        [2219, 1245,  965,  ..., 4825,  948, 2873],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2219, 1245,  965,  ..., 4825,  948, 2873],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6048, -4.0173, -3.8540,  ..., -5.5911,  5.9139, 13.1795],\n",
      "        [-2.6048, -4.0173, -3.8540,  ..., -5.5911,  5.9139, 13.1795],\n",
      "        [-2.6048, -4.0173, -3.8540,  ..., -5.5911,  5.9139, 13.1795],\n",
      "        ...,\n",
      "        [-3.9950, -4.2894, -5.6039,  ..., 10.5879, -3.0917, -3.2152],\n",
      "        [-4.1832, -3.9050, -4.4603,  ...,  9.1354, -3.5047, -3.5372],\n",
      "        [-4.5958, -3.5364, -4.5904,  ..., 11.2183, -3.1924, -2.9740]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8675, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3331, 4465, 4467,  ...,  307,  796,   76],\n",
      "        [4679, 3074, 1884,  ..., 3670, 4987, 1474],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4679, 3074, 1884,  ..., 3670, 4987, 1474],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6014, -4.0161, -3.8535,  ..., -5.5921,  5.9170, 13.1763],\n",
      "        [-2.6014, -4.0161, -3.8535,  ..., -5.5921,  5.9170, 13.1763],\n",
      "        [-2.6014, -4.0161, -3.8535,  ..., -5.5921,  5.9170, 13.1763],\n",
      "        ...,\n",
      "        [-4.2842, -3.6556, -5.2890,  ..., 10.2596, -3.3144, -3.1825],\n",
      "        [-4.1979, -4.4009, -4.9031,  ..., 10.3275, -2.4808, -2.7977],\n",
      "        [-4.0631, -4.0592, -5.2514,  ..., 10.0057, -3.1275, -3.3044]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0024, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4330, 5211, 2947,  ..., 4470, 4181, 4809],\n",
      "        [2936, 4294, 1399,  ..., 3500, 1724, 1535],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2936, 4294, 1399,  ..., 3500, 1724, 1535],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5987, -4.0152, -3.8530,  ..., -5.5924,  5.9201, 13.1731],\n",
      "        [-2.5987, -4.0152, -3.8530,  ..., -5.5924,  5.9201, 13.1731],\n",
      "        [-2.5987, -4.0152, -3.8530,  ..., -5.5924,  5.9201, 13.1731],\n",
      "        ...,\n",
      "        [-4.8356, -4.5222, -5.4232,  ..., 10.9990, -3.1615, -3.1889],\n",
      "        [-4.4941, -3.6690, -4.9922,  ..., 10.7050, -2.4922, -2.2353],\n",
      "        [-4.2436, -4.0017, -5.2915,  ..., 10.6964, -3.3217, -3.2698]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8859, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1767, 5275, 2771,  ..., 5295, 2991, 1437],\n",
      "        [1976,  283, 4052,  ..., 5295, 4331, 4060],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1976,  283, 4052,  ..., 5295, 4331, 4060],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5964, -4.0147, -3.8525,  ..., -5.5933,  5.9213, 13.1721],\n",
      "        [-2.5964, -4.0147, -3.8525,  ..., -5.5933,  5.9213, 13.1721],\n",
      "        [-2.5964, -4.0147, -3.8525,  ..., -5.5933,  5.9213, 13.1721],\n",
      "        ...,\n",
      "        [-3.3578, -4.0523, -5.9417,  ...,  7.9435, -0.2934, -0.2329],\n",
      "        [-4.6882, -3.8172, -4.9470,  ..., 11.4712, -3.2388, -3.0127],\n",
      "        [-4.5507, -4.5525, -4.6551,  ..., 10.0178, -2.1762, -2.2951]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8711, grad_fn=<NllLossBackward>)\n",
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花李。', '月下，一番春风雨。', '夜蓉雨                                                                                                                                                                                                     ', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番花开舞。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4346, 2159, 3376,  ..., 2915, 2378, 2601],\n",
      "        [2987, 1258, 2122,  ..., 2809,  526,  192],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2987, 1258, 2122,  ..., 2809,  526,  192],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5939, -4.0147, -3.8523,  ..., -5.5945,  5.9206, 13.1738],\n",
      "        [-2.5939, -4.0147, -3.8523,  ..., -5.5945,  5.9206, 13.1738],\n",
      "        [-2.5939, -4.0147, -3.8523,  ..., -5.5945,  5.9206, 13.1738],\n",
      "        ...,\n",
      "        [-4.2201, -4.1442, -5.8112,  ...,  9.6980, -3.2830, -3.5561],\n",
      "        [-4.1615, -4.2880, -5.3716,  ..., 10.5407, -2.7864, -2.9975],\n",
      "        [-4.3443, -4.2637, -5.3745,  ...,  9.5261, -3.1539, -3.4384]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9433, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2763, 4329, 4840,  ..., 4200, 4103, 1401],\n",
      "        [4679, 2956, 4963,  ..., 1937, 1010, 4291],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4679, 2956, 4963,  ..., 1937, 1010, 4291],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5920, -4.0152, -3.8521,  ..., -5.5955,  5.9192, 13.1764],\n",
      "        [-2.5920, -4.0152, -3.8521,  ..., -5.5955,  5.9192, 13.1764],\n",
      "        [-2.5920, -4.0152, -3.8521,  ..., -5.5955,  5.9192, 13.1764],\n",
      "        ...,\n",
      "        [-4.8090, -4.0732, -5.1449,  ..., 10.6974, -3.0135, -2.6574],\n",
      "        [-4.2934, -3.7706, -5.1677,  ..., 11.7997, -3.1961, -3.3600],\n",
      "        [-4.3302, -3.8731, -5.2926,  ..., 10.2691, -3.0461, -3.0816]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0077, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1922,  791,  625,  ..., 2082,  712, 1648],\n",
      "        [1398, 1906, 2598,  ...,  952, 4263, 2022],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1398, 1906, 2598,  ...,  952, 4263, 2022],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5904, -4.0157, -3.8522,  ..., -5.5971,  5.9187, 13.1776],\n",
      "        [-2.5904, -4.0157, -3.8522,  ..., -5.5971,  5.9187, 13.1776],\n",
      "        [-2.5904, -4.0157, -3.8522,  ..., -5.5971,  5.9187, 13.1776],\n",
      "        ...,\n",
      "        [-4.3545, -4.0521, -5.0116,  ..., 11.5497, -3.4650, -3.0946],\n",
      "        [-4.0874, -3.9123, -4.6762,  ...,  7.9823, -3.4037, -3.5450],\n",
      "        [-4.8338, -4.2117, -5.1751,  ..., 12.2548, -2.9488, -2.5695]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.1208, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3522, 2629, 2582,  ..., 3152,  593, 1081],\n",
      "        [ 298, 3898, 2244,  ..., 3331, 2164,  468],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 298, 3898, 2244,  ..., 3331, 2164,  468],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5893, -4.0149, -3.8525,  ..., -5.5980,  5.9202, 13.1759],\n",
      "        [-2.5893, -4.0149, -3.8525,  ..., -5.5980,  5.9202, 13.1759],\n",
      "        [-2.5893, -4.0149, -3.8525,  ..., -5.5980,  5.9202, 13.1759],\n",
      "        ...,\n",
      "        [-3.8664, -4.2933, -5.0363,  ...,  8.1203, -2.3706, -2.7824],\n",
      "        [-4.8904, -3.9531, -4.8442,  ..., 11.2728, -2.9132, -2.9186],\n",
      "        [-4.6307, -3.9795, -4.7008,  ..., 10.7423, -3.1199, -3.0296]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9603, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4813, 2645,   43,  ..., 4467, 4877, 1272],\n",
      "        [1262, 2844, 5275,  ..., 1216,  220, 2219],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1262, 2844, 5275,  ..., 1216,  220, 2219],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5888, -4.0135, -3.8530,  ..., -5.5985,  5.9206, 13.1750],\n",
      "        [-2.5888, -4.0135, -3.8530,  ..., -5.5985,  5.9206, 13.1750],\n",
      "        [-2.5888, -4.0135, -3.8530,  ..., -5.5985,  5.9206, 13.1750],\n",
      "        ...,\n",
      "        [-4.2428, -3.9090, -5.6469,  ...,  9.9325, -2.8706, -2.9465],\n",
      "        [-4.2282, -3.9199, -5.0771,  ..., 11.6621, -3.4589, -3.4759],\n",
      "        [-4.6007, -4.3499, -5.3370,  ...,  9.9024, -3.3567, -3.2274]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9263, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4265, 4614, 5295,  ...,   15, 2809,  321],\n",
      "        [3466, 4614, 5295,  ..., 1796, 4679, 2349],\n",
      "        [ 436,  436, 5294,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3466, 4614, 5295,  ..., 1796, 4679, 2349],\n",
      "        [ 436,  436, 5294,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5884, -4.0111, -3.8534,  ..., -5.6006,  5.9197, 13.1753],\n",
      "        [-2.5884, -4.0111, -3.8534,  ..., -5.6006,  5.9197, 13.1753],\n",
      "        [-2.5884, -4.0111, -3.8534,  ..., -5.6006,  5.9197, 13.1753],\n",
      "        ...,\n",
      "        [-3.9058, -4.1250, -5.3910,  ...,  9.8127, -2.8097, -2.8242],\n",
      "        [-4.2196, -4.5431, -5.4833,  ...,  9.9387, -3.1146, -3.2081],\n",
      "        [-4.7162, -4.5160, -5.2671,  ..., 11.5062, -2.8593, -2.9454]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9640, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2227, 1661, 3390,  ..., 4052, 2490,  861],\n",
      "        [2891,  745,  220,  ...,  528, 2586,  745],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2891,  745,  220,  ...,  528, 2586,  745],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5884, -4.0084, -3.8539,  ..., -5.6024,  5.9189, 13.1757],\n",
      "        [-2.5884, -4.0084, -3.8539,  ..., -5.6024,  5.9189, 13.1757],\n",
      "        [-2.5884, -4.0084, -3.8539,  ..., -5.6024,  5.9189, 13.1757],\n",
      "        ...,\n",
      "        [-4.1602, -4.5533, -4.8807,  ...,  8.3551, -2.3857, -2.2689],\n",
      "        [-3.9995, -4.0256, -5.4504,  ..., 10.2809, -3.2659, -3.3417],\n",
      "        [-4.5111, -3.6625, -4.8425,  ..., 11.8429, -2.6394, -2.4148]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9034, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 114, 1706, 1237,  ..., 1989, 3710, 1384],\n",
      "        [1266, 2022, 3069,  ..., 2848, 1884, 2486],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1266, 2022, 3069,  ..., 2848, 1884, 2486],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5873, -4.0064, -3.8545,  ..., -5.6034,  5.9172, 13.1769],\n",
      "        [-2.5873, -4.0064, -3.8545,  ..., -5.6034,  5.9172, 13.1769],\n",
      "        [-2.5873, -4.0064, -3.8545,  ..., -5.6034,  5.9172, 13.1769],\n",
      "        ...,\n",
      "        [-3.8244, -3.8833, -5.6317,  ...,  8.9724, -3.1798, -3.2621],\n",
      "        [-4.4857, -3.7841, -4.3449,  ..., 11.2923, -3.4611, -3.2375],\n",
      "        [-4.2749, -3.8541, -5.1701,  ..., 10.5822, -3.2222, -3.0957]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0101, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2204, 5160, 3428,  ..., 3061, 2349, 4204],\n",
      "        [3665,  982, 1614,  ..., 2809, 2059, 2961],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3665,  982, 1614,  ..., 2809, 2059, 2961],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5867, -4.0049, -3.8551,  ..., -5.6035,  5.9168, 13.1769],\n",
      "        [-2.5867, -4.0049, -3.8551,  ..., -5.6035,  5.9168, 13.1769],\n",
      "        [-2.5867, -4.0049, -3.8551,  ..., -5.6035,  5.9168, 13.1769],\n",
      "        ...,\n",
      "        [-4.9732, -4.3519, -5.2911,  ..., 11.0780, -2.9440, -2.7127],\n",
      "        [-4.4305, -4.2735, -5.6293,  ..., 12.1534, -2.9779, -2.8416],\n",
      "        [-4.4367, -3.9350, -5.7076,  ..., 11.0103, -2.9003, -2.9565]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8955, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5081, 1731, 1427,  ..., 3046, 2048,  811],\n",
      "        [ 321, 4069, 1526,  ..., 3575, 2374, 4465],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 321, 4069, 1526,  ..., 3575, 2374, 4465],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5853, -4.0036, -3.8557,  ..., -5.6047,  5.9150, 13.1791],\n",
      "        [-2.5853, -4.0036, -3.8557,  ..., -5.6047,  5.9150, 13.1791],\n",
      "        [-2.5853, -4.0036, -3.8557,  ..., -5.6047,  5.9150, 13.1791],\n",
      "        ...,\n",
      "        [-4.2260, -4.3281, -5.7782,  ..., 11.4459, -3.0165, -3.0643],\n",
      "        [-4.8975, -4.0437, -4.5721,  ..., 10.4242, -2.4951, -1.9845],\n",
      "        [-4.5739, -3.7875, -4.7227,  ..., 11.2731, -3.7314, -3.6220]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8660, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1888, 1309, 1661,  ..., 2405, 5183, 3898],\n",
      "        [4123,  390, 3061,  ...,  513, 5183, 3941],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4123,  390, 3061,  ...,  513, 5183, 3941],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5844, -4.0026, -3.8563,  ..., -5.6065,  5.9120, 13.1833],\n",
      "        [-2.5844, -4.0026, -3.8563,  ..., -5.6065,  5.9120, 13.1833],\n",
      "        [-2.5844, -4.0026, -3.8563,  ..., -5.6065,  5.9120, 13.1833],\n",
      "        ...,\n",
      "        [-4.5837, -3.6326, -4.6016,  ..., 11.5224, -2.6978, -2.3545],\n",
      "        [-5.0687, -5.0465, -5.5329,  ...,  9.0646, -1.0200, -1.0511],\n",
      "        [-4.6960, -4.0635, -4.6924,  ..., 12.0929, -3.4574, -2.9769]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9103, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 712, 3898, 1144,  ..., 1017, 4682,  965],\n",
      "        [3085, 4825, 1401,  ..., 1131, 3712, 2809],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3085, 4825, 1401,  ..., 1131, 3712, 2809],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5838, -4.0000, -3.8567,  ..., -5.6075,  5.9092, 13.1869],\n",
      "        [-2.5838, -4.0000, -3.8567,  ..., -5.6075,  5.9092, 13.1869],\n",
      "        [-2.5838, -4.0000, -3.8567,  ..., -5.6075,  5.9092, 13.1869],\n",
      "        ...,\n",
      "        [-4.1082, -4.1681, -4.3298,  ..., 10.5672, -2.5858, -2.4762],\n",
      "        [-4.6994, -3.8152, -4.8200,  ..., 11.6642, -2.9787, -2.7209],\n",
      "        [-4.4713, -4.2013, -5.6322,  ..., 11.5756, -2.8772, -3.1887]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8847, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 545, 3844, 1452,  ..., 1888, 3934, 2013],\n",
      "        [4679, 3844, 4944,  ..., 5081,  852, 4348],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4679, 3844, 4944,  ..., 5081,  852, 4348],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5833, -3.9967, -3.8570,  ..., -5.6093,  5.9071, 13.1900],\n",
      "        [-2.5833, -3.9967, -3.8570,  ..., -5.6093,  5.9071, 13.1900],\n",
      "        [-2.5833, -3.9967, -3.8570,  ..., -5.6093,  5.9071, 13.1900],\n",
      "        ...,\n",
      "        [-4.2398, -4.1933, -5.3550,  ..., 11.5298, -3.2709, -3.2011],\n",
      "        [-3.8758, -3.9064, -5.4421,  ...,  8.5555, -3.6650, -4.0389],\n",
      "        [-4.5673, -3.8817, -4.4567,  ...,  9.4845, -3.1791, -3.0106]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8145, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4575, 2378, 2460,  ..., 3542, 1661, 3898],\n",
      "        [ 825, 3909, 3522,  ..., 2792, 1192, 1086],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 825, 3909, 3522,  ..., 2792, 1192, 1086],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5830, -3.9940, -3.8573,  ..., -5.6104,  5.9056, 13.1925],\n",
      "        [-2.5830, -3.9940, -3.8573,  ..., -5.6104,  5.9056, 13.1925],\n",
      "        [-2.5830, -3.9940, -3.8573,  ..., -5.6104,  5.9056, 13.1925],\n",
      "        ...,\n",
      "        [-4.4196, -4.5920, -5.4883,  ..., 10.7397, -2.9520, -2.9793],\n",
      "        [-4.4345, -4.7575, -6.1243,  ..., 11.1895, -2.7243, -2.7114],\n",
      "        [-4.3780, -4.0295, -5.7337,  ..., 11.0814, -2.8067, -2.6792]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9953, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4914, 2909, 3277,  ..., 2924, 1076, 4193],\n",
      "        [4821, 2909, 4263,  ..., 2058, 1959, 5081],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4821, 2909, 4263,  ..., 2058, 1959, 5081],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5829, -3.9912, -3.8574,  ..., -5.6128,  5.9058, 13.1928],\n",
      "        [-2.5829, -3.9912, -3.8574,  ..., -5.6128,  5.9058, 13.1928],\n",
      "        [-2.5829, -3.9912, -3.8574,  ..., -5.6128,  5.9058, 13.1928],\n",
      "        ...,\n",
      "        [-3.8103, -3.9398, -5.7346,  ...,  8.2236, -2.9453, -3.1496],\n",
      "        [-4.1257, -4.1857, -5.1604,  ..., 11.2896, -3.3820, -3.4556],\n",
      "        [-4.2876, -3.7353, -5.3956,  ..., 11.0997, -3.4050, -3.3489]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8964, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5102, 2941, 4840,  ..., 4052,   44, 3898],\n",
      "        [3061, 5275, 3119,  ..., 3547, 2873,  192],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3061, 5275, 3119,  ..., 3547, 2873,  192],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5830, -3.9889, -3.8576,  ..., -5.6147,  5.9067, 13.1926],\n",
      "        [-2.5830, -3.9889, -3.8576,  ..., -5.6147,  5.9067, 13.1926],\n",
      "        [-2.5830, -3.9889, -3.8576,  ..., -5.6147,  5.9067, 13.1926],\n",
      "        ...,\n",
      "        [-4.6516, -3.8539, -4.4956,  ..., 11.3698, -3.3996, -2.8342],\n",
      "        [-4.1591, -3.8785, -5.1020,  ..., 10.9331, -3.5423, -3.4056],\n",
      "        [-4.3074, -4.0081, -4.6101,  ...,  8.1568, -3.3762, -3.2847]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8665, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4528, 3898, 3563,  ..., 3166, 4017, 4021],\n",
      "        [5275, 4348, 2941,  ..., 3173,   35, 1230],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5275, 4348, 2941,  ..., 3173,   35, 1230],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5833, -3.9855, -3.8576,  ..., -5.6155,  5.9085, 13.1905],\n",
      "        [-2.5833, -3.9855, -3.8576,  ..., -5.6155,  5.9085, 13.1905],\n",
      "        [-2.5833, -3.9855, -3.8576,  ..., -5.6155,  5.9085, 13.1905],\n",
      "        ...,\n",
      "        [-5.0687, -4.0278, -4.8416,  ..., 11.0058, -2.5481, -2.2310],\n",
      "        [-4.2445, -3.9491, -5.3865,  ..., 11.6497, -3.2841, -3.3344],\n",
      "        [-4.7074, -4.0781, -4.9907,  ..., 11.8865, -3.3233, -3.0176]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9405, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2979, 3061, 3277,  ..., 1808, 1030, 3390],\n",
      "        [ 298,   35,  148,  ..., 3298,  738, 2234],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 298,   35,  148,  ..., 3298,  738, 2234],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5836, -3.9825, -3.8578,  ..., -5.6171,  5.9111, 13.1876],\n",
      "        [-2.5836, -3.9825, -3.8578,  ..., -5.6171,  5.9111, 13.1876],\n",
      "        [-2.5836, -3.9825, -3.8578,  ..., -5.6171,  5.9111, 13.1876],\n",
      "        ...,\n",
      "        [-4.1484, -4.5428, -5.9187,  ..., 10.9621, -2.9129, -2.8137],\n",
      "        [-4.4839, -4.1607, -5.1862,  ..., 11.1355, -2.7034, -2.6024],\n",
      "        [-4.3488, -3.9648, -5.4597,  ..., 11.3859, -3.4168, -3.4223]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8421, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1579,  466, 4877,  ...,  151, 2152, 3331],\n",
      "        [2058, 3607, 5081,  ..., 2058, 2412, 3092],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2058, 3607, 5081,  ..., 2058, 2412, 3092],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5842, -3.9801, -3.8580,  ..., -5.6188,  5.9138, 13.1848],\n",
      "        [-2.5842, -3.9801, -3.8580,  ..., -5.6188,  5.9138, 13.1848],\n",
      "        [-2.5842, -3.9801, -3.8580,  ..., -5.6188,  5.9138, 13.1848],\n",
      "        ...,\n",
      "        [-4.3883, -3.9786, -5.6836,  ..., 10.5443, -3.0282, -2.9649],\n",
      "        [-4.5770, -3.8479, -5.4402,  ..., 10.0020, -3.2768, -3.3153],\n",
      "        [-4.4178, -3.9108, -4.9821,  ...,  9.0216, -2.8942, -2.8298]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0077, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3749, 1231, 1789,  ..., 2694, 1779,   15],\n",
      "        [1579, 2595, 4467,  ..., 5009, 5165, 1094],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1579, 2595, 4467,  ..., 5009, 5165, 1094],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5850, -3.9782, -3.8586,  ..., -5.6207,  5.9177, 13.1807],\n",
      "        [-2.5850, -3.9782, -3.8586,  ..., -5.6207,  5.9177, 13.1807],\n",
      "        [-2.5850, -3.9782, -3.8586,  ..., -5.6207,  5.9177, 13.1807],\n",
      "        ...,\n",
      "        [-4.0152, -3.7211, -5.2253,  ..., 10.6857, -3.3968, -3.6530],\n",
      "        [-4.0168, -4.4738, -5.1732,  ..., 10.4527, -3.0169, -2.9901],\n",
      "        [-4.2389, -4.0943, -5.5890,  ..., 11.4549, -2.9366, -2.7175]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9155, grad_fn=<NllLossBackward>)\n",
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花李。', '月下，一番春风雨。', '夜蓉雨                                                                                                                                                                                                     ', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番番月下，一片春风。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1272, 2579, 3030,  ..., 2017,   35,   43],\n",
      "        [1787,  321, 3382,  ...,  768, 2763, 1384],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1787,  321, 3382,  ...,  768, 2763, 1384],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5860, -3.9768, -3.8577,  ..., -5.6233,  5.9205, 13.1779],\n",
      "        [-2.5860, -3.9768, -3.8577,  ..., -5.6233,  5.9205, 13.1779],\n",
      "        [-2.5860, -3.9768, -3.8577,  ..., -5.6233,  5.9205, 13.1779],\n",
      "        ...,\n",
      "        [-4.2198, -3.7181, -5.9857,  ..., 10.4065, -2.3018, -2.3777],\n",
      "        [-4.0842, -4.5518, -5.8613,  ..., 11.9830, -2.6863, -2.7796],\n",
      "        [-4.0283, -3.9410, -5.6899,  ...,  9.8428, -2.7888, -2.6819]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8381, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5102, 1081, 3400,  ..., 4460, 4266,  321],\n",
      "        [5083, 4753, 4882,  ..., 4069, 4052, 2933],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5083, 4753, 4882,  ..., 4069, 4052, 2933],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5873, -3.9759, -3.8571,  ..., -5.6260,  5.9219, 13.1766],\n",
      "        [-2.5873, -3.9759, -3.8571,  ..., -5.6260,  5.9219, 13.1766],\n",
      "        [-2.5873, -3.9759, -3.8571,  ..., -5.6260,  5.9219, 13.1766],\n",
      "        ...,\n",
      "        [-4.3163, -3.9005, -5.5658,  ..., 10.9712, -3.1498, -3.1908],\n",
      "        [-2.3085, -3.8715, -5.6679,  ...,  3.8504, -2.4226, -2.7377],\n",
      "        [-4.3300, -4.1914, -5.2638,  ..., 11.6206, -3.2008, -2.9567]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9840, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1888, 4525, 4747,  ...,  705, 3061, 2405],\n",
      "        [1502, 4737, 2871,  ..., 2033, 4753, 2369],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1502, 4737, 2871,  ..., 2033, 4753, 2369],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5888, -3.9753, -3.8564,  ..., -5.6268,  5.9235, 13.1742],\n",
      "        [-2.5888, -3.9753, -3.8564,  ..., -5.6268,  5.9235, 13.1742],\n",
      "        [-2.5888, -3.9753, -3.8564,  ..., -5.6268,  5.9235, 13.1742],\n",
      "        ...,\n",
      "        [-4.3208, -4.3636, -5.8695,  ..., 12.3366, -2.5304, -2.4163],\n",
      "        [-4.1777, -3.9734, -5.3969,  ..., 10.5962, -3.1151, -3.3036],\n",
      "        [-4.6354, -3.8513, -4.2661,  ..., 10.9507, -2.5427, -2.2132]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9074, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 572,  639,  381,  ...,  321,    4, 4470],\n",
      "        [1618,  805, 1030,  ..., 3560,  468, 3500],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1618,  805, 1030,  ..., 3560,  468, 3500],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5905, -3.9751, -3.8558,  ..., -5.6272,  5.9253, 13.1716],\n",
      "        [-2.5905, -3.9751, -3.8558,  ..., -5.6272,  5.9253, 13.1716],\n",
      "        [-2.5905, -3.9751, -3.8558,  ..., -5.6272,  5.9253, 13.1716],\n",
      "        ...,\n",
      "        [-4.3641, -4.3838, -5.4811,  ..., 11.3426, -2.8074, -2.9807],\n",
      "        [-4.1151, -4.0818, -5.5471,  ...,  9.3611, -3.3964, -3.5492],\n",
      "        [-4.2450, -3.9878, -5.6724,  ..., 10.1040, -3.4204, -3.4900]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8702, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1246, 3428, 1662,  ..., 1888, 3563, 4560],\n",
      "        [  94, 4069, 2136,  ..., 3823, 3096, 4305],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  94, 4069, 2136,  ..., 3823, 3096, 4305],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5922, -3.9752, -3.8553,  ..., -5.6283,  5.9258, 13.1706],\n",
      "        [-2.5922, -3.9752, -3.8553,  ..., -5.6283,  5.9258, 13.1706],\n",
      "        [-2.5922, -3.9752, -3.8553,  ..., -5.6283,  5.9258, 13.1706],\n",
      "        ...,\n",
      "        [-4.8304, -3.5713, -4.5020,  ..., 10.9802, -2.8011, -2.2899],\n",
      "        [-3.9415, -3.6626, -5.2619,  ...,  8.5163, -2.8500, -3.0393],\n",
      "        [-4.6405, -3.7106, -4.7832,  ..., 11.6607, -3.1289, -3.0934]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8049, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4905, 2947, 3046,  ..., 2936,  996, 1888],\n",
      "        [3087, 1618, 4166,  ...,  436,  745, 1989],\n",
      "        [ 436,  436,  436,  ..., 2738,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3087, 1618, 4166,  ...,  436,  745, 1989],\n",
      "        [ 436,  436,  436,  ..., 2738,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5940, -3.9756, -3.8550,  ..., -5.6305,  5.9243, 13.1729],\n",
      "        [-2.5940, -3.9756, -3.8550,  ..., -5.6305,  5.9243, 13.1729],\n",
      "        [-2.5940, -3.9756, -3.8550,  ..., -5.6305,  5.9243, 13.1729],\n",
      "        ...,\n",
      "        [-4.7612, -4.5998, -4.8344,  ...,  6.4124, -1.7140, -1.4141],\n",
      "        [-4.5077, -4.3368, -5.6717,  ..., 12.0144, -2.5895, -2.7158],\n",
      "        [-4.5064, -3.6622, -4.2845,  ..., 10.8548, -2.4816, -1.9265]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9311, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 301, 5295,  360,  ...,  811, 1158,  974],\n",
      "        [1398, 5295, 4899,  ..., 4166, 5107, 4838],\n",
      "        [ 436, 5294,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1398, 5295, 4899,  ..., 4166, 5107, 4838],\n",
      "        [ 436, 5294,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5957, -3.9762, -3.8546,  ..., -5.6326,  5.9226, 13.1757],\n",
      "        [-2.5957, -3.9762, -3.8546,  ..., -5.6326,  5.9226, 13.1757],\n",
      "        [-2.5957, -3.9762, -3.8546,  ..., -5.6326,  5.9226, 13.1757],\n",
      "        ...,\n",
      "        [-4.2225, -4.4256, -5.2478,  ...,  8.2942, -2.7552, -2.8221],\n",
      "        [-4.1737, -3.6806, -5.3107,  ..., 10.2050, -2.5453, -2.9302],\n",
      "        [-4.3905, -3.5767, -4.8598,  ...,  9.9204, -2.9282, -3.1061]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8433, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3693,  432, 1940,  ..., 2809,  792, 3331],\n",
      "        [2922, 3331, 5275,  ..., 2058, 1913,  562],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2922, 3331, 5275,  ..., 2058, 1913,  562],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5975, -3.9769, -3.8540,  ..., -5.6329,  5.9202, 13.1783],\n",
      "        [-2.5975, -3.9769, -3.8540,  ..., -5.6329,  5.9202, 13.1783],\n",
      "        [-2.5975, -3.9769, -3.8540,  ..., -5.6329,  5.9202, 13.1783],\n",
      "        ...,\n",
      "        [-4.4919, -4.0953, -5.5098,  ...,  8.9660, -2.8302, -2.9428],\n",
      "        [-4.3658, -3.8360, -5.3471,  ..., 11.4489, -2.8652, -2.7682],\n",
      "        [-4.1871, -3.9265, -5.2534,  ..., 10.4161, -3.3744, -3.4644]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9161, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4340, 5159, 2844,  ...,  307, 4003, 2733],\n",
      "        [2587, 1911, 1194,  ..., 2244, 1937, 4465],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2587, 1911, 1194,  ..., 2244, 1937, 4465],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.5995, -3.9753, -3.8534,  ..., -5.6322,  5.9188, 13.1795],\n",
      "        [-2.5995, -3.9753, -3.8534,  ..., -5.6322,  5.9188, 13.1795],\n",
      "        [-2.5995, -3.9753, -3.8534,  ..., -5.6322,  5.9188, 13.1795],\n",
      "        ...,\n",
      "        [-4.3170, -4.6205, -5.1566,  ..., 11.1579, -2.8610, -2.7544],\n",
      "        [-4.4071, -4.0735, -5.0614,  ..., 11.3094, -3.3291, -2.9026],\n",
      "        [-4.7483, -4.0342, -4.7732,  ..., 11.2961, -3.3070, -3.1252]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9124, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 192, 4470, 2991,  ..., 1262, 3862, 3428],\n",
      "        [  43, 2792, 3022,  ..., 3667,  843, 2080],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  43, 2792, 3022,  ..., 3667,  843, 2080],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6014, -3.9740, -3.8530,  ..., -5.6332,  5.9165, 13.1824],\n",
      "        [-2.6014, -3.9740, -3.8530,  ..., -5.6332,  5.9165, 13.1824],\n",
      "        [-2.6014, -3.9740, -3.8530,  ..., -5.6332,  5.9165, 13.1824],\n",
      "        ...,\n",
      "        [-4.7347, -4.2198, -4.5706,  ..., 10.3161, -2.5261, -2.5889],\n",
      "        [-4.5009, -3.9708, -5.0841,  ..., 10.7616, -2.4317, -2.3764],\n",
      "        [-4.2546, -3.5560, -5.0915,  ..., 11.0710, -3.3257, -3.2383]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9250, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3030, 1661, 1086,  ..., 1913, 4265,  201],\n",
      "        [  75,  513, 2773,  ..., 4266, 4176, 4241],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  75,  513, 2773,  ..., 4266, 4176, 4241],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6034, -3.9730, -3.8528,  ..., -5.6347,  5.9131, 13.1869],\n",
      "        [-2.6034, -3.9730, -3.8528,  ..., -5.6347,  5.9131, 13.1869],\n",
      "        [-2.6034, -3.9730, -3.8528,  ..., -5.6347,  5.9131, 13.1869],\n",
      "        ...,\n",
      "        [-4.5330, -3.8106, -5.1689,  ..., 12.1180, -3.1828, -3.1729],\n",
      "        [-4.7109, -3.9641, -5.0923,  ..., 11.2412, -3.0721, -2.9044],\n",
      "        [-4.3147, -3.7184, -5.3217,  ...,  9.6713, -3.1839, -2.9704]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8684, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [   4,  321, 5183,  ..., 4905, 4614, 3765],\n",
      "        [3563, 2936, 5183,  ...,  974, 2383, 1064],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3563, 2936, 5183,  ...,  974, 2383, 1064],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6055, -3.9724, -3.8528,  ..., -5.6365,  5.9094, 13.1914],\n",
      "        [-2.6055, -3.9724, -3.8528,  ..., -5.6365,  5.9094, 13.1914],\n",
      "        [-2.6055, -3.9724, -3.8528,  ..., -5.6365,  5.9094, 13.1914],\n",
      "        ...,\n",
      "        [-4.2815, -3.9137, -5.2406,  ..., 11.7005, -3.1175, -3.0494],\n",
      "        [-4.2201, -4.3071, -5.7232,  ...,  8.9526, -2.9817, -3.1428],\n",
      "        [-4.2159, -3.5603, -5.0799,  ...,  9.7954, -3.4898, -3.6032]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9167, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3255, 1271,  768,  ..., 3061, 1452, 2941],\n",
      "        [2873, 3807, 3382,  ...,  965, 3087, 3068],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2873, 3807, 3382,  ...,  965, 3087, 3068],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6076, -3.9712, -3.8529,  ..., -5.6362,  5.9074, 13.1932],\n",
      "        [-2.6076, -3.9712, -3.8529,  ..., -5.6362,  5.9074, 13.1932],\n",
      "        [-2.6076, -3.9712, -3.8529,  ..., -5.6362,  5.9074, 13.1932],\n",
      "        ...,\n",
      "        [-4.4444, -4.3141, -5.8957,  ..., 11.1157, -2.9153, -3.1101],\n",
      "        [-4.5183, -4.2454, -5.0881,  ..., 11.3860, -2.8761, -2.7872],\n",
      "        [-4.0331, -4.4063, -5.9175,  ...,  9.6666, -3.1398, -3.1449]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0189, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4265,  712,  688,  ...,   43, 3252, 2460],\n",
      "        [4839, 2900, 1187,  ..., 2093, 4782, 1888],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4839, 2900, 1187,  ..., 2093, 4782, 1888],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6100, -3.9687, -3.8530,  ..., -5.6355,  5.9071, 13.1933],\n",
      "        [-2.6100, -3.9687, -3.8530,  ..., -5.6355,  5.9071, 13.1933],\n",
      "        [-2.6100, -3.9687, -3.8530,  ..., -5.6355,  5.9071, 13.1933],\n",
      "        ...,\n",
      "        [-4.5037, -3.9608, -5.7078,  ..., 10.7858, -2.8503, -2.6786],\n",
      "        [-3.9180, -4.1342, -5.4291,  ..., 10.4029, -2.7364, -3.0736],\n",
      "        [-4.7366, -3.7688, -4.5159,  ..., 10.8157, -2.0343, -2.1003]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8423, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3068, 1266, 1081,  ..., 3290, 1116, 1826],\n",
      "        [4963, 3021, 1980,  ...,  325, 3544, 2201],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4963, 3021, 1980,  ...,  325, 3544, 2201],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6123, -3.9653, -3.8534,  ..., -5.6367,  5.9041, 13.1972],\n",
      "        [-2.6123, -3.9653, -3.8534,  ..., -5.6367,  5.9041, 13.1972],\n",
      "        [-2.6123, -3.9653, -3.8534,  ..., -5.6367,  5.9041, 13.1972],\n",
      "        ...,\n",
      "        [-2.1210, -3.6154, -5.9586,  ...,  4.0677, -2.1363, -2.2623],\n",
      "        [-4.7108, -3.8298, -5.7904,  ..., 10.7958, -2.7683, -2.7238],\n",
      "        [-4.5471, -3.9837, -5.1623,  ..., 12.4053, -3.0391, -3.0712]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8527, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3661, 4460, 5173,  ..., 4021, 1240,  360],\n",
      "        [2586, 3279, 5047,  ..., 1058, 2181, 4581],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2586, 3279, 5047,  ..., 1058, 2181, 4581],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6144, -3.9608, -3.8530,  ..., -5.6389,  5.8986, 13.2033],\n",
      "        [-2.6144, -3.9608, -3.8530,  ..., -5.6389,  5.8986, 13.2033],\n",
      "        [-2.6144, -3.9608, -3.8530,  ..., -5.6389,  5.8986, 13.2033],\n",
      "        ...,\n",
      "        [-4.8589, -3.6085, -4.7990,  ..., 10.8061, -2.5078, -2.5464],\n",
      "        [-4.1615, -4.1681, -5.2798,  ..., 11.0779, -2.4187, -2.5082],\n",
      "        [-4.1026, -4.4305, -5.4813,  ...,  9.2417, -2.6965, -2.7601]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9586, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3382, 2032,  745,  ..., 2793, 4265, 4155],\n",
      "        [4903,  468, 4340,  ..., 4771, 4052, 2930],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4903,  468, 4340,  ..., 4771, 4052, 2930],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6167, -3.9569, -3.8525,  ..., -5.6404,  5.8947, 13.2080],\n",
      "        [-2.6167, -3.9569, -3.8525,  ..., -5.6404,  5.8947, 13.2080],\n",
      "        [-2.6167, -3.9569, -3.8525,  ..., -5.6404,  5.8947, 13.2080],\n",
      "        ...,\n",
      "        [-4.5039, -3.8991, -4.9154,  ...,  9.3243, -3.0966, -3.0010],\n",
      "        [-4.4765, -3.7716, -5.6797,  ..., 11.8572, -2.8809, -2.7193],\n",
      "        [-4.4603, -4.2490, -5.0249,  ..., 10.5924, -3.1809, -2.9983]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8395, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3087, 4904, 4465,  ...,  745, 4916, 2991],\n",
      "        [ 436,  620, 1251,  ..., 2987, 4916, 4813],\n",
      "        [2738,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 436,  620, 1251,  ..., 2987, 4916, 4813],\n",
      "        [2738,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6189, -3.9537, -3.8520,  ..., -5.6402,  5.8912, 13.2116],\n",
      "        [-2.6189, -3.9537, -3.8520,  ..., -5.6402,  5.8912, 13.2116],\n",
      "        [-2.6189, -3.9537, -3.8520,  ..., -5.6402,  5.8912, 13.2116],\n",
      "        ...,\n",
      "        [-4.4241, -3.6853, -4.9411,  ..., 11.2035, -1.9694, -2.2450],\n",
      "        [-4.1409, -3.8173, -5.8039,  ..., 10.2701, -2.1767, -2.2072],\n",
      "        [-4.4753, -3.8960, -5.5345,  ..., 12.2449, -3.1165, -3.2450]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9228, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2991,   71, 4312,  ..., 2181, 4265, 2586],\n",
      "        [ 961, 2017, 1282,  ..., 4346, 4839,  429],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 961, 2017, 1282,  ..., 4346, 4839,  429],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6202, -3.9498, -3.8514,  ..., -5.6411,  5.8889, 13.2134],\n",
      "        [-2.6202, -3.9498, -3.8514,  ..., -5.6411,  5.8889, 13.2134],\n",
      "        [-2.6202, -3.9498, -3.8514,  ..., -5.6411,  5.8889, 13.2134],\n",
      "        ...,\n",
      "        [-4.3396, -3.8188, -5.0051,  ..., 10.9706, -3.1936, -3.0478],\n",
      "        [-4.6388, -4.1108, -5.8797,  ..., 12.1216, -2.8872, -2.9943],\n",
      "        [-4.4190, -3.6528, -4.7486,  ..., 11.3090, -3.3258, -3.1204]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9626, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2629, 3668, 1705,  ...,   25,   15,  692],\n",
      "        [3331, 1843, 4753,  ..., 2412, 1796, 2763],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3331, 1843, 4753,  ..., 2412, 1796, 2763],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6216, -3.9456, -3.8512,  ..., -5.6434,  5.8878, 13.2143],\n",
      "        [-2.6216, -3.9456, -3.8512,  ..., -5.6434,  5.8878, 13.2143],\n",
      "        [-2.6216, -3.9456, -3.8512,  ..., -5.6434,  5.8878, 13.2143],\n",
      "        ...,\n",
      "        [-4.7076, -3.9010, -4.9639,  ..., 10.7420, -3.4547, -3.3385],\n",
      "        [-3.8483, -3.8842, -5.7796,  ...,  9.4933, -2.6588, -3.2128],\n",
      "        [-4.0875, -4.4792, -6.0135,  ..., 11.3315, -2.5428, -2.6550]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8401, grad_fn=<NllLossBackward>)\n",
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花李。', '月下，一番春风雨。', '夜蓉雨                                                                                                                                                                                                     ', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番花开舞。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4305, 2159,  861,  ..., 1120, 1514,   36],\n",
      "        [2058,  825,  843,  ..., 1293, 4750,  560],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2058,  825,  843,  ..., 1293, 4750,  560],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6230, -3.9418, -3.8511,  ..., -5.6475,  5.8852, 13.2178],\n",
      "        [-2.6230, -3.9418, -3.8511,  ..., -5.6475,  5.8852, 13.2178],\n",
      "        [-2.6230, -3.9418, -3.8511,  ..., -5.6475,  5.8852, 13.2178],\n",
      "        ...,\n",
      "        [-4.4075, -4.1691, -5.1662,  ..., 12.1020, -2.7290, -2.5819],\n",
      "        [-4.7620, -3.8644, -5.0535,  ..., 11.6395, -2.7701, -2.4055],\n",
      "        [-4.3772, -3.5214, -4.7794,  ...,  8.7004, -3.4927, -3.5274]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9505, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2947, 1081, 1618,  ..., 3092,   35, 2809],\n",
      "        [2689, 3101, 2369,  ...,  389,  709, 4679],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2689, 3101, 2369,  ...,  389,  709, 4679],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6242, -3.9379, -3.8508,  ..., -5.6517,  5.8833, 13.2200],\n",
      "        [-2.6242, -3.9379, -3.8508,  ..., -5.6517,  5.8833, 13.2200],\n",
      "        [-2.6242, -3.9379, -3.8508,  ..., -5.6517,  5.8833, 13.2200],\n",
      "        ...,\n",
      "        [-3.9756, -4.3207, -5.5761,  ..., 10.0714, -2.9401, -3.3333],\n",
      "        [-4.1989, -4.1954, -5.7569,  ...,  8.9713, -3.1984, -3.4129],\n",
      "        [-4.6574, -4.2499, -5.8267,  ..., 11.7260, -3.0623, -2.8591]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8999, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 301, 4577, 5214,  ..., 1158, 2313, 3844],\n",
      "        [2778,  173, 3085,  ...,  351, 4944, 4672],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2778,  173, 3085,  ...,  351, 4944, 4672],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6255, -3.9346, -3.8505,  ..., -5.6542,  5.8828, 13.2204],\n",
      "        [-2.6255, -3.9346, -3.8505,  ..., -5.6542,  5.8828, 13.2204],\n",
      "        [-2.6255, -3.9346, -3.8505,  ..., -5.6542,  5.8828, 13.2204],\n",
      "        ...,\n",
      "        [-4.3799, -4.1197, -5.2305,  ..., 10.1012, -3.3757, -3.4890],\n",
      "        [-4.1048, -4.4187, -5.9003,  ..., 11.2341, -2.7566, -2.7792],\n",
      "        [-4.3190, -3.6384, -4.8467,  ...,  9.5493, -2.5086, -2.6304]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8654, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3864, 3575,    4,  ...,  118, 2378, 2961],\n",
      "        [4628, 4987, 1579,  ...,   51,   25, 4042],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4628, 4987, 1579,  ...,   51,   25, 4042],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6272, -3.9303, -3.8503,  ..., -5.6539,  5.8827, 13.2193],\n",
      "        [-2.6272, -3.9303, -3.8503,  ..., -5.6539,  5.8827, 13.2193],\n",
      "        [-2.6272, -3.9303, -3.8503,  ..., -5.6539,  5.8827, 13.2193],\n",
      "        ...,\n",
      "        [-4.6998, -4.4714, -5.1332,  ..., 11.6870, -2.6118, -2.5060],\n",
      "        [-4.7279, -4.0407, -5.0745,  ..., 11.7445, -2.1990, -2.1872],\n",
      "        [-3.8785, -3.6633, -4.8312,  ..., 10.2599, -3.2964, -3.2268]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9232, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1103,   49, 1194,  ..., 4823, 2763, 3795],\n",
      "        [ 277, 4825, 2827,  ..., 3030, 1119, 3833],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 277, 4825, 2827,  ..., 3030, 1119, 3833],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6290, -3.9265, -3.8502,  ..., -5.6539,  5.8830, 13.2179],\n",
      "        [-2.6290, -3.9265, -3.8502,  ..., -5.6539,  5.8830, 13.2179],\n",
      "        [-2.6290, -3.9265, -3.8502,  ..., -5.6539,  5.8830, 13.2179],\n",
      "        ...,\n",
      "        [-4.3040, -4.2492, -5.5673,  ..., 11.3380, -2.6986, -2.9498],\n",
      "        [-4.0278, -3.5198, -5.0543,  ..., 10.5484, -2.6374, -2.5519],\n",
      "        [-4.2696, -3.1318, -3.5427,  ...,  7.9374, -2.6730, -2.9596]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8250, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1834, 4155, 2378,  ...,  709,  321, 2624],\n",
      "        [2732, 3934, 1415,  ...,  965, 1348,  825],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2732, 3934, 1415,  ...,  965, 1348,  825],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6307, -3.9233, -3.8504,  ..., -5.6570,  5.8820, 13.2192],\n",
      "        [-2.6307, -3.9233, -3.8504,  ..., -5.6570,  5.8820, 13.2192],\n",
      "        [-2.6307, -3.9233, -3.8504,  ..., -5.6570,  5.8820, 13.2192],\n",
      "        ...,\n",
      "        [-4.5089, -3.7824, -5.5630,  ..., 11.8852, -3.0772, -3.1206],\n",
      "        [-4.5791, -4.3385, -5.2245,  ..., 10.4819, -2.9271, -3.1937],\n",
      "        [-4.5130, -4.3898, -5.5629,  ..., 10.7900, -3.1688, -3.3806]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7541, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4465, 3795, 3046,  ..., 3257, 1081, 1452],\n",
      "        [2047, 1463, 4166,  ..., 2776, 1792,  379],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2047, 1463, 4166,  ..., 2776, 1792,  379],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6326, -3.9202, -3.8507,  ..., -5.6610,  5.8795, 13.2230],\n",
      "        [-2.6326, -3.9202, -3.8507,  ..., -5.6610,  5.8795, 13.2230],\n",
      "        [-2.6326, -3.9202, -3.8507,  ..., -5.6610,  5.8795, 13.2230],\n",
      "        ...,\n",
      "        [-4.3631, -4.4808, -5.2871,  ..., 10.7717, -2.5985, -2.8764],\n",
      "        [-4.5924, -4.1778, -5.8954,  ..., 10.1495, -2.7644, -2.6175],\n",
      "        [-3.6611, -4.2495, -5.8551,  ...,  9.9312, -2.7796, -2.8880]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8115, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 912, 2793,   71,  ..., 2689,  321,  192],\n",
      "        [1220, 2193,  800,  ..., 3331, 2809, 4919],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1220, 2193,  800,  ..., 3331, 2809, 4919],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6336, -3.9177, -3.8509,  ..., -5.6640,  5.8767, 13.2264],\n",
      "        [-2.6336, -3.9177, -3.8509,  ..., -5.6640,  5.8767, 13.2264],\n",
      "        [-2.6336, -3.9177, -3.8509,  ..., -5.6640,  5.8767, 13.2264],\n",
      "        ...,\n",
      "        [-4.4430, -4.4897, -6.0334,  ..., 12.3036, -2.8106, -2.9363],\n",
      "        [-4.4101, -3.8429, -4.8741,  ...,  9.0543, -2.9599, -2.8247],\n",
      "        [-4.0625, -3.3567, -3.6607,  ...,  7.3601, -2.4662, -2.7608]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9171, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3575,  639,    4,  ..., 3806, 2991, 3134],\n",
      "        [ 831, 1452, 4526,  ..., 1748, 1423, 1323],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 831, 1452, 4526,  ..., 1748, 1423, 1323],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6349, -3.9154, -3.8511,  ..., -5.6652,  5.8761, 13.2262],\n",
      "        [-2.6349, -3.9154, -3.8511,  ..., -5.6652,  5.8761, 13.2262],\n",
      "        [-2.6349, -3.9154, -3.8511,  ..., -5.6652,  5.8761, 13.2262],\n",
      "        ...,\n",
      "        [-4.9159, -3.7151, -4.6394,  ..., 11.5574, -2.9101, -2.9482],\n",
      "        [-4.2694, -3.8442, -5.1309,  ..., 10.4008, -3.3226, -3.1641],\n",
      "        [-4.4239, -3.9204, -4.2759,  ..., 11.7859, -3.5172, -2.8257]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8745, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2991,  321, 4470,  ..., 2219,  831, 3061],\n",
      "        [3022, 1197, 1427,  ..., 4679, 1540, 2809],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3022, 1197, 1427,  ..., 4679, 1540, 2809],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6363, -3.9133, -3.8512,  ..., -5.6661,  5.8756, 13.2256],\n",
      "        [-2.6363, -3.9133, -3.8512,  ..., -5.6661,  5.8756, 13.2256],\n",
      "        [-2.6363, -3.9133, -3.8512,  ..., -5.6661,  5.8756, 13.2256],\n",
      "        ...,\n",
      "        [-4.1158, -4.4061, -5.5225,  ..., 11.2537, -3.2062, -3.2475],\n",
      "        [-3.9348, -3.8176, -5.8113,  ..., 10.0885, -3.2236, -3.4397],\n",
      "        [-4.5399, -4.1993, -5.7246,  ..., 11.5575, -3.0069, -3.2684]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8618, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2870, 1237, 5283,  ...,  283,    4, 1728],\n",
      "        [1884, 3466, 3428,  ..., 3286, 3828, 2197],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1884, 3466, 3428,  ..., 3286, 3828, 2197],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6377, -3.9116, -3.8514,  ..., -5.6683,  5.8749, 13.2260],\n",
      "        [-2.6377, -3.9116, -3.8514,  ..., -5.6683,  5.8749, 13.2260],\n",
      "        [-2.6377, -3.9116, -3.8514,  ..., -5.6683,  5.8749, 13.2260],\n",
      "        ...,\n",
      "        [-4.4480, -4.0540, -5.6097,  ..., 10.8952, -3.3833, -3.4279],\n",
      "        [-4.2056, -4.4681, -5.1716,  ...,  8.4866, -1.7681, -1.8431],\n",
      "        [-4.7029, -3.9295, -4.4887,  ..., 10.6322, -2.7143, -2.4516]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8724, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 283, 5295, 2984,  ..., 2347, 3428, 4393],\n",
      "        [2667, 5295,  970,  ..., 3087, 1210, 1435],\n",
      "        [ 436, 5294,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2667, 5295,  970,  ..., 3087, 1210, 1435],\n",
      "        [ 436, 5294,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6392, -3.9104, -3.8498,  ..., -5.6721,  5.8737, 13.2281],\n",
      "        [-2.6392, -3.9104, -3.8498,  ..., -5.6721,  5.8737, 13.2281],\n",
      "        [-2.6392, -3.9104, -3.8498,  ..., -5.6721,  5.8737, 13.2281],\n",
      "        ...,\n",
      "        [-4.0165, -4.3561, -5.3317,  ..., 10.8654, -3.1431, -3.0682],\n",
      "        [-4.5698, -4.2720, -5.3991,  ..., 10.6833, -3.4375, -3.3344],\n",
      "        [-3.7567, -2.9503, -4.3903,  ...,  8.7480, -3.2615, -3.0830]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8492, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 466, 2181, 3428,  ..., 2010, 1667, 1009],\n",
      "        [3087, 2667, 5032,  ..., 4265, 3898, 4585],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3087, 2667, 5032,  ..., 4265, 3898, 4585],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6406, -3.9087, -3.8481,  ..., -5.6765,  5.8719, 13.2312],\n",
      "        [-2.6406, -3.9087, -3.8481,  ..., -5.6765,  5.8719, 13.2312],\n",
      "        [-2.6406, -3.9087, -3.8481,  ..., -5.6765,  5.8719, 13.2312],\n",
      "        ...,\n",
      "        [-4.4116, -4.3417, -5.9175,  ..., 11.5187, -3.1260, -3.2873],\n",
      "        [-4.9637, -3.6128, -4.5911,  ..., 11.0403, -3.0762, -2.9302],\n",
      "        [-3.7857, -3.5909, -4.7947,  ...,  9.5374, -3.6539, -3.4303]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8667, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3828, 2378, 1847,  ..., 3665, 2809, 4087],\n",
      "        [4331,  528, 1989,  ..., 4346, 4679, 4729],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4331,  528, 1989,  ..., 4346, 4679, 4729],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6422, -3.9059, -3.8464,  ..., -5.6779,  5.8718, 13.2316],\n",
      "        [-2.6422, -3.9059, -3.8464,  ..., -5.6779,  5.8718, 13.2316],\n",
      "        [-2.6422, -3.9059, -3.8464,  ..., -5.6779,  5.8718, 13.2316],\n",
      "        ...,\n",
      "        [-4.1608, -3.7640, -5.5983,  ..., 10.3809, -3.4860, -3.4771],\n",
      "        [-4.4163, -4.4005, -5.8672,  ..., 10.4284, -3.1099, -3.0977],\n",
      "        [-4.6559, -3.9976, -5.3531,  ..., 11.2466, -3.4201, -3.2207]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8071, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4175, 1401, 4465,  ..., 1309, 2320,  965],\n",
      "        [ 298, 3409, 4737,  ..., 2164, 2629, 4075],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 298, 3409, 4737,  ..., 2164, 2629, 4075],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6439, -3.9036, -3.8448,  ..., -5.6776,  5.8724, 13.2306],\n",
      "        [-2.6439, -3.9036, -3.8448,  ..., -5.6776,  5.8724, 13.2306],\n",
      "        [-2.6439, -3.9036, -3.8448,  ..., -5.6776,  5.8724, 13.2306],\n",
      "        ...,\n",
      "        [-4.6586, -3.8877, -4.2028,  ..., 10.6898, -2.9391, -2.9238],\n",
      "        [-4.1170, -4.4056, -5.5894,  ..., 10.6693, -3.4170, -3.4611],\n",
      "        [-4.2047, -3.6189, -4.8737,  ...,  8.1635, -3.2174, -3.0776]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9296, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4471,  754, 1913,  ..., 4526,  321, 2195],\n",
      "        [2181, 5188, 1062,  ..., 2331,  965, 2164],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2181, 5188, 1062,  ..., 2331,  965, 2164],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6456, -3.9018, -3.8435,  ..., -5.6779,  5.8744, 13.2286],\n",
      "        [-2.6456, -3.9018, -3.8435,  ..., -5.6779,  5.8744, 13.2286],\n",
      "        [-2.6456, -3.9018, -3.8435,  ..., -5.6779,  5.8744, 13.2286],\n",
      "        ...,\n",
      "        [-4.6824, -3.8913, -4.6564,  ..., 11.1395, -2.8488, -2.8045],\n",
      "        [-4.3950, -4.1158, -5.6717,  ..., 11.4068, -3.2922, -3.5594],\n",
      "        [-4.9881, -3.5649, -4.2105,  ..., 11.0650, -2.8832, -2.9510]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8229, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4985, 2460,  712,  ...,  301, 2915, 4640],\n",
      "        [3205, 1888, 4549,  ..., 3712,  709, 4866],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3205, 1888, 4549,  ..., 3712,  709, 4866],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6471, -3.8989, -3.8425,  ..., -5.6812,  5.8741, 13.2304],\n",
      "        [-2.6471, -3.8989, -3.8425,  ..., -5.6812,  5.8741, 13.2304],\n",
      "        [-2.6471, -3.8989, -3.8425,  ..., -5.6812,  5.8741, 13.2304],\n",
      "        ...,\n",
      "        [-4.5702, -3.6872, -4.8231,  ..., 11.7520, -2.9228, -2.6246],\n",
      "        [-4.3823, -4.5898, -5.9828,  ..., 12.0550, -2.3973, -2.3655],\n",
      "        [-4.5078, -4.4218, -5.2339,  ..., 11.2291, -2.1049, -2.1678]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9928, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5076, 2159,  457,  ..., 2181, 2378, 2793],\n",
      "        [2058, 1194, 4265,  ..., 1565, 2309, 4052],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2058, 1194, 4265,  ..., 1565, 2309, 4052],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6473, -3.8960, -3.8418,  ..., -5.6857,  5.8748, 13.2312],\n",
      "        [-2.6473, -3.8960, -3.8418,  ..., -5.6857,  5.8748, 13.2312],\n",
      "        [-2.6473, -3.8960, -3.8418,  ..., -5.6857,  5.8748, 13.2312],\n",
      "        ...,\n",
      "        [-4.1146, -4.1110, -5.0654,  ...,  9.4629, -2.9163, -3.0961],\n",
      "        [-4.6020, -3.7683, -4.8664,  ..., 10.6973, -2.7126, -2.7747],\n",
      "        [-4.2642, -4.3599, -5.5079,  ..., 10.5958, -2.4768, -2.7591]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8162, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3046, 4541, 1542,  ...,  572, 1452, 2586],\n",
      "        [4166, 5162, 4746,  ...,  380, 3087,  965],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4166, 5162, 4746,  ...,  380, 3087,  965],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6477, -3.8936, -3.8412,  ..., -5.6887,  5.8751, 13.2317],\n",
      "        [-2.6477, -3.8936, -3.8412,  ..., -5.6887,  5.8751, 13.2317],\n",
      "        [-2.6477, -3.8936, -3.8412,  ..., -5.6887,  5.8751, 13.2317],\n",
      "        ...,\n",
      "        [-4.1017, -3.6784, -5.0030,  ...,  8.5945, -3.4596, -3.4342],\n",
      "        [-4.4809, -3.9467, -5.0579,  ...,  9.1016, -2.8421, -2.8025],\n",
      "        [-4.2536, -3.9576, -5.8624,  ..., 11.1563, -3.0955, -3.4119]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8541, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4151,  366, 1843,  ..., 1192, 3563, 2160],\n",
      "        [1980,  601, 5189,  ..., 2181,  466,  421],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1980,  601, 5189,  ..., 2181,  466,  421],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6484, -3.8911, -3.8403,  ..., -5.6880,  5.8757, 13.2300],\n",
      "        [-2.6484, -3.8911, -3.8403,  ..., -5.6880,  5.8757, 13.2300],\n",
      "        [-2.6484, -3.8911, -3.8403,  ..., -5.6880,  5.8757, 13.2300],\n",
      "        ...,\n",
      "        [-4.7270, -3.7891, -4.9647,  ..., 11.5602, -2.9584, -2.5322],\n",
      "        [-4.4541, -3.9064, -5.0956,  ..., 11.7934, -3.4980, -3.3768],\n",
      "        [-4.7898, -3.8301, -4.9925,  ..., 10.2540, -2.9844, -3.0395]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7753, grad_fn=<NllLossBackward>)\n",
      "['春暮                                                                                                                                                                                                      ', '江北水                                                                                                                                                                                                     ', '花李。', '月下，一番春风雨。', '夜蓉雨                                                                                                                                                                                                     ', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番花开舞。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2978, 4467, 5147,  ..., 4470,  192, 4530],\n",
      "        [3383, 4679, 3642,  ...,  325,  974,  923],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3383, 4679, 3642,  ...,  325,  974,  923],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6492, -3.8884, -3.8393,  ..., -5.6876,  5.8755, 13.2295],\n",
      "        [-2.6492, -3.8884, -3.8393,  ..., -5.6876,  5.8755, 13.2295],\n",
      "        [-2.6492, -3.8884, -3.8393,  ..., -5.6876,  5.8755, 13.2295],\n",
      "        ...,\n",
      "        [-4.2874, -4.4577, -6.1165,  ..., 11.8742, -3.0840, -3.0446],\n",
      "        [-4.3515, -3.9584, -5.4313,  ..., 11.4747, -3.0487, -3.0983],\n",
      "        [-4.4830, -3.7141, -4.9524,  ..., 11.3106, -3.0769, -3.2210]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8687, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2357, 1844,  659,  ...,  890, 5295, 4648],\n",
      "        [1430, 1844,  264,  ...,   14, 5295, 2586],\n",
      "        [ 436,  436,  436,  ...,  436, 5294,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1430, 1844,  264,  ...,   14, 5295, 2586],\n",
      "        [ 436,  436,  436,  ...,  436, 5294,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6490, -3.8861, -3.8386,  ..., -5.6897,  5.8744, 13.2309],\n",
      "        [-2.6490, -3.8861, -3.8386,  ..., -5.6897,  5.8744, 13.2309],\n",
      "        [-2.6490, -3.8861, -3.8386,  ..., -5.6897,  5.8744, 13.2309],\n",
      "        ...,\n",
      "        [-4.6190, -3.4179, -4.2878,  ..., 10.0458, -2.6962, -2.7205],\n",
      "        [-3.4859, -4.0971, -6.0244,  ...,  7.9000, -0.2877, -0.1887],\n",
      "        [-4.0881, -4.2833, -5.5892,  ..., 11.5795, -3.0100, -3.1699]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9104, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  43, 2624, 1779,  ..., 1340, 4585, 1117],\n",
      "        [3384, 4312,  861,  ..., 3236,  592, 4267],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3384, 4312,  861,  ..., 3236,  592, 4267],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6489, -3.8841, -3.8382,  ..., -5.6939,  5.8726, 13.2341],\n",
      "        [-2.6489, -3.8841, -3.8382,  ..., -5.6939,  5.8726, 13.2341],\n",
      "        [-2.6489, -3.8841, -3.8382,  ..., -5.6939,  5.8726, 13.2341],\n",
      "        ...,\n",
      "        [-4.1334, -4.2837, -4.8761,  ...,  9.9524, -2.8424, -3.1529],\n",
      "        [-4.0968, -3.7746, -5.3340,  ..., 10.8522, -3.1373, -3.3261],\n",
      "        [-4.4351, -3.9381, -4.7247,  ..., 11.4808, -3.4421, -3.5516]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8266, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 321, 2378,  593,  ..., 2309, 5241, 3665],\n",
      "        [1212, 3909, 2546,  ..., 2053, 1245, 1983],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1212, 3909, 2546,  ..., 2053, 1245, 1983],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6473, -3.8825, -3.8379,  ..., -5.6981,  5.8708, 13.2373],\n",
      "        [-2.6473, -3.8825, -3.8379,  ..., -5.6981,  5.8708, 13.2373],\n",
      "        [-2.6473, -3.8825, -3.8379,  ..., -5.6981,  5.8708, 13.2373],\n",
      "        ...,\n",
      "        [-4.7172, -3.7986, -4.8945,  ...,  9.9670, -3.6431, -3.5841],\n",
      "        [-3.9606, -4.0752, -5.9704,  ...,  9.7299, -2.6460, -2.8679],\n",
      "        [-4.5037, -3.9605, -4.3898,  ..., 10.9849, -3.2172, -2.4884]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7983, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2144, 1579, 1054,  ...,   38, 4002,  574],\n",
      "        [2058, 2058,  563,  ..., 1614, 1298, 3334],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2058, 2058,  563,  ..., 1614, 1298, 3334],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6447, -3.8814, -3.8373,  ..., -5.6994,  5.8692, 13.2391],\n",
      "        [-2.6447, -3.8814, -3.8373,  ..., -5.6994,  5.8692, 13.2391],\n",
      "        [-2.6447, -3.8814, -3.8373,  ..., -5.6994,  5.8692, 13.2391],\n",
      "        ...,\n",
      "        [-4.2051, -4.1633, -5.8421,  ...,  9.1232, -3.0683, -3.0038],\n",
      "        [-4.1462, -3.8489, -5.5772,  ..., 11.0986, -3.3672, -3.3159],\n",
      "        [-4.2858, -3.9767, -5.8235,  ..., 11.2686, -2.8917, -3.0661]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9938, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5188, 4623, 3689,  ..., 1246, 3611, 1925],\n",
      "        [3424, 2369, 4166,  ..., 4148, 2488, 3661],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3424, 2369, 4166,  ..., 4148, 2488, 3661],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6430, -3.8787, -3.8370,  ..., -5.6997,  5.8710, 13.2367],\n",
      "        [-2.6430, -3.8787, -3.8370,  ..., -5.6997,  5.8710, 13.2367],\n",
      "        [-2.6430, -3.8787, -3.8370,  ..., -5.6997,  5.8710, 13.2367],\n",
      "        ...,\n",
      "        [-4.7822, -3.9244, -4.7303,  ..., 10.9280, -3.0620, -2.5464],\n",
      "        [-4.1698, -3.8031, -4.9938,  ..., 12.2148, -3.2246, -3.2724],\n",
      "        [-4.7826, -3.9471, -4.9512,  ..., 11.3100, -3.2275, -2.9136]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8599, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 818, 2947,  843,  ..., 5183, 2309, 4682],\n",
      "        [2624, 1492, 3983,  ..., 5183, 1767, 3712],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2624, 1492, 3983,  ..., 5183, 1767, 3712],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6416, -3.8751, -3.8368,  ..., -5.7013,  5.8726, 13.2352],\n",
      "        [-2.6416, -3.8751, -3.8368,  ..., -5.7013,  5.8726, 13.2352],\n",
      "        [-2.6416, -3.8751, -3.8368,  ..., -5.7013,  5.8726, 13.2352],\n",
      "        ...,\n",
      "        [-4.8121, -4.9955, -5.1775,  ...,  7.6705, -0.6965, -0.5863],\n",
      "        [-4.3074, -3.9740, -5.0927,  ..., 10.8405, -3.4565, -3.5620],\n",
      "        [-4.8936, -3.9048, -5.4956,  ..., 11.6333, -2.7548, -2.4804]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9305, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2412, 3331, 3277,  ...,  593, 3290, 1192],\n",
      "        [1748, 2792,  852,  ..., 2127, 4052,  168],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1748, 2792,  852,  ..., 2127, 4052,  168],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6406, -3.8721, -3.8370,  ..., -5.7044,  5.8740, 13.2345],\n",
      "        [-2.6406, -3.8721, -3.8370,  ..., -5.7044,  5.8740, 13.2345],\n",
      "        [-2.6406, -3.8721, -3.8370,  ..., -5.7044,  5.8740, 13.2345],\n",
      "        ...,\n",
      "        [-4.5658, -3.6490, -4.6177,  ..., 11.0617, -3.4019, -3.0557],\n",
      "        [-4.2776, -3.7835, -5.1815,  ..., 10.2645, -3.1097, -3.1472],\n",
      "        [-3.4041, -3.8137, -5.3118,  ...,  6.0105, -2.3420, -2.6658]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8091, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1452, 2460, 4052,  ...,   43, 4467, 1618],\n",
      "        [4963, 1648, 1989,  ...,  843,  432, 5189],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4963, 1648, 1989,  ...,  843,  432, 5189],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6397, -3.8694, -3.8371,  ..., -5.7087,  5.8735, 13.2361],\n",
      "        [-2.6397, -3.8694, -3.8371,  ..., -5.7087,  5.8735, 13.2361],\n",
      "        [-2.6397, -3.8694, -3.8371,  ..., -5.7087,  5.8735, 13.2361],\n",
      "        ...,\n",
      "        [-4.4543, -3.6345, -5.1082,  ...,  9.8994, -2.7708, -2.7403],\n",
      "        [-4.3961, -3.9375, -5.6088,  ..., 11.8126, -3.0793, -3.2682],\n",
      "        [-4.0661, -3.7611, -4.8555,  ...,  9.4763, -3.4452, -3.1220]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7769, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4533, 1772, 1054,  ...,  380,  712, 1309],\n",
      "        [4560, 2306, 5240,  ..., 2181,   81, 4107],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4560, 2306, 5240,  ..., 2181,   81, 4107],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6391, -3.8673, -3.8372,  ..., -5.7118,  5.8722, 13.2382],\n",
      "        [-2.6391, -3.8673, -3.8372,  ..., -5.7118,  5.8722, 13.2382],\n",
      "        [-2.6391, -3.8673, -3.8372,  ..., -5.7118,  5.8722, 13.2382],\n",
      "        ...,\n",
      "        [-4.1990, -3.9608, -5.6373,  ...,  9.5737, -2.8188, -2.9609],\n",
      "        [-3.8958, -4.2192, -5.4070,  ...,  9.1347, -3.2583, -3.4537],\n",
      "        [-3.8994, -3.3819, -4.1489,  ...,  8.5800, -2.9851, -2.7265]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7824, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 825,  513, 4831,  ..., 1894, 2586, 4526],\n",
      "        [4838, 3382, 1987,  ..., 4777, 2964, 4987],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4838, 3382, 1987,  ..., 4777, 2964, 4987],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6389, -3.8657, -3.8371,  ..., -5.7122,  5.8720, 13.2383],\n",
      "        [-2.6389, -3.8657, -3.8371,  ..., -5.7122,  5.8720, 13.2383],\n",
      "        [-2.6389, -3.8657, -3.8371,  ..., -5.7122,  5.8720, 13.2383],\n",
      "        ...,\n",
      "        [-3.9047, -3.9260, -5.4994,  ...,  9.8522, -3.1370, -3.1737],\n",
      "        [-4.4707, -4.0961, -5.4994,  ..., 11.8652, -3.0001, -2.8421],\n",
      "        [-4.1994, -3.8067, -5.2758,  ...,  9.7198, -2.7933, -2.9180]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8113, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 466,  740, 1054,  ...,   43, 3321, 2159],\n",
      "        [3907, 3321,   51,  ...,  466, 3481, 2486],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3907, 3321,   51,  ...,  466, 3481, 2486],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6389, -3.8645, -3.8373,  ..., -5.7122,  5.8712, 13.2384],\n",
      "        [-2.6389, -3.8645, -3.8373,  ..., -5.7122,  5.8712, 13.2384],\n",
      "        [-2.6389, -3.8645, -3.8373,  ..., -5.7122,  5.8712, 13.2384],\n",
      "        ...,\n",
      "        [-4.1047, -4.0863, -5.4230,  ...,  9.8413, -3.0852, -3.2034],\n",
      "        [-4.0523, -3.9358, -5.8533,  ...,  9.3889, -2.5502, -2.3642],\n",
      "        [-4.6209, -3.6467, -4.8005,  ..., 10.9605, -2.7359, -2.6329]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8744, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  35, 1232, 3400,  ..., 5102, 4178, 1452],\n",
      "        [2763,  366, 2058,  ...,  379, 5015,   43],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2763,  366, 2058,  ...,  379, 5015,   43],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6380, -3.8638, -3.8377,  ..., -5.7130,  5.8709, 13.2384],\n",
      "        [-2.6380, -3.8638, -3.8377,  ..., -5.7130,  5.8709, 13.2384],\n",
      "        [-2.6380, -3.8638, -3.8377,  ..., -5.7130,  5.8709, 13.2384],\n",
      "        ...,\n",
      "        [-3.8853, -3.6613, -5.7411,  ...,  9.7111, -3.1984, -3.3155],\n",
      "        [-4.9009, -3.4205, -4.3520,  ...,  9.4488, -3.0857, -2.5069],\n",
      "        [-4.1910, -4.1374, -5.2817,  ..., 11.9504, -2.6090, -2.8510]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7541, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  25, 4541,  366,  ..., 5147, 3087, 1209],\n",
      "        [2412, 2732, 3922,  ..., 4329, 5240,  961],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2412, 2732, 3922,  ..., 4329, 5240,  961],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6373, -3.8629, -3.8383,  ..., -5.7160,  5.8688, 13.2413],\n",
      "        [-2.6373, -3.8629, -3.8383,  ..., -5.7160,  5.8688, 13.2413],\n",
      "        [-2.6373, -3.8629, -3.8383,  ..., -5.7160,  5.8688, 13.2413],\n",
      "        ...,\n",
      "        [-4.4487, -3.8330, -4.9374,  ..., 11.6821, -3.3552, -3.1392],\n",
      "        [-4.1785, -4.0535, -5.2756,  ..., 10.8999, -3.0647, -2.8447],\n",
      "        [-4.4446, -3.9502, -5.3119,  ...,  9.9158, -3.2376, -3.1549]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9417, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4505, 1988, 2405,  ..., 2979, 1372, 4346],\n",
      "        [4604, 1045, 4329,  ..., 4234, 4679, 3428],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4604, 1045, 4329,  ..., 4234, 4679, 3428],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6370, -3.8623, -3.8388,  ..., -5.7188,  5.8682, 13.2428],\n",
      "        [-2.6370, -3.8623, -3.8388,  ..., -5.7188,  5.8682, 13.2428],\n",
      "        [-2.6370, -3.8623, -3.8388,  ..., -5.7188,  5.8682, 13.2428],\n",
      "        ...,\n",
      "        [-4.2351, -3.9634, -5.5036,  ..., 10.6822, -3.2562, -3.2083],\n",
      "        [-4.4621, -4.5404, -5.4646,  ..., 11.1611, -3.0516, -2.8809],\n",
      "        [-3.9867, -4.1503, -5.2254,  ...,  8.7753, -3.2935, -3.3797]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9752, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4987, 2159, 2960,  ..., 1618, 2930, 4526],\n",
      "        [ 832, 1366,  765,  ..., 3669,  366, 3594],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 832, 1366,  765,  ..., 3669,  366, 3594],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6369, -3.8616, -3.8394,  ..., -5.7191,  5.8691, 13.2422],\n",
      "        [-2.6369, -3.8616, -3.8394,  ..., -5.7191,  5.8691, 13.2422],\n",
      "        [-2.6369, -3.8616, -3.8394,  ..., -5.7191,  5.8691, 13.2422],\n",
      "        ...,\n",
      "        [-4.3792, -4.3241, -4.9706,  ..., 10.8390, -2.8829, -3.1650],\n",
      "        [-4.2151, -4.0130, -4.4256,  ...,  8.0499, -2.4924, -2.5061],\n",
      "        [-4.7691, -3.4837, -4.5734,  ..., 11.0926, -3.2159, -2.8871]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9025, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4096, 5295, 5275,  ..., 5295, 3814, 2822],\n",
      "        [3331, 5295,  283,  ..., 5295, 1020, 2822],\n",
      "        [ 436, 5294,  436,  ..., 5294,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3331, 5295,  283,  ..., 5295, 1020, 2822],\n",
      "        [ 436, 5294,  436,  ..., 5294,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6362, -3.8612, -3.8398,  ..., -5.7181,  5.8713, 13.2397],\n",
      "        [-2.6362, -3.8612, -3.8398,  ..., -5.7181,  5.8713, 13.2397],\n",
      "        [-2.6362, -3.8612, -3.8398,  ..., -5.7181,  5.8713, 13.2397],\n",
      "        ...,\n",
      "        [-3.4487, -4.0679, -6.0214,  ...,  7.8630, -0.3181, -0.2323],\n",
      "        [-4.1269, -4.3453, -5.2216,  ..., 10.1045, -2.8778, -2.9863],\n",
      "        [-4.5028, -4.5634, -5.2076,  ..., 10.5175, -2.8701, -3.1376]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8116, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2378, 5183,  620,  ..., 4110,  593, 2979],\n",
      "        [1348, 5183, 4933,  ..., 5275, 4838, 2792],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1348, 5183, 4933,  ..., 5275, 4838, 2792],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6357, -3.8610, -3.8402,  ..., -5.7162,  5.8711, 13.2395],\n",
      "        [-2.6357, -3.8610, -3.8402,  ..., -5.7162,  5.8711, 13.2395],\n",
      "        [-2.6357, -3.8610, -3.8402,  ..., -5.7162,  5.8711, 13.2395],\n",
      "        ...,\n",
      "        [-4.7152, -4.5371, -5.0614,  ..., 10.4622, -2.1116, -2.5100],\n",
      "        [-4.6634, -3.6447, -4.5919,  ..., 10.7038, -1.7720, -1.8662],\n",
      "        [-4.2574, -4.2604, -5.6846,  ..., 11.0767, -3.1187, -3.2457]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8819, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3438, 4297, 1192,  ..., 3500,  649, 4944],\n",
      "        [ 369, 5123, 3365,  ..., 1398, 4813,  952],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 369, 5123, 3365,  ..., 1398, 4813,  952],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6355, -3.8607, -3.8406,  ..., -5.7164,  5.8710, 13.2401],\n",
      "        [-2.6355, -3.8607, -3.8406,  ..., -5.7164,  5.8710, 13.2401],\n",
      "        [-2.6355, -3.8607, -3.8406,  ..., -5.7164,  5.8710, 13.2401],\n",
      "        ...,\n",
      "        [-4.8343, -3.8633, -4.7181,  ..., 10.7862, -1.9558, -2.1109],\n",
      "        [-4.3794, -4.2898, -5.9696,  ..., 12.4453, -2.7275, -2.9251],\n",
      "        [-3.7755, -3.8888, -5.8173,  ...,  9.9692, -3.3532, -3.5725]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7360, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2807, 2763, 2195,  ..., 5295,   25, 2244],\n",
      "        [4357, 2552,  965,  ..., 5295, 4813, 2516],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4357, 2552,  965,  ..., 5295, 4813, 2516],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6355, -3.8607, -3.8411,  ..., -5.7172,  5.8678, 13.2443],\n",
      "        [-2.6355, -3.8607, -3.8411,  ..., -5.7172,  5.8678, 13.2443],\n",
      "        [-2.6355, -3.8607, -3.8411,  ..., -5.7172,  5.8678, 13.2443],\n",
      "        ...,\n",
      "        [-3.4576, -4.0756, -6.0273,  ...,  7.8613, -0.3170, -0.2293],\n",
      "        [-4.7747, -3.9471, -5.0928,  ..., 10.8768, -2.3971, -2.7610],\n",
      "        [-4.8779, -4.1459, -4.2457,  ..., 10.6128, -2.0933, -2.1488]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8399, grad_fn=<NllLossBackward>)\n",
      "['春晚                                                                                                                                                                                                      ', '江北北，一番风月，一枝春色。', '花悴。', '月下，一番春风雨。', '夜蓉雨                                                                                                                                                                                                     ', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番花开舞。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2602, 1309, 4357,  ..., 2378, 3277,  379],\n",
      "        [ 922, 2164, 1796,  ..., 1194,  933, 4895],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 922, 2164, 1796,  ..., 1194,  933, 4895],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6358, -3.8609, -3.8417,  ..., -5.7181,  5.8641, 13.2487],\n",
      "        [-2.6358, -3.8609, -3.8417,  ..., -5.7181,  5.8641, 13.2487],\n",
      "        [-2.6358, -3.8609, -3.8417,  ..., -5.7181,  5.8641, 13.2487],\n",
      "        ...,\n",
      "        [-4.7639, -4.7057, -5.2957,  ...,  9.9156, -2.4440, -2.3720],\n",
      "        [-4.3429, -3.2618, -4.0218,  ...,  8.3121, -2.2965, -2.4024],\n",
      "        [-4.0442, -4.4041, -5.9117,  ..., 10.8024, -3.1816, -3.2241]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8118, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3258,  785, 4305,  ..., 3934, 1054, 2844],\n",
      "        [1323,  320, 3909,  ..., 2319, 2093, 3228],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1323,  320, 3909,  ..., 2319, 2093, 3228],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6351, -3.8615, -3.8424,  ..., -5.7176,  5.8597, 13.2531],\n",
      "        [-2.6351, -3.8615, -3.8424,  ..., -5.7176,  5.8597, 13.2531],\n",
      "        [-2.6351, -3.8615, -3.8424,  ..., -5.7176,  5.8597, 13.2531],\n",
      "        ...,\n",
      "        [-4.4493, -3.5010, -4.3320,  ...,  9.0790, -2.7417, -2.6990],\n",
      "        [-3.7393, -3.9389, -5.1558,  ..., 10.2155, -2.3565, -2.5367],\n",
      "        [-4.4560, -3.6185, -4.4141,  ..., 10.1377, -2.6476, -2.5417]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9301, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1579, 1452, 1272,  ...,    4, 2732,  366],\n",
      "        [2629,  745,   76,  ..., 5102,   58, 3355],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2629,  745,   76,  ..., 5102,   58, 3355],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6336, -3.8623, -3.8430,  ..., -5.7164,  5.8569, 13.2557],\n",
      "        [-2.6336, -3.8623, -3.8430,  ..., -5.7164,  5.8569, 13.2557],\n",
      "        [-2.6336, -3.8623, -3.8430,  ..., -5.7164,  5.8569, 13.2557],\n",
      "        ...,\n",
      "        [-4.1542, -4.0521, -5.5567,  ..., 10.1548, -2.9705, -3.0028],\n",
      "        [-4.0590, -3.8594, -5.1647,  ...,  8.6606, -3.2401, -3.5682],\n",
      "        [-4.7397, -4.2094, -5.8920,  ..., 11.6180, -2.6318, -2.7644]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8616, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2795, 4188,  965,  ..., 1358, 4032, 1081],\n",
      "        [ 563,  380, 5081,  ...,  283, 4176, 4987],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 563,  380, 5081,  ...,  283, 4176, 4987],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6324, -3.8628, -3.8437,  ..., -5.7159,  5.8554, 13.2573],\n",
      "        [-2.6324, -3.8628, -3.8437,  ..., -5.7159,  5.8554, 13.2573],\n",
      "        [-2.6324, -3.8628, -3.8437,  ..., -5.7159,  5.8554, 13.2573],\n",
      "        ...,\n",
      "        [-4.5340, -4.3470, -5.8997,  ..., 10.2182, -3.1822, -3.2764],\n",
      "        [-4.7486, -3.8123, -5.3114,  ..., 12.1528, -3.0771, -3.0387],\n",
      "        [-4.7066, -3.7028, -4.7551,  ..., 10.5401, -2.9944, -3.2010]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9366, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1635, 3428, 3828,  ..., 2703, 5295, 3087],\n",
      "        [4627, 2887, 4470,  ..., 4556, 5295, 2961],\n",
      "        [ 436,  436,  436,  ...,  436, 5294,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4627, 2887, 4470,  ..., 4556, 5295, 2961],\n",
      "        [ 436,  436,  436,  ...,  436, 5294,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6315, -3.8633, -3.8445,  ..., -5.7164,  5.8556, 13.2574],\n",
      "        [-2.6315, -3.8633, -3.8445,  ..., -5.7164,  5.8556, 13.2574],\n",
      "        [-2.6315, -3.8633, -3.8445,  ..., -5.7164,  5.8556, 13.2574],\n",
      "        ...,\n",
      "        [-4.7554, -3.9788, -5.1650,  ..., 10.4189, -3.2594, -3.2365],\n",
      "        [-3.4587, -4.0889, -6.0308,  ...,  7.8577, -0.3229, -0.2203],\n",
      "        [-4.4111, -4.2668, -5.8881,  ..., 12.3165, -2.9403, -3.1616]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8991, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4265, 2529, 4052,  ..., 1271, 4328, 4792],\n",
      "        [4526,  456, 4430,  ..., 1101,  145, 1340],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4526,  456, 4430,  ..., 1101,  145, 1340],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6309, -3.8640, -3.8454,  ..., -5.7183,  5.8558, 13.2581],\n",
      "        [-2.6309, -3.8640, -3.8454,  ..., -5.7183,  5.8558, 13.2581],\n",
      "        [-2.6309, -3.8640, -3.8454,  ..., -5.7183,  5.8558, 13.2581],\n",
      "        ...,\n",
      "        [-4.0815, -3.7647, -5.4459,  ...,  8.8279, -3.3077, -3.3915],\n",
      "        [-4.3500, -4.0740, -5.6832,  ..., 11.4388, -2.8681, -3.1873],\n",
      "        [-4.4395, -3.4973, -4.0781,  ...,  9.5239, -2.8666, -2.8936]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8333, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1399, 2250, 4877,  ...,  321, 2319, 1989],\n",
      "        [4265, 1579, 3898,  ..., 4166, 2366, 1502],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4265, 1579, 3898,  ..., 4166, 2366, 1502],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6288, -3.8649, -3.8462,  ..., -5.7184,  5.8581, 13.2562],\n",
      "        [-2.6288, -3.8649, -3.8462,  ..., -5.7184,  5.8581, 13.2562],\n",
      "        [-2.6288, -3.8649, -3.8462,  ..., -5.7184,  5.8581, 13.2562],\n",
      "        ...,\n",
      "        [-4.4605, -3.9617, -5.8295,  ..., 11.7863, -3.0487, -3.2968],\n",
      "        [-4.5998, -3.5545, -4.7484,  ..., 11.0044, -2.8145, -3.0176],\n",
      "        [-4.6864, -3.7261, -4.7702,  ..., 10.6112, -3.3341, -3.0506]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8416, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2378, 3620, 2629,  ..., 4265, 2236, 4017],\n",
      "        [3505, 2082, 3250,  ...,  965, 1661, 3846],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3505, 2082, 3250,  ...,  965, 1661, 3846],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6273, -3.8660, -3.8469,  ..., -5.7172,  5.8610, 13.2532],\n",
      "        [-2.6273, -3.8660, -3.8469,  ..., -5.7172,  5.8610, 13.2532],\n",
      "        [-2.6273, -3.8660, -3.8469,  ..., -5.7172,  5.8610, 13.2532],\n",
      "        ...,\n",
      "        [-4.0719, -3.3482, -4.3023,  ...,  8.1684, -3.0560, -3.4037],\n",
      "        [-4.0070, -4.1204, -3.6401,  ...,  8.1470, -1.6950, -1.5944],\n",
      "        [-4.5751, -3.9938, -5.4071,  ..., 10.6271, -3.1983, -3.1219]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8486, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2732,  877,  831,  ..., 5295, 2915, 3061],\n",
      "        [1937,  403, 3165,  ..., 5295, 5147, 2997],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1937,  403, 3165,  ..., 5295, 5147, 2997],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6260, -3.8672, -3.8478,  ..., -5.7158,  5.8644, 13.2488],\n",
      "        [-2.6260, -3.8672, -3.8478,  ..., -5.7158,  5.8644, 13.2488],\n",
      "        [-2.6260, -3.8672, -3.8478,  ..., -5.7158,  5.8644, 13.2488],\n",
      "        ...,\n",
      "        [-3.4535, -4.1029, -6.0408,  ...,  7.8744, -0.3157, -0.2208],\n",
      "        [-4.1665, -4.5521, -5.7057,  ..., 12.3506, -2.6570, -2.7780],\n",
      "        [-4.0209, -3.7156, -4.3212,  ...,  8.2769, -3.6957, -3.6352]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8174, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [   4, 2122, 2033,  ..., 3380, 1398,   15],\n",
      "        [4465, 1579, 4052,  ..., 3380, 1271, 1796],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4465, 1579, 4052,  ..., 3380, 1271, 1796],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6251, -3.8658, -3.8486,  ..., -5.7155,  5.8655, 13.2470],\n",
      "        [-2.6251, -3.8658, -3.8486,  ..., -5.7155,  5.8655, 13.2470],\n",
      "        [-2.6251, -3.8658, -3.8486,  ..., -5.7155,  5.8655, 13.2470],\n",
      "        ...,\n",
      "        [-3.7165, -3.7820, -2.9996,  ...,  8.1488, -0.9527, -1.0680],\n",
      "        [-4.8688, -3.9625, -4.5734,  ..., 10.4513, -2.7706, -2.5548],\n",
      "        [-4.2650, -4.1548, -5.8073,  ..., 11.6540, -3.1658, -3.3804]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7303, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2198, 2732,  563,  ..., 5295, 3500,   35],\n",
      "        [3598, 4716, 3138,  ..., 5295, 1539, 1913],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3598, 4716, 3138,  ..., 5295, 1539, 1913],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6244, -3.8647, -3.8494,  ..., -5.7163,  5.8635, 13.2495],\n",
      "        [-2.6244, -3.8647, -3.8494,  ..., -5.7163,  5.8635, 13.2495],\n",
      "        [-2.6244, -3.8647, -3.8494,  ..., -5.7163,  5.8635, 13.2495],\n",
      "        ...,\n",
      "        [-3.4499, -4.1003, -6.0430,  ...,  7.8878, -0.3181, -0.2219],\n",
      "        [-4.8678, -4.5407, -5.6298,  ..., 11.3825, -2.7161, -2.8503],\n",
      "        [-4.2009, -4.2581, -5.7011,  ..., 11.7278, -3.0325, -2.9959]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9047, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3573, 5102, 5290,  ..., 4087, 4987, 3011],\n",
      "        [1062, 4052,  411,  ..., 4813, 1158,  945],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1062, 4052,  411,  ..., 4813, 1158,  945],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6241, -3.8630, -3.8501,  ..., -5.7180,  5.8612, 13.2524],\n",
      "        [-2.6241, -3.8630, -3.8501,  ..., -5.7180,  5.8612, 13.2524],\n",
      "        [-2.6241, -3.8630, -3.8501,  ..., -5.7180,  5.8612, 13.2524],\n",
      "        ...,\n",
      "        [-4.5907, -4.0720, -5.5793,  ..., 12.2649, -3.3993, -3.5176],\n",
      "        [-4.0511, -3.9951, -6.0399,  ...,  7.4462, -2.8923, -3.4346],\n",
      "        [-4.4157, -4.1314, -4.8894,  ..., 10.2045, -3.4736, -3.2995]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8854, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3560, 1192, 3933,  ..., 2809, 4932, 2562],\n",
      "        [3094, 2181, 3417,  ..., 4679, 3292, 3933],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3094, 2181, 3417,  ..., 4679, 3292, 3933],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6240, -3.8609, -3.8508,  ..., -5.7185,  5.8592, 13.2543],\n",
      "        [-2.6240, -3.8609, -3.8508,  ..., -5.7185,  5.8592, 13.2543],\n",
      "        [-2.6240, -3.8609, -3.8508,  ..., -5.7185,  5.8592, 13.2543],\n",
      "        ...,\n",
      "        [-4.7217, -4.2966, -5.7907,  ..., 11.9509, -2.9203, -2.6455],\n",
      "        [-3.0769, -3.5944, -5.1524,  ...,  6.4109, -2.5967, -3.0593],\n",
      "        [-4.4831, -4.1629, -4.9260,  ..., 10.8164, -2.4245, -2.7490]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8877, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3438, 2947, 2913,  ..., 2460, 4775, 1340],\n",
      "        [ 369, 3022,  489,  ...,   43, 1940,  859],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 369, 3022,  489,  ...,   43, 1940,  859],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6243, -3.8583, -3.8496,  ..., -5.7187,  5.8567, 13.2562],\n",
      "        [-2.6243, -3.8583, -3.8496,  ..., -5.7187,  5.8567, 13.2562],\n",
      "        [-2.6243, -3.8583, -3.8496,  ..., -5.7187,  5.8567, 13.2562],\n",
      "        ...,\n",
      "        [-3.7110, -3.7414, -3.8515,  ...,  8.4214, -2.0495, -2.0979],\n",
      "        [-4.3776, -3.5387, -5.0021,  ...,  9.9992, -3.3643, -3.3797],\n",
      "        [-3.6354, -3.4902, -3.5404,  ...,  8.1214, -2.1870, -2.4783]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9211, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3382, 4052,   56,  ..., 1144,  574, 5128],\n",
      "        [2979, 2809, 1715,  ..., 4465, 1935, 1158],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2979, 2809, 1715,  ..., 4465, 1935, 1158],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6247, -3.8562, -3.8486,  ..., -5.7190,  5.8554, 13.2566],\n",
      "        [-2.6247, -3.8562, -3.8486,  ..., -5.7190,  5.8554, 13.2566],\n",
      "        [-2.6247, -3.8562, -3.8486,  ..., -5.7190,  5.8554, 13.2566],\n",
      "        ...,\n",
      "        [-4.4111, -4.1141, -5.4683,  ..., 11.3586, -3.4266, -3.4347],\n",
      "        [-4.1242, -3.6928, -5.4727,  ...,  9.2725, -3.1807, -3.4303],\n",
      "        [-4.3249, -4.2109, -5.0174,  ..., 11.5257, -3.1091, -3.1620]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7610, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 996, 1452,  764,  ..., 3642, 4017,  712],\n",
      "        [4093,  644, 1579,  ..., 2624, 4175, 4899],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4093,  644, 1579,  ..., 2624, 4175, 4899],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6253, -3.8536, -3.8477,  ..., -5.7197,  5.8527, 13.2588],\n",
      "        [-2.6253, -3.8536, -3.8477,  ..., -5.7197,  5.8527, 13.2588],\n",
      "        [-2.6253, -3.8536, -3.8477,  ..., -5.7197,  5.8527, 13.2588],\n",
      "        ...,\n",
      "        [-4.6242, -4.2124, -5.1180,  ..., 11.5334, -3.5784, -3.4646],\n",
      "        [-4.0794, -4.4505, -5.4292,  ..., 11.0214, -2.9939, -3.2742],\n",
      "        [-4.4405, -3.9868, -5.2955,  ..., 10.7731, -2.7889, -2.7297]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9228, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1452,  942, 4838,  ..., 2915,  277,   43],\n",
      "        [3634, 2214, 2590,  ..., 1114, 3505, 1210],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3634, 2214, 2590,  ..., 1114, 3505, 1210],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6262, -3.8515, -3.8470,  ..., -5.7207,  5.8505, 13.2606],\n",
      "        [-2.6262, -3.8515, -3.8470,  ..., -5.7207,  5.8505, 13.2606],\n",
      "        [-2.6262, -3.8515, -3.8470,  ..., -5.7207,  5.8505, 13.2606],\n",
      "        ...,\n",
      "        [-4.1503, -3.9816, -5.4545,  ...,  8.2822, -3.5484, -3.6596],\n",
      "        [-4.5670, -3.8681, -5.6586,  ..., 11.1915, -3.1408, -3.2587],\n",
      "        [-4.4281, -3.7362, -4.5523,  ...,  9.9476, -3.5172, -3.2603]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9960, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3061, 1913, 2793,  ...,  734, 3978, 1407],\n",
      "        [2915,  738, 4776,  ..., 2732, 2085, 2482],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2915,  738, 4776,  ..., 2732, 2085, 2482],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6272, -3.8487, -3.8465,  ..., -5.7214,  5.8492, 13.2615],\n",
      "        [-2.6272, -3.8487, -3.8465,  ..., -5.7214,  5.8492, 13.2615],\n",
      "        [-2.6272, -3.8487, -3.8465,  ..., -5.7214,  5.8492, 13.2615],\n",
      "        ...,\n",
      "        [-4.7298, -4.0282, -5.0712,  ..., 11.3904, -3.6836, -3.6968],\n",
      "        [-4.4323, -3.9789, -4.4279,  ..., 11.7685, -3.4332, -2.7002],\n",
      "        [-4.3260, -3.3242, -3.3330,  ...,  8.4781, -2.2388, -2.3648]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9485, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3428, 3500, 1372,  ..., 2915,  192, 2763],\n",
      "        [1197, 1539,  379,  ..., 2884, 4933, 4679],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1197, 1539,  379,  ..., 2884, 4933, 4679],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6284, -3.8459, -3.8445,  ..., -5.7216,  5.8500, 13.2598],\n",
      "        [-2.6284, -3.8459, -3.8445,  ..., -5.7216,  5.8500, 13.2598],\n",
      "        [-2.6284, -3.8459, -3.8445,  ..., -5.7216,  5.8500, 13.2598],\n",
      "        ...,\n",
      "        [-4.3166, -3.7494, -5.2164,  ..., 10.3017, -3.5026, -3.5039],\n",
      "        [-4.5565, -3.4493, -4.7663,  ..., 10.0240, -2.6287, -2.6206],\n",
      "        [-4.4083, -3.9187, -5.1605,  ..., 11.2307, -3.1037, -2.9146]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8367, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2616, 3382, 2773,  ...,   71, 4181, 1308],\n",
      "        [3503, 1452, 1245,  ..., 2017, 1724,  835],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3503, 1452, 1245,  ..., 2017, 1724,  835],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6298, -3.8432, -3.8407,  ..., -5.7232,  5.8502, 13.2594],\n",
      "        [-2.6298, -3.8432, -3.8407,  ..., -5.7232,  5.8502, 13.2594],\n",
      "        [-2.6298, -3.8432, -3.8407,  ..., -5.7232,  5.8502, 13.2594],\n",
      "        ...,\n",
      "        [-4.3231, -4.0596, -5.7734,  ..., 11.8130, -3.1661, -3.2131],\n",
      "        [-4.8001, -3.9306, -5.4792,  ..., 11.8768, -2.8560, -2.6289],\n",
      "        [-4.7788, -4.1335, -4.6549,  ..., 10.4261, -3.5229, -3.2663]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0008, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 712,  593, 2947,  ..., 3978, 2732, 4526],\n",
      "        [4899, 2809, 1728,  ..., 3074, 4263,  201],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4899, 2809, 1728,  ..., 3074, 4263,  201],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6314, -3.8410, -3.8377,  ..., -5.7258,  5.8513, 13.2585],\n",
      "        [-2.6314, -3.8410, -3.8377,  ..., -5.7258,  5.8513, 13.2585],\n",
      "        [-2.6314, -3.8410, -3.8377,  ..., -5.7258,  5.8513, 13.2585],\n",
      "        ...,\n",
      "        [-4.6803, -3.8713, -5.2744,  ..., 11.4783, -3.4098, -3.2416],\n",
      "        [-4.7619, -4.7927, -5.6017,  ..., 12.6095, -2.6117, -2.4269],\n",
      "        [-4.4676, -4.2446, -5.0219,  ..., 10.7930, -2.5941, -2.3865]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8766, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5275, 3046,  380,  ..., 4470, 2089, 3331],\n",
      "        [1639, 3575, 1245,  ..., 4224, 3061, 2227],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1639, 3575, 1245,  ..., 4224, 3061, 2227],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6330, -3.8389, -3.8350,  ..., -5.7285,  5.8520, 13.2582],\n",
      "        [-2.6330, -3.8389, -3.8350,  ..., -5.7285,  5.8520, 13.2582],\n",
      "        [-2.6330, -3.8389, -3.8350,  ..., -5.7285,  5.8520, 13.2582],\n",
      "        ...,\n",
      "        [-4.2759, -3.9846, -5.7732,  ..., 11.1957, -3.2336, -3.3757],\n",
      "        [-4.6840, -3.6684, -4.3360,  ..., 10.4955, -3.2375, -3.1099],\n",
      "        [-4.2650, -4.3641, -5.5935,  ..., 10.8649, -2.9047, -3.2278]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7950, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1457, 4560,  466,  ..., 2652,  740, 1661],\n",
      "        [3286, 1989, 3290,  ..., 4470, 2829,  740],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3286, 1989, 3290,  ..., 4470, 2829,  740],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6348, -3.8367, -3.8325,  ..., -5.7297,  5.8530, 13.2574],\n",
      "        [-2.6348, -3.8367, -3.8325,  ..., -5.7297,  5.8530, 13.2574],\n",
      "        [-2.6348, -3.8367, -3.8325,  ..., -5.7297,  5.8530, 13.2574],\n",
      "        ...,\n",
      "        [-4.2821, -4.5401, -5.6110,  ..., 11.7857, -3.2176, -3.2027],\n",
      "        [-4.2389, -4.0872, -5.7688,  ..., 10.8816, -2.9668, -3.0757],\n",
      "        [-3.9660, -4.2436, -5.4171,  ..., 10.6313, -2.9431, -2.7124]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9273, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4585, 1309,  712,  ..., 3656,  842, 1166],\n",
      "        [ 277, 3878, 3530,  ..., 4305, 3413, 3920],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 277, 3878, 3530,  ..., 4305, 3413, 3920],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6367, -3.8329, -3.8304,  ..., -5.7299,  5.8536, 13.2564],\n",
      "        [-2.6367, -3.8329, -3.8304,  ..., -5.7299,  5.8536, 13.2564],\n",
      "        [-2.6367, -3.8329, -3.8304,  ..., -5.7299,  5.8536, 13.2564],\n",
      "        ...,\n",
      "        [-4.5289, -3.9074, -5.6564,  ..., 10.9134, -2.6331, -2.7205],\n",
      "        [-4.2124, -3.4479, -3.4590,  ...,  9.4667, -2.5169, -2.5099],\n",
      "        [-4.5133, -4.6588, -5.1611,  ..., 11.7916, -1.8676, -1.7102]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8813, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 734, 1888, 3506,  ...,  974, 4087, 2490],\n",
      "        [3806, 1502,  315,  ..., 4838, 4022, 2586],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3806, 1502,  315,  ..., 4838, 4022, 2586],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6386, -3.8298, -3.8287,  ..., -5.7310,  5.8530, 13.2572],\n",
      "        [-2.6386, -3.8298, -3.8287,  ..., -5.7310,  5.8530, 13.2572],\n",
      "        [-2.6386, -3.8298, -3.8287,  ..., -5.7310,  5.8530, 13.2572],\n",
      "        ...,\n",
      "        [-4.4197, -3.5336, -4.9153,  ..., 10.7909, -2.9942, -3.0823],\n",
      "        [-4.4329, -3.8995, -5.1277,  ..., 11.0250, -3.2401, -3.1997],\n",
      "        [-4.0980, -3.9177, -5.4599,  ..., 11.0073, -3.3051, -3.2786]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(2.0117, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 672, 4548, 5116,  ..., 1192, 1452,   20],\n",
      "        [2915, 5072, 4234,  ..., 3279,  644, 4821],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2915, 5072, 4234,  ..., 3279,  644, 4821],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6406, -3.8268, -3.8272,  ..., -5.7342,  5.8548, 13.2562],\n",
      "        [-2.6406, -3.8268, -3.8272,  ..., -5.7342,  5.8548, 13.2562],\n",
      "        [-2.6406, -3.8268, -3.8272,  ..., -5.7342,  5.8548, 13.2562],\n",
      "        ...,\n",
      "        [-4.2022, -4.2909, -5.3888,  ..., 10.7984, -2.9643, -3.1565],\n",
      "        [-4.5928, -4.1416, -5.0923,  ..., 11.7093, -2.5824, -2.4095],\n",
      "        [-4.3748, -4.2510, -5.6152,  ..., 11.5319, -3.0846, -2.9542]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8275, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2829, 2159, 1054,  ...,  563, 4168, 5295],\n",
      "        [2936, 1194, 4857,  ...,  509, 4987, 5295],\n",
      "        [ 436,  436,  436,  ...,  436,  436, 5294]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2936, 1194, 4857,  ...,  509, 4987, 5295],\n",
      "        [ 436,  436,  436,  ...,  436,  436, 5294],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6426, -3.8243, -3.8259,  ..., -5.7375,  5.8556, 13.2566],\n",
      "        [-2.6426, -3.8243, -3.8259,  ..., -5.7375,  5.8556, 13.2566],\n",
      "        [-2.6426, -3.8243, -3.8259,  ..., -5.7375,  5.8556, 13.2566],\n",
      "        ...,\n",
      "        [-4.6795, -3.8327, -5.5115,  ..., 11.8693, -2.6832, -2.7244],\n",
      "        [-4.1164, -4.2014, -5.6178,  ...,  9.0940, -3.2362, -3.5134],\n",
      "        [-3.5002, -4.0761, -6.0334,  ...,  7.9945, -0.3140, -0.1909]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8503, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5295, 5295, 1010,  ..., 1081, 3366, 3661],\n",
      "        [5295, 5295, 3656,  ..., 1511, 3722, 4905],\n",
      "        [5294, 5294,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5295, 5295, 3656,  ..., 1511, 3722, 4905],\n",
      "        [5294, 5294,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6446, -3.8213, -3.8248,  ..., -5.7395,  5.8559, 13.2569],\n",
      "        [-2.6446, -3.8213, -3.8248,  ..., -5.7395,  5.8559, 13.2569],\n",
      "        [-2.6446, -3.8213, -3.8248,  ..., -5.7395,  5.8559, 13.2569],\n",
      "        ...,\n",
      "        [-4.6202, -3.4990, -4.5407,  ..., 10.2259, -1.8164, -1.8441],\n",
      "        [-4.5690, -4.3673, -5.4220,  ..., 10.5763, -2.6280, -2.6929],\n",
      "        [-4.2869, -4.3202, -5.7664,  ..., 12.1717, -2.8273, -2.9410]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7411, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1452, 2595, 3525,  ..., 5295, 1192, 3814],\n",
      "        [ 277, 5181, 2936,  ..., 5295, 4052, 1020],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 277, 5181, 2936,  ..., 5295, 4052, 1020],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6468, -3.8189, -3.8238,  ..., -5.7404,  5.8536, 13.2596],\n",
      "        [-2.6468, -3.8189, -3.8238,  ..., -5.7404,  5.8536, 13.2596],\n",
      "        [-2.6468, -3.8189, -3.8238,  ..., -5.7404,  5.8536, 13.2596],\n",
      "        ...,\n",
      "        [-3.5150, -4.0813, -6.0440,  ...,  8.0186, -0.3064, -0.1770],\n",
      "        [-4.5236, -4.5954, -6.0623,  ..., 10.4495, -2.6937, -2.6789],\n",
      "        [-4.2962, -4.2638, -5.5349,  ..., 11.1486, -3.1555, -3.4087]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9298, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3092, 4017, 4265,  ..., 1081,  806,  593],\n",
      "        [4679, 1132,  129,  ..., 1158, 1350, 1240],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4679, 1132,  129,  ..., 1158, 1350, 1240],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6491, -3.8155, -3.8226,  ..., -5.7424,  5.8518, 13.2619],\n",
      "        [-2.6491, -3.8155, -3.8226,  ..., -5.7424,  5.8518, 13.2619],\n",
      "        [-2.6491, -3.8155, -3.8226,  ..., -5.7424,  5.8518, 13.2619],\n",
      "        ...,\n",
      "        [-4.0645, -3.7073, -5.3618,  ...,  7.3630, -2.9485, -3.3691],\n",
      "        [-4.8778, -3.6144, -4.2182,  ..., 10.2917, -3.4282, -2.9947],\n",
      "        [-4.4602, -4.2246, -5.6729,  ..., 12.2155, -2.9220, -3.1905]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9510, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 745, 2164, 3331,  ..., 4723, 5240, 2624],\n",
      "        [2082, 1251, 4666,  ..., 3026, 1570,  985],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2082, 1251, 4666,  ..., 3026, 1570,  985],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6514, -3.8126, -3.8218,  ..., -5.7447,  5.8506, 13.2634],\n",
      "        [-2.6514, -3.8126, -3.8218,  ..., -5.7447,  5.8506, 13.2634],\n",
      "        [-2.6514, -3.8126, -3.8218,  ..., -5.7447,  5.8506, 13.2634],\n",
      "        ...,\n",
      "        [-4.7147, -3.4397, -4.5671,  ..., 11.8290, -2.9030, -2.7539],\n",
      "        [-4.3851, -4.5422, -5.4380,  ..., 12.1512, -2.2471, -2.2082],\n",
      "        [-4.1402, -4.0562, -4.8660,  ...,  8.5775, -2.7666, -2.8586]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8163, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 321, 5157, 3171,  ...,  210, 4716, 2143],\n",
      "        [1197,  408, 2244,  ...,  989, 1158, 2763],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1197,  408, 2244,  ...,  989, 1158, 2763],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6536, -3.8094, -3.8211,  ..., -5.7481,  5.8488, 13.2656],\n",
      "        [-2.6536, -3.8094, -3.8211,  ..., -5.7481,  5.8488, 13.2656],\n",
      "        [-2.6536, -3.8094, -3.8211,  ..., -5.7481,  5.8488, 13.2656],\n",
      "        ...,\n",
      "        [-4.6892, -3.3997, -4.4756,  ..., 10.9557, -3.0695, -2.7798],\n",
      "        [-4.4548, -3.8195, -5.5704,  ..., 10.9045, -3.0429, -3.1025],\n",
      "        [-4.4753, -4.0078, -3.9870,  ..., 10.5767, -1.5990, -1.8625]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9011, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 321, 3277, 4572,  ...,  965, 1086, 5295],\n",
      "        [2548, 2064, 2629,  ..., 3665, 1158, 5295],\n",
      "        [ 436,  436,  436,  ...,  436,  436, 5294]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2548, 2064, 2629,  ..., 3665, 1158, 5295],\n",
      "        [ 436,  436,  436,  ...,  436,  436, 5294],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6540, -3.8068, -3.8206,  ..., -5.7511,  5.8479, 13.2670],\n",
      "        [-2.6540, -3.8068, -3.8206,  ..., -5.7511,  5.8479, 13.2670],\n",
      "        [-2.6540, -3.8068, -3.8206,  ..., -5.7511,  5.8479, 13.2670],\n",
      "        ...,\n",
      "        [-4.3577, -4.0023, -5.3018,  ...,  8.5575, -2.1902, -2.2634],\n",
      "        [-4.1053, -4.3945, -5.6710,  ..., 11.9478, -2.6475, -2.8235],\n",
      "        [-3.5385, -4.0862, -6.0476,  ...,  8.0213, -0.3056, -0.1662]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8175, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4204, 4266,  403,  ...,  380, 1192, 4512],\n",
      "        [ 620, 3634, 2111,  ..., 4944,  432, 3403],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 620, 3634, 2111,  ..., 4944,  432, 3403],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6547, -3.8042, -3.8200,  ..., -5.7534,  5.8455, 13.2696],\n",
      "        [-2.6547, -3.8042, -3.8200,  ..., -5.7534,  5.8455, 13.2696],\n",
      "        [-2.6547, -3.8042, -3.8200,  ..., -5.7534,  5.8455, 13.2696],\n",
      "        ...,\n",
      "        [-4.2208, -4.0490, -5.7816,  ..., 11.3041, -3.5083, -3.3649],\n",
      "        [-4.4932, -3.9920, -5.7242,  ...,  9.8659, -2.4072, -2.5201],\n",
      "        [-4.6609, -3.4312, -4.5082,  ..., 10.2309, -3.4081, -3.0222]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9132, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3331, 3205, 2242,  ..., 3428, 3934, 1220],\n",
      "        [4944, 5031, 3403,  ..., 2960, 4559, 2197],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4944, 5031, 3403,  ..., 2960, 4559, 2197],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6556, -3.8022, -3.8198,  ..., -5.7551,  5.8432, 13.2718],\n",
      "        [-2.6556, -3.8022, -3.8198,  ..., -5.7551,  5.8432, 13.2718],\n",
      "        [-2.6556, -3.8022, -3.8198,  ..., -5.7551,  5.8432, 13.2718],\n",
      "        ...,\n",
      "        [-4.7528, -3.6077, -4.3370,  ..., 11.7441, -2.9145, -2.5940],\n",
      "        [-4.1028, -4.5724, -6.1632,  ..., 10.2750, -2.4624, -2.5121],\n",
      "        [-4.5732, -4.1807, -5.1353,  ..., 11.9031, -3.5235, -3.6820]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9488, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2733, 2378, 5088,  ...,  574, 3862, 3087],\n",
      "        [4650, 2951, 4305,  ..., 1192, 1115,  509],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4650, 2951, 4305,  ..., 1192, 1115,  509],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6566, -3.7998, -3.8199,  ..., -5.7574,  5.8426, 13.2724],\n",
      "        [-2.6566, -3.7998, -3.8199,  ..., -5.7574,  5.8426, 13.2724],\n",
      "        [-2.6566, -3.7998, -3.8199,  ..., -5.7574,  5.8426, 13.2724],\n",
      "        ...,\n",
      "        [-4.3001, -4.3352, -5.9684,  ..., 10.4753, -2.9114, -2.9172],\n",
      "        [-4.7554, -3.5487, -4.1308,  ...,  9.5010, -2.7645, -2.4661],\n",
      "        [-4.3026, -3.9999, -5.7658,  ..., 10.7948, -3.1956, -3.2658]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9448, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4465,  321, 2378,  ...,  192, 3030, 3277],\n",
      "        [4017, 2047, 2164,  ...,  974, 4716,  933],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4017, 2047, 2164,  ...,  974, 4716,  933],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6578, -3.7980, -3.8200,  ..., -5.7585,  5.8432, 13.2722],\n",
      "        [-2.6578, -3.7980, -3.8200,  ..., -5.7585,  5.8432, 13.2722],\n",
      "        [-2.6578, -3.7980, -3.8200,  ..., -5.7585,  5.8432, 13.2722],\n",
      "        ...,\n",
      "        [-4.4650, -3.5894, -4.2594,  ..., 11.4245, -3.5032, -2.7807],\n",
      "        [-4.1571, -3.6360, -5.0802,  ...,  9.1022, -3.1257, -3.3220],\n",
      "        [-4.4136, -3.2416, -4.0367,  ...,  8.5185, -2.4986, -2.5792]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.6998, grad_fn=<NllLossBackward>)\n",
      "['春暮                                                                                                                                                                                                      ', '江北北，一番风月，一枝千里。', '花悴。', '月下，一番春风雨。', '夜蓉雨                                                                                                                                                                                                     ', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番番月下，一片春风。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3237,  891,  192,  ..., 2309, 4113, 2844],\n",
      "        [3091, 1369,  974,  ..., 1194, 2306, 3795],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3091, 1369,  974,  ..., 1194, 2306, 3795],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6591, -3.7966, -3.8200,  ..., -5.7593,  5.8418, 13.2742],\n",
      "        [-2.6591, -3.7966, -3.8200,  ..., -5.7593,  5.8418, 13.2742],\n",
      "        [-2.6591, -3.7966, -3.8200,  ..., -5.7593,  5.8418, 13.2742],\n",
      "        ...,\n",
      "        [-4.5757, -4.5813, -5.8902,  ...,  8.9055, -2.5125, -2.5148],\n",
      "        [-3.9495, -3.7863, -5.2933,  ...,  9.9077, -3.2496, -3.3522],\n",
      "        [-4.8993, -4.0297, -5.0560,  ..., 10.9142, -2.2548, -2.3850]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8985, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  94, 1192, 3382,  ..., 2089, 5295, 4265],\n",
      "        [2389, 3119, 1144,  ...,  700, 5295, 4465],\n",
      "        [ 436,  436,  436,  ...,  436, 5294,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2389, 3119, 1144,  ...,  700, 5295, 4465],\n",
      "        [ 436,  436,  436,  ...,  436, 5294,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6606, -3.7955, -3.8201,  ..., -5.7605,  5.8415, 13.2755],\n",
      "        [-2.6606, -3.7955, -3.8201,  ..., -5.7605,  5.8415, 13.2755],\n",
      "        [-2.6606, -3.7955, -3.8201,  ..., -5.7605,  5.8415, 13.2755],\n",
      "        ...,\n",
      "        [-4.7734, -3.8431, -4.5733,  ..., 11.2670, -2.8545, -2.3818],\n",
      "        [-3.5604, -4.0948, -6.0693,  ...,  8.0814, -0.3034, -0.1481],\n",
      "        [-4.3563, -3.9576, -4.8338,  ..., 11.1296, -3.5583, -3.4549]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7998, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3428, 5051, 2809,  ..., 2237, 3875,  965],\n",
      "        [2383, 3951,  965,  ..., 4585, 4722,  969],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2383, 3951,  965,  ..., 4585, 4722,  969],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6623, -3.7948, -3.8203,  ..., -5.7624,  5.8409, 13.2775],\n",
      "        [-2.6623, -3.7948, -3.8203,  ..., -5.7624,  5.8409, 13.2775],\n",
      "        [-2.6623, -3.7948, -3.8203,  ..., -5.7624,  5.8409, 13.2775],\n",
      "        ...,\n",
      "        [-4.2764, -3.6372, -5.0349,  ...,  9.1620, -3.3886, -3.6803],\n",
      "        [-4.3055, -3.4558, -4.4370,  ...,  9.3333, -3.0684, -2.9820],\n",
      "        [-4.3133, -3.9647, -5.5021,  ..., 10.9682, -3.0684, -2.9905]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8224, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4305,  593, 4266,  ..., 4470, 3390, 3331],\n",
      "        [4193, 1240,  321,  ..., 4679, 3032,  151],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4193, 1240,  321,  ..., 4679, 3032,  151],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6640, -3.7937, -3.8206,  ..., -5.7636,  5.8417, 13.2779],\n",
      "        [-2.6640, -3.7937, -3.8206,  ..., -5.7636,  5.8417, 13.2779],\n",
      "        [-2.6640, -3.7937, -3.8206,  ..., -5.7636,  5.8417, 13.2779],\n",
      "        ...,\n",
      "        [-4.2855, -3.9219, -5.3660,  ..., 10.7559, -3.4870, -3.5317],\n",
      "        [-4.3501, -4.4304, -5.8038,  ..., 12.0375, -3.1347, -3.0818],\n",
      "        [-4.6792, -4.3862, -5.6317,  ..., 11.7903, -3.0870, -3.1585]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9069, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2032, 2378,   43,  ..., 4985,  965, 2791],\n",
      "        [3591,   15, 3384,  ..., 3205, 4346, 3021],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3591,   15, 3384,  ..., 3205, 4346, 3021],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6658, -3.7931, -3.8211,  ..., -5.7653,  5.8428, 13.2780],\n",
      "        [-2.6658, -3.7931, -3.8211,  ..., -5.7653,  5.8428, 13.2780],\n",
      "        [-2.6658, -3.7931, -3.8211,  ..., -5.7653,  5.8428, 13.2780],\n",
      "        ...,\n",
      "        [-4.4472, -3.8085, -5.3703,  ..., 11.9444, -3.5159, -3.6539],\n",
      "        [-4.1418, -3.8982, -5.6095,  ..., 11.1440, -3.4247, -3.4597],\n",
      "        [-4.3072, -4.0157, -5.6866,  ..., 11.6448, -3.4748, -3.4696]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8612, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  66, 5033, 3092,  ..., 1120, 2937, 1492],\n",
      "        [4944, 3092, 4985,  ..., 5275, 2548, 3705],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4944, 3092, 4985,  ..., 5275, 2548, 3705],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6677, -3.7921, -3.8214,  ..., -5.7675,  5.8438, 13.2771],\n",
      "        [-2.6677, -3.7921, -3.8214,  ..., -5.7675,  5.8438, 13.2771],\n",
      "        [-2.6677, -3.7921, -3.8214,  ..., -5.7675,  5.8438, 13.2771],\n",
      "        ...,\n",
      "        [-3.9244, -3.9150, -5.6684,  ..., 10.6842, -3.2874, -3.4109],\n",
      "        [-4.2144, -3.9694, -5.5336,  ..., 11.4915, -3.1936, -3.0983],\n",
      "        [-4.4425, -3.8247, -5.4891,  ...,  9.9803, -3.0780, -2.9536]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8495, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3366, 4835, 2913,  ...,  754,  631, 1427],\n",
      "        [2602, 4069, 2378,  ..., 4052, 4467,  321],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2602, 4069, 2378,  ..., 4052, 4467,  321],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6697, -3.7916, -3.8202,  ..., -5.7686,  5.8455, 13.2750],\n",
      "        [-2.6697, -3.7916, -3.8202,  ..., -5.7686,  5.8455, 13.2750],\n",
      "        [-2.6697, -3.7916, -3.8202,  ..., -5.7686,  5.8455, 13.2750],\n",
      "        ...,\n",
      "        [-4.4389, -3.2249, -4.6123,  ...,  9.1846, -2.6222, -2.5974],\n",
      "        [-4.3339, -3.8814, -5.7180,  ..., 11.3626, -2.9487, -3.0695],\n",
      "        [-4.6128, -4.3431, -5.6412,  ..., 11.6797, -3.1855, -3.3099]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9657, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3457,  508,  283,  ..., 1254, 4426, 1616],\n",
      "        [2091, 1822, 2643,  ..., 1254, 4265, 3500],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2091, 1822, 2643,  ..., 1254, 4265, 3500],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6717, -3.7914, -3.8192,  ..., -5.7696,  5.8481, 13.2715],\n",
      "        [-2.6717, -3.7914, -3.8192,  ..., -5.7696,  5.8481, 13.2715],\n",
      "        [-2.6717, -3.7914, -3.8192,  ..., -5.7696,  5.8481, 13.2715],\n",
      "        ...,\n",
      "        [-3.7367, -3.7904, -4.4207,  ...,  5.0363, -2.0952, -2.5253],\n",
      "        [-4.2810, -3.8453, -6.3083,  ..., 10.1725, -2.5870, -2.8125],\n",
      "        [-4.3108, -3.9134, -5.5559,  ..., 10.9991, -3.3603, -3.4372]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8928, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4087, 5128, 4585,  ...,  712, 4823, 3814],\n",
      "        [1540, 1158, 2809,  ..., 3530, 5058, 5241],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1540, 1158, 2809,  ..., 3530, 5058, 5241],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6738, -3.7913, -3.8185,  ..., -5.7718,  5.8502, 13.2690],\n",
      "        [-2.6738, -3.7913, -3.8185,  ..., -5.7718,  5.8502, 13.2690],\n",
      "        [-2.6738, -3.7913, -3.8185,  ..., -5.7718,  5.8502, 13.2690],\n",
      "        ...,\n",
      "        [-4.4109, -3.9349, -5.0149,  ..., 10.9204, -3.3587, -3.2527],\n",
      "        [-4.2057, -4.2470, -5.2958,  ..., 10.2175, -3.0292, -3.2931],\n",
      "        [-4.0108, -4.0814, -5.1260,  ...,  9.7056, -2.9244, -3.1593]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8467, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5081,   75, 1579,  ..., 1988, 1232, 3878],\n",
      "        [3061, 3844, 2373,  ..., 1045,  964, 4944],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3061, 3844, 2373,  ..., 1045,  964, 4944],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6745, -3.7912, -3.8180,  ..., -5.7753,  5.8502, 13.2689],\n",
      "        [-2.6745, -3.7912, -3.8180,  ..., -5.7753,  5.8502, 13.2689],\n",
      "        [-2.6745, -3.7912, -3.8180,  ..., -5.7753,  5.8502, 13.2689],\n",
      "        ...,\n",
      "        [-4.2882, -3.9130, -4.8802,  ..., 10.9919, -3.4007, -3.0701],\n",
      "        [-4.4275, -3.9915, -5.5449,  ..., 11.3981, -3.3373, -3.2124],\n",
      "        [-4.3616, -4.3048, -5.6632,  ..., 10.1264, -3.0325, -2.8641]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9178, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1421, 1240,  825,  ...,  822, 4265,  631],\n",
      "        [3021, 3951, 3466,  ...,  918, 4944, 3505],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3021, 3951, 3466,  ...,  918, 4944, 3505],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6740, -3.7916, -3.8177,  ..., -5.7780,  5.8498, 13.2694],\n",
      "        [-2.6740, -3.7916, -3.8177,  ..., -5.7780,  5.8498, 13.2694],\n",
      "        [-2.6740, -3.7916, -3.8177,  ..., -5.7780,  5.8498, 13.2694],\n",
      "        ...,\n",
      "        [-2.5368, -3.8944, -5.4364,  ...,  4.8755, -2.4289, -2.8569],\n",
      "        [-3.9668, -4.1140, -5.9381,  ..., 10.3821, -3.0653, -3.2567],\n",
      "        [-3.8931, -3.9910, -5.4318,  ...,  9.5738, -3.0106, -2.9773]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7500, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2947, 4145, 1514,  ..., 3934,  996, 1734],\n",
      "        [1929, 2773, 5270,  ..., 2848, 3500, 2058],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1929, 2773, 5270,  ..., 2848, 3500, 2058],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6738, -3.7923, -3.8171,  ..., -5.7776,  5.8486, 13.2696],\n",
      "        [-2.6738, -3.7923, -3.8171,  ..., -5.7776,  5.8486, 13.2696],\n",
      "        [-2.6738, -3.7923, -3.8171,  ..., -5.7776,  5.8486, 13.2696],\n",
      "        ...,\n",
      "        [-4.1266, -4.5609, -5.8669,  ...,  8.8139, -3.4448, -3.4698],\n",
      "        [-4.7170, -4.6125, -6.1340,  ..., 11.8994, -2.8761, -2.8968],\n",
      "        [-4.3506, -3.9865, -5.2530,  ..., 10.9782, -3.0384, -2.7244]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7818, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2373, 2947, 2979,  ..., 5295,  828, 1442],\n",
      "        [1925, 4834, 1693,  ..., 5295, 4012, 1442],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1925, 4834, 1693,  ..., 5295, 4012, 1442],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6739, -3.7923, -3.8165,  ..., -5.7766,  5.8458, 13.2717],\n",
      "        [-2.6739, -3.7923, -3.8165,  ..., -5.7766,  5.8458, 13.2717],\n",
      "        [-2.6739, -3.7923, -3.8165,  ..., -5.7766,  5.8458, 13.2717],\n",
      "        ...,\n",
      "        [-3.5511, -4.0826, -6.0650,  ...,  8.0375, -0.3207, -0.1786],\n",
      "        [-3.7168, -4.1573, -5.0412,  ...,  9.0087, -3.5701, -3.8007],\n",
      "        [-4.3694, -3.9318, -5.5943,  ..., 12.7717, -2.9040, -2.8104]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9641, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4753, 3400,  165,  ..., 4890, 5295, 3046],\n",
      "        [4753, 2058, 2773,  ..., 1398, 5295, 3575],\n",
      "        [ 436,  436,  436,  ...,  436, 5294,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4753, 2058, 2773,  ..., 1398, 5295, 3575],\n",
      "        [ 436,  436,  436,  ...,  436, 5294,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6740, -3.7912, -3.8158,  ..., -5.7776,  5.8434, 13.2739],\n",
      "        [-2.6740, -3.7912, -3.8158,  ..., -5.7776,  5.8434, 13.2739],\n",
      "        [-2.6740, -3.7912, -3.8158,  ..., -5.7776,  5.8434, 13.2739],\n",
      "        ...,\n",
      "        [-5.0223, -4.1003, -5.0328,  ..., 11.2219, -2.9178, -2.8988],\n",
      "        [-3.5562, -4.0870, -6.0705,  ...,  8.0486, -0.3173, -0.1728],\n",
      "        [-4.3655, -3.9656, -5.9133,  ..., 11.8371, -3.1849, -3.1630]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9487, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5183, 5295,  785,  ..., 1331, 1705, 2961],\n",
      "        [4440, 5295,  548,  ..., 2809, 3186, 4186],\n",
      "        [ 436, 5294,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4440, 5295,  548,  ..., 2809, 3186, 4186],\n",
      "        [ 436, 5294,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6740, -3.7902, -3.8152,  ..., -5.7804,  5.8412, 13.2773],\n",
      "        [-2.6740, -3.7902, -3.8152,  ..., -5.7804,  5.8412, 13.2773],\n",
      "        [-2.6740, -3.7902, -3.8152,  ..., -5.7804,  5.8412, 13.2773],\n",
      "        ...,\n",
      "        [-4.5640, -4.6940, -6.1288,  ..., 12.2886, -2.7469, -2.9131],\n",
      "        [-4.2770, -3.5812, -5.4157,  ...,  9.9367, -3.7099, -3.7220],\n",
      "        [-4.3737, -4.1976, -4.9197,  ...,  9.6763, -3.4799, -3.8618]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8112, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4516, 2809, 1131,  ..., 5183, 4077, 2159],\n",
      "        [ 851, 4679,  314,  ..., 4244,  639, 1654],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 851, 4679,  314,  ..., 4244,  639, 1654],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6743, -3.7895, -3.8146,  ..., -5.7820,  5.8394, 13.2798],\n",
      "        [-2.6743, -3.7895, -3.8146,  ..., -5.7820,  5.8394, 13.2798],\n",
      "        [-2.6743, -3.7895, -3.8146,  ..., -5.7820,  5.8394, 13.2798],\n",
      "        ...,\n",
      "        [-4.4180, -4.3103, -4.5246,  ...,  9.3807, -1.8329, -1.9377],\n",
      "        [-4.6863, -3.9301, -6.1634,  ..., 11.8434, -2.7552, -2.8368],\n",
      "        [-4.5467, -3.9390, -5.2184,  ...,  9.9298, -3.1911, -3.3466]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8485, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2793, 4943, 2733,  ...,  672, 1010, 1372],\n",
      "        [4166,  380, 2915,  ..., 3831, 4334,  380],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4166,  380, 2915,  ..., 3831, 4334,  380],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6748, -3.7893, -3.8140,  ..., -5.7816,  5.8383, 13.2807],\n",
      "        [-2.6748, -3.7893, -3.8140,  ..., -5.7816,  5.8383, 13.2807],\n",
      "        [-2.6748, -3.7893, -3.8140,  ..., -5.7816,  5.8383, 13.2807],\n",
      "        ...,\n",
      "        [-4.1813, -3.7894, -5.6244,  ...,  9.2378, -3.1052, -3.3189],\n",
      "        [-4.4121, -3.6218, -4.1755,  ..., 10.9340, -3.8106, -3.4615],\n",
      "        [-4.2300, -4.1348, -5.9047,  ..., 10.9999, -3.0815, -3.1445]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7761, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2844, 1407, 1976,  ..., 1579, 3933, 3382],\n",
      "        [1081, 2653, 2602,  ..., 2058, 4775,  745],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1081, 2653, 2602,  ..., 2058, 4775,  745],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6742, -3.7894, -3.8138,  ..., -5.7810,  5.8338, 13.2848],\n",
      "        [-2.6742, -3.7894, -3.8138,  ..., -5.7810,  5.8338, 13.2848],\n",
      "        [-2.6742, -3.7894, -3.8138,  ..., -5.7810,  5.8338, 13.2848],\n",
      "        ...,\n",
      "        [-4.3810, -4.5100, -5.4673,  ..., 10.6084, -3.3956, -3.6436],\n",
      "        [-4.7911, -3.5143, -4.3336,  ..., 10.1682, -3.2943, -3.0085],\n",
      "        [-4.1411, -3.9610, -5.8863,  ...,  9.3558, -2.1135, -2.4513]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8956, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4813, 2763, 4813,  ..., 4916,  505, 2349],\n",
      "        [5277, 2052, 5186,  ..., 1904, 1115, 2059],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5277, 2052, 5186,  ..., 1904, 1115, 2059],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6738, -3.7899, -3.8139,  ..., -5.7812,  5.8302, 13.2883],\n",
      "        [-2.6738, -3.7899, -3.8139,  ..., -5.7812,  5.8302, 13.2883],\n",
      "        [-2.6738, -3.7899, -3.8139,  ..., -5.7812,  5.8302, 13.2883],\n",
      "        ...,\n",
      "        [-4.6127, -3.8135, -5.1584,  ..., 11.4633, -3.1006, -2.9066],\n",
      "        [-4.4934, -3.8373, -4.8985,  ..., 10.7681, -3.2918, -3.2643],\n",
      "        [-4.5082, -3.8814, -5.2206,  ..., 12.1068, -3.2493, -2.9035]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8512, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2219,  639, 4297,  ..., 1758, 4478, 1221],\n",
      "        [4679, 1452, 2022,  ..., 2226, 2164, 3521],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4679, 1452, 2022,  ..., 2226, 2164, 3521],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6737, -3.7896, -3.8142,  ..., -5.7820,  5.8262, 13.2926],\n",
      "        [-2.6737, -3.7896, -3.8142,  ..., -5.7820,  5.8262, 13.2926],\n",
      "        [-2.6737, -3.7896, -3.8142,  ..., -5.7820,  5.8262, 13.2926],\n",
      "        ...,\n",
      "        [-4.7060, -3.5885, -4.3907,  ..., 10.9553, -3.6490, -3.4115],\n",
      "        [-4.7592, -3.6423, -5.3043,  ..., 11.7684, -3.0182, -3.1855],\n",
      "        [-4.3403, -3.7217, -4.4224,  ..., 10.5197, -3.2131, -3.3074]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9518, grad_fn=<NllLossBackward>)\n",
      "['春晚                                                                                                                                                                                                      ', '江北北，一番花下，一片春风。', '花悴。', '月下，一番春风雨。', '夜蓉雨                                                                                                                                                                                                     ', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番番月下，一片春风。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4460, 3382, 4716,  ...,  948,  639, 1694],\n",
      "        [4689,  745, 5249,  ..., 4266, 1452,  220],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4689,  745, 5249,  ..., 4266, 1452,  220],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6738, -3.7897, -3.8146,  ..., -5.7825,  5.8251, 13.2934],\n",
      "        [-2.6738, -3.7897, -3.8146,  ..., -5.7825,  5.8251, 13.2934],\n",
      "        [-2.6738, -3.7897, -3.8146,  ..., -5.7825,  5.8251, 13.2934],\n",
      "        ...,\n",
      "        [-4.7673, -4.3392, -5.0965,  ..., 11.6243, -3.2620, -3.2995],\n",
      "        [-4.6341, -3.8242, -5.9251,  ..., 11.0301, -2.6964, -2.5315],\n",
      "        [-4.4813, -4.6246, -6.0798,  ..., 11.6327, -3.1097, -3.2941]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9215, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3004, 3505, 4623,  ...,   25,  712, 3665],\n",
      "        [3382, 5081,  283,  ...,  806,  933,   27],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3382, 5081,  283,  ...,  806,  933,   27],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6742, -3.7891, -3.8152,  ..., -5.7825,  5.8255, 13.2925],\n",
      "        [-2.6742, -3.7891, -3.8152,  ..., -5.7825,  5.8255, 13.2925],\n",
      "        [-2.6742, -3.7891, -3.8152,  ..., -5.7825,  5.8255, 13.2925],\n",
      "        ...,\n",
      "        [-4.6227, -4.3869, -5.7748,  ..., 11.2879, -2.9231, -2.9188],\n",
      "        [-4.7484, -4.3391, -5.5305,  ..., 11.8759, -2.7136, -2.8349],\n",
      "        [-4.4103, -4.0873, -5.4560,  ..., 10.4600, -3.6434, -3.7570]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8362, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1273, 1401, 2460,  ..., 4526,  832, 4204],\n",
      "        [3575, 2915, 3733,  ..., 4104,  283,   53],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3575, 2915, 3733,  ..., 4104,  283,   53],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6747, -3.7887, -3.8158,  ..., -5.7821,  5.8266, 13.2906],\n",
      "        [-2.6747, -3.7887, -3.8158,  ..., -5.7821,  5.8266, 13.2906],\n",
      "        [-2.6747, -3.7887, -3.8158,  ..., -5.7821,  5.8266, 13.2906],\n",
      "        ...,\n",
      "        [-4.4965, -3.9429, -4.4153,  ..., 10.8223, -3.2291, -2.6181],\n",
      "        [-4.3653, -4.0240, -6.0998,  ..., 11.4171, -2.8012, -3.0185],\n",
      "        [-4.1219, -4.1405, -5.6778,  ..., 11.6698, -3.1406, -3.2085]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9525, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1240, 3668, 1452,  ...,  593, 1372,   48],\n",
      "        [2234, 3030, 4825,  ..., 2460, 2017, 4069],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2234, 3030, 4825,  ..., 2460, 2017, 4069],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6754, -3.7868, -3.8164,  ..., -5.7817,  5.8302, 13.2862],\n",
      "        [-2.6754, -3.7868, -3.8164,  ..., -5.7817,  5.8302, 13.2862],\n",
      "        [-2.6754, -3.7868, -3.8164,  ..., -5.7817,  5.8302, 13.2862],\n",
      "        ...,\n",
      "        [-4.7385, -3.8829, -4.6066,  ..., 11.8106, -2.5011, -2.1762],\n",
      "        [-3.9236, -3.2579, -4.6062,  ...,  8.4716, -3.3025, -3.7537],\n",
      "        [-5.1458, -4.2574, -5.2026,  ..., 11.2472, -3.1786, -2.9288]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8505, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5189, 2979, 3506,  ..., 3061, 3467, 2809],\n",
      "        [2809,  260, 2602,  ...,  922, 1884, 3074],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2809,  260, 2602,  ...,  922, 1884, 3074],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6752, -3.7845, -3.8169,  ..., -5.7814,  5.8332, 13.2825],\n",
      "        [-2.6752, -3.7845, -3.8169,  ..., -5.7814,  5.8332, 13.2825],\n",
      "        [-2.6752, -3.7845, -3.8169,  ..., -5.7814,  5.8332, 13.2825],\n",
      "        ...,\n",
      "        [-3.3002, -3.5281, -4.6498,  ...,  4.0923, -2.8258, -3.0011],\n",
      "        [-4.1205, -3.7385, -5.1699,  ..., 10.1316, -3.6959, -3.7633],\n",
      "        [-4.5793, -4.2118, -5.7378,  ..., 11.0848, -2.9531, -2.5937]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8388, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1989, 2809, 1912,  ...,  831, 4813, 3978],\n",
      "        [1384, 4679,  681,  ..., 5150, 3894, 1539],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1384, 4679,  681,  ..., 5150, 3894, 1539],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6752, -3.7826, -3.8173,  ..., -5.7818,  5.8355, 13.2800],\n",
      "        [-2.6752, -3.7826, -3.8173,  ..., -5.7818,  5.8355, 13.2800],\n",
      "        [-2.6752, -3.7826, -3.8173,  ..., -5.7818,  5.8355, 13.2800],\n",
      "        ...,\n",
      "        [-4.6971, -4.4535, -5.5511,  ..., 11.2693, -3.2367, -3.1676],\n",
      "        [-4.9120, -3.6023, -4.3731,  ..., 10.6493, -3.3961, -3.0918],\n",
      "        [-4.7959, -3.6350, -5.0055,  ..., 11.4258, -2.9551, -2.9031]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8237, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3598, 1427, 3205,  ..., 1192, 5027,  709],\n",
      "        [4017, 4997,  974,  ..., 2093, 5128, 3892],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4017, 4997,  974,  ..., 2093, 5128, 3892],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6754, -3.7811, -3.8176,  ..., -5.7822,  5.8368, 13.2791],\n",
      "        [-2.6754, -3.7811, -3.8176,  ..., -5.7822,  5.8368, 13.2791],\n",
      "        [-2.6754, -3.7811, -3.8176,  ..., -5.7822,  5.8368, 13.2791],\n",
      "        ...,\n",
      "        [-4.5026, -3.8792, -5.0484,  ..., 11.5700, -3.1770, -3.0720],\n",
      "        [-4.7998, -3.8662, -5.3852,  ..., 11.6529, -3.4537, -3.3388],\n",
      "        [-4.5071, -4.0536, -5.7910,  ..., 11.6814, -2.4877, -2.5251]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8263, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3885, 4401, 1131,  ...,  105, 1868, 1262],\n",
      "        [1535, 3118,  825,  ..., 4119,  366, 3665],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1535, 3118,  825,  ..., 4119,  366, 3665],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6758, -3.7791, -3.8178,  ..., -5.7820,  5.8371, 13.2790],\n",
      "        [-2.6758, -3.7791, -3.8178,  ..., -5.7820,  5.8371, 13.2790],\n",
      "        [-2.6758, -3.7791, -3.8178,  ..., -5.7820,  5.8371, 13.2790],\n",
      "        ...,\n",
      "        [-4.2004, -3.6229, -5.7522,  ...,  9.0581, -2.9768, -3.2126],\n",
      "        [-4.7392, -4.1467, -5.0411,  ..., 11.3969, -3.1336, -3.1970],\n",
      "        [-4.8428, -4.6268, -5.8644,  ..., 11.4762, -2.5878, -2.6537]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9482, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3092, 4526, 1579,  ..., 4702,  851, 3166],\n",
      "        [2936, 4987, 2058,  ...,  832, 5240, 2936],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2936, 4987, 2058,  ...,  832, 5240, 2936],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6765, -3.7768, -3.8182,  ..., -5.7810,  5.8385, 13.2775],\n",
      "        [-2.6765, -3.7768, -3.8182,  ..., -5.7810,  5.8385, 13.2775],\n",
      "        [-2.6765, -3.7768, -3.8182,  ..., -5.7810,  5.8385, 13.2775],\n",
      "        ...,\n",
      "        [-4.8380, -4.3272, -5.0197,  ..., 11.0040, -2.4389, -2.3654],\n",
      "        [-4.5681, -4.1184, -5.2793,  ..., 11.0952, -2.6593, -2.4839],\n",
      "        [-4.3471, -4.2276, -4.7920,  ..., 10.8103, -2.0215, -2.1480]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7465, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 851, 5295, 1131,  ..., 1240,   43,  389],\n",
      "        [1983, 5295, 4439,  ..., 4857, 3223,  326],\n",
      "        [ 436, 5294,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1983, 5295, 4439,  ..., 4857, 3223,  326],\n",
      "        [ 436, 5294,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6762, -3.7750, -3.8185,  ..., -5.7800,  5.8368, 13.2795],\n",
      "        [-2.6762, -3.7750, -3.8185,  ..., -5.7800,  5.8368, 13.2795],\n",
      "        [-2.6762, -3.7750, -3.8185,  ..., -5.7800,  5.8368, 13.2795],\n",
      "        ...,\n",
      "        [-4.6654, -4.2969, -4.9952,  ..., 10.5199, -2.3195, -2.3974],\n",
      "        [-3.5097, -3.3860, -3.5149,  ...,  7.9016, -2.0908, -2.2939],\n",
      "        [-4.4658, -3.8767, -5.9229,  ..., 10.7930, -3.1509, -3.1568]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8475, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1382, 2414,  144,  ..., 4493, 3428, 4987],\n",
      "        [3021, 2219, 4329,  ..., 1849,  881, 2152],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3021, 2219, 4329,  ..., 1849,  881, 2152],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6760, -3.7734, -3.8188,  ..., -5.7810,  5.8330, 13.2840],\n",
      "        [-2.6760, -3.7734, -3.8188,  ..., -5.7810,  5.8330, 13.2840],\n",
      "        [-2.6760, -3.7734, -3.8188,  ..., -5.7810,  5.8330, 13.2840],\n",
      "        ...,\n",
      "        [-4.4026, -4.6154, -5.8449,  ..., 12.6107, -2.6634, -2.6971],\n",
      "        [-4.1572, -3.9052, -5.7284,  ...,  9.5531, -3.1956, -3.3934],\n",
      "        [-4.1257, -4.0446, -5.6884,  ..., 10.9091, -2.7764, -3.0374]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8485, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 498, 3980, 3949,  ..., 1194, 2526,  978],\n",
      "        [4331, 2181, 2624,  ..., 1210, 2388, 3048],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4331, 2181, 2624,  ..., 1210, 2388, 3048],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6761, -3.7721, -3.8194,  ..., -5.7819,  5.8297, 13.2872],\n",
      "        [-2.6761, -3.7721, -3.8194,  ..., -5.7819,  5.8297, 13.2872],\n",
      "        [-2.6761, -3.7721, -3.8194,  ..., -5.7819,  5.8297, 13.2872],\n",
      "        ...,\n",
      "        [-4.3051, -4.0726, -5.3586,  ..., 10.3624, -3.5263, -3.7120],\n",
      "        [-4.9127, -4.2406, -5.2268,  ..., 10.9826, -2.6227, -2.4907],\n",
      "        [-4.1315, -3.6086, -5.3711,  ...,  9.6448, -3.5074, -3.3327]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9059, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1976, 3342, 5240,  ...,  639, 1888, 4753],\n",
      "        [ 321, 3237, 3786,  ..., 1192, 1502,  881],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 321, 3237, 3786,  ..., 1192, 1502,  881],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6765, -3.7713, -3.8200,  ..., -5.7818,  5.8274, 13.2884],\n",
      "        [-2.6765, -3.7713, -3.8200,  ..., -5.7818,  5.8274, 13.2884],\n",
      "        [-2.6765, -3.7713, -3.8200,  ..., -5.7818,  5.8274, 13.2884],\n",
      "        ...,\n",
      "        [-4.5694, -4.3039, -6.3169,  ..., 10.4903, -2.5324, -2.5506],\n",
      "        [-4.6361, -3.9850, -5.3935,  ..., 12.2900, -2.8322, -2.8561],\n",
      "        [-4.1991, -4.0052, -5.5518,  ..., 10.0575, -3.0610, -3.0377]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8741, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1947, 2601, 4753,  ..., 5295, 2793, 3818],\n",
      "        [4585,  754, 2219,  ..., 5295, 3417, 2371],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4585,  754, 2219,  ..., 5295, 3417, 2371],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6770, -3.7706, -3.8207,  ..., -5.7822,  5.8259, 13.2889],\n",
      "        [-2.6770, -3.7706, -3.8207,  ..., -5.7822,  5.8259, 13.2889],\n",
      "        [-2.6770, -3.7706, -3.8207,  ..., -5.7822,  5.8259, 13.2889],\n",
      "        ...,\n",
      "        [-3.5024, -4.0476, -6.0323,  ...,  7.8461, -0.3618, -0.2252],\n",
      "        [-4.6076, -4.0101, -5.5308,  ..., 12.2419, -3.1957, -2.8502],\n",
      "        [-4.5476, -4.0346, -4.6411,  ...,  8.0724, -3.4061, -3.8369]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9602, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4240, 4265, 3616,  ...,  283, 4623, 1192],\n",
      "        [5218, 1933, 1263,  ..., 1158, 1164, 5077],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5218, 1933, 1263,  ..., 1158, 1164, 5077],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6777, -3.7696, -3.8213,  ..., -5.7842,  5.8252, 13.2890],\n",
      "        [-2.6777, -3.7696, -3.8213,  ..., -5.7842,  5.8252, 13.2890],\n",
      "        [-2.6777, -3.7696, -3.8213,  ..., -5.7842,  5.8252, 13.2890],\n",
      "        ...,\n",
      "        [-4.0357, -3.9859, -5.2503,  ..., 11.0740, -2.8147, -3.0134],\n",
      "        [-4.6903, -3.4793, -4.3062,  ..., 10.4361, -2.8091, -2.4708],\n",
      "        [-4.2863, -4.1945, -5.1596,  ..., 11.0637, -2.2667, -2.5907]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9134, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4340, 3236, 1452,  ...,  129,  564, 1649],\n",
      "        [1654, 1340, 3364,  ...,  861, 2732, 3217],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1654, 1340, 3364,  ...,  861, 2732, 3217],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6785, -3.7662, -3.8220,  ..., -5.7865,  5.8246, 13.2889],\n",
      "        [-2.6785, -3.7662, -3.8220,  ..., -5.7865,  5.8246, 13.2889],\n",
      "        [-2.6785, -3.7662, -3.8220,  ..., -5.7865,  5.8246, 13.2889],\n",
      "        ...,\n",
      "        [-4.1584, -3.9556, -5.3550,  ..., 10.4548, -2.5957, -2.8066],\n",
      "        [-3.6366, -4.1858, -5.8295,  ...,  8.5320, -3.4816, -3.8263],\n",
      "        [-4.4441, -4.0888, -5.8068,  ..., 11.2493, -3.1567, -3.3830]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8707, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1293, 4628,    4,  ..., 2198, 2793,  321],\n",
      "        [1017, 1463, 2624,  ..., 2022,  389, 2936],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1017, 1463, 2624,  ..., 2022,  389, 2936],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6793, -3.7626, -3.8223,  ..., -5.7887,  5.8223, 13.2908],\n",
      "        [-2.6793, -3.7626, -3.8223,  ..., -5.7887,  5.8223, 13.2908],\n",
      "        [-2.6793, -3.7626, -3.8223,  ..., -5.7887,  5.8223, 13.2908],\n",
      "        ...,\n",
      "        [-4.6589, -3.9734, -5.1195,  ..., 11.7822, -3.1183, -2.8004],\n",
      "        [-4.6737, -4.6428, -5.2842,  ..., 10.1437, -2.4114, -2.4252],\n",
      "        [-4.6808, -3.5428, -4.5743,  ..., 11.6798, -3.1696, -2.8928]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7698, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3321, 3898,  321,  ..., 4087, 5295, 2258],\n",
      "        [2058, 2961,  965,  ...,  411, 5295, 3046],\n",
      "        [ 436,  436,  436,  ...,  436, 5294,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2058, 2961,  965,  ...,  411, 5295, 3046],\n",
      "        [ 436,  436,  436,  ...,  436, 5294,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6804, -3.7598, -3.8225,  ..., -5.7894,  5.8188, 13.2939],\n",
      "        [-2.6804, -3.7598, -3.8225,  ..., -5.7894,  5.8188, 13.2939],\n",
      "        [-2.6804, -3.7598, -3.8225,  ..., -5.7894,  5.8188, 13.2939],\n",
      "        ...,\n",
      "        [-3.8142, -4.0498, -4.7165,  ...,  7.9478, -3.4401, -3.8270],\n",
      "        [-3.5390, -4.0772, -6.0650,  ...,  7.9015, -0.3382, -0.1868],\n",
      "        [-4.8512, -4.1792, -4.7012,  ..., 11.9096, -2.1648, -1.9128]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8522, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4716, 2801, 4317,  ..., 3379, 1539,  283],\n",
      "        [4265, 2801, 2887,  ...,  948, 5036, 1245],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4265, 2801, 2887,  ...,  948, 5036, 1245],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6817, -3.7576, -3.8228,  ..., -5.7898,  5.8156, 13.2968],\n",
      "        [-2.6817, -3.7576, -3.8228,  ..., -5.7898,  5.8156, 13.2968],\n",
      "        [-2.6817, -3.7576, -3.8228,  ..., -5.7898,  5.8156, 13.2968],\n",
      "        ...,\n",
      "        [-4.4870, -3.2956, -3.9080,  ...,  9.3214, -2.7606, -2.4220],\n",
      "        [-4.5593, -3.8257, -5.3771,  ..., 10.9893, -3.2858, -3.1109],\n",
      "        [-4.4733, -3.5573, -5.3723,  ..., 11.5455, -2.8254, -2.6826]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8492, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2828,  254,  114,  ..., 5235,  987, 2058],\n",
      "        [4266, 2752, 3820,  ..., 1089,   48,  832],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4266, 2752, 3820,  ..., 1089,   48,  832],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6829, -3.7556, -3.8229,  ..., -5.7912,  5.8119, 13.3011],\n",
      "        [-2.6829, -3.7556, -3.8229,  ..., -5.7912,  5.8119, 13.3011],\n",
      "        [-2.6829, -3.7556, -3.8229,  ..., -5.7912,  5.8119, 13.3011],\n",
      "        ...,\n",
      "        [-4.5350, -3.7714, -4.8350,  ...,  9.7475, -3.3587, -3.2678],\n",
      "        [-4.8096, -4.2465, -4.3820,  ..., 10.0229, -2.1550, -2.3552],\n",
      "        [-4.5862, -4.2073, -5.3129,  ..., 11.5894, -2.6592, -2.5855]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8899, grad_fn=<NllLossBackward>)\n",
      "['春晚                                                                                                                                                                                                      ', '江北北，一番风月，一枝千里。', '花李。', '月下，一番春风雨。', '夜蓉雨                                                                                                                                                                                                     ', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番番月下，一片春风。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1910, 5173,  369,  ..., 4305, 5027, 1452],\n",
      "        [2378, 4899, 1081,  ..., 2453, 3670, 4532],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2378, 4899, 1081,  ..., 2453, 3670, 4532],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6843, -3.7536, -3.8231,  ..., -5.7925,  5.8089, 13.3051],\n",
      "        [-2.6843, -3.7536, -3.8231,  ..., -5.7925,  5.8089, 13.3051],\n",
      "        [-2.6843, -3.7536, -3.8231,  ..., -5.7925,  5.8089, 13.3051],\n",
      "        ...,\n",
      "        [-4.5162, -4.0048, -5.3209,  ..., 11.2786, -3.4834, -3.3797],\n",
      "        [-4.4574, -3.9518, -5.5790,  ..., 10.1811, -3.2690, -3.1028],\n",
      "        [-4.3717, -4.0928, -5.2078,  ..., 11.5007, -3.3656, -2.9353]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9120, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4266, 3854,    4,  ...,  620, 3331,  717],\n",
      "        [ 380,  574, 3023,  ..., 3500, 2378, 3217],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 380,  574, 3023,  ..., 3500, 2378, 3217],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6847, -3.7516, -3.8212,  ..., -5.7924,  5.8085, 13.3060],\n",
      "        [-2.6847, -3.7516, -3.8212,  ..., -5.7924,  5.8085, 13.3060],\n",
      "        [-2.6847, -3.7516, -3.8212,  ..., -5.7924,  5.8085, 13.3060],\n",
      "        ...,\n",
      "        [-4.5638, -4.0004, -5.6709,  ..., 12.0839, -3.1348, -3.2327],\n",
      "        [-4.4234, -4.5499, -5.6482,  ..., 10.6934, -2.9061, -3.3177],\n",
      "        [-4.5919, -4.2256, -5.4046,  ..., 10.3917, -2.7493, -2.7899]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8047, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 861, 1282, 2378,  ...,  969, 2915, 4470],\n",
      "        [3907, 2058, 3909,  ..., 4905, 4857, 3500],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3907, 2058, 3909,  ..., 4905, 4857, 3500],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6844, -3.7500, -3.8194,  ..., -5.7917,  5.8089, 13.3056],\n",
      "        [-2.6844, -3.7500, -3.8194,  ..., -5.7917,  5.8089, 13.3056],\n",
      "        [-2.6844, -3.7500, -3.8194,  ..., -5.7917,  5.8089, 13.3056],\n",
      "        ...,\n",
      "        [-4.8029, -4.0783, -5.6951,  ..., 11.9531, -2.7609, -2.7380],\n",
      "        [-4.2998, -4.0648, -5.6921,  ...,  9.6169, -3.6249, -3.7741],\n",
      "        [-4.8001, -4.5591, -5.3314,  ..., 10.3505, -2.6772, -2.6549]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8789, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4069, 2164, 2378,  ..., 4691, 3852, 3806],\n",
      "        [3938, 1399, 3092,  ..., 1492, 4193, 4894],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3938, 1399, 3092,  ..., 1492, 4193, 4894],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6843, -3.7487, -3.8180,  ..., -5.7922,  5.8098, 13.3047],\n",
      "        [-2.6843, -3.7487, -3.8180,  ..., -5.7922,  5.8098, 13.3047],\n",
      "        [-2.6843, -3.7487, -3.8180,  ..., -5.7922,  5.8098, 13.3047],\n",
      "        ...,\n",
      "        [-4.5048, -3.9250, -5.3429,  ...,  9.4994, -3.2800, -3.3829],\n",
      "        [-4.3537, -4.0405, -5.9416,  ...,  9.5169, -3.0312, -3.0280],\n",
      "        [-4.6415, -3.8089, -5.2416,  ..., 11.8759, -3.6218, -3.5490]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9842, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 712, 3331,  336,  ..., 1017, 5102, 2058],\n",
      "        [  87, 5143, 3457,  ...,  851,  283, 1309],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  87, 5143, 3457,  ...,  851,  283, 1309],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6835, -3.7476, -3.8170,  ..., -5.7925,  5.8122, 13.3019],\n",
      "        [-2.6835, -3.7476, -3.8170,  ..., -5.7925,  5.8122, 13.3019],\n",
      "        [-2.6835, -3.7476, -3.8170,  ..., -5.7925,  5.8122, 13.3019],\n",
      "        ...,\n",
      "        [-4.3984, -4.4497, -5.4194,  ..., 10.1128, -2.8279, -2.8355],\n",
      "        [-4.5730, -4.0457, -6.0413,  ..., 11.6026, -3.0951, -3.0594],\n",
      "        [-4.1592, -4.0125, -5.6864,  ..., 10.8223, -2.9195, -3.0826]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7794, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3008, 3113,  321,  ..., 2048, 2942, 3046],\n",
      "        [3008, 3566,  230,  ..., 2514, 2347, 3575],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3008, 3566,  230,  ..., 2514, 2347, 3575],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6831, -3.7463, -3.8163,  ..., -5.7928,  5.8133, 13.3007],\n",
      "        [-2.6831, -3.7463, -3.8163,  ..., -5.7928,  5.8133, 13.3007],\n",
      "        [-2.6831, -3.7463, -3.8163,  ..., -5.7928,  5.8133, 13.3007],\n",
      "        ...,\n",
      "        [-4.6688, -3.8801, -4.7900,  ..., 11.0564, -2.4396, -2.2628],\n",
      "        [-4.8902, -3.5883, -5.0348,  ..., 11.0864, -2.6381, -2.4892],\n",
      "        [-4.2882, -4.2343, -5.8740,  ..., 10.7613, -3.1101, -3.2008]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9208, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5295,  159,  458,  ..., 5173, 4265,  740],\n",
      "        [5295, 1499, 2017,  ..., 3290, 5222, 5017],\n",
      "        [5294,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5295, 1499, 2017,  ..., 3290, 5222, 5017],\n",
      "        [5294,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6831, -3.7456, -3.8164,  ..., -5.7924,  5.8158, 13.2980],\n",
      "        [-2.6831, -3.7456, -3.8164,  ..., -5.7924,  5.8158, 13.2980],\n",
      "        [-2.6831, -3.7456, -3.8164,  ..., -5.7924,  5.8158, 13.2980],\n",
      "        ...,\n",
      "        [-4.1156, -3.7462, -4.8766,  ...,  9.7273, -3.5675, -3.2966],\n",
      "        [-4.2151, -3.7452, -5.0554,  ..., 10.8547, -3.3731, -3.5341],\n",
      "        [-4.4039, -3.8466, -5.6362,  ..., 10.9667, -3.1433, -2.9264]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0140, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2947, 2809, 1240,  ..., 2122, 2991, 4877],\n",
      "        [1399, 4346, 2058,  ..., 2991, 1010,  948],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1399, 4346, 2058,  ..., 2991, 1010,  948],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6835, -3.7454, -3.8167,  ..., -5.7914,  5.8200, 13.2936],\n",
      "        [-2.6835, -3.7454, -3.8167,  ..., -5.7914,  5.8200, 13.2936],\n",
      "        [-2.6835, -3.7454, -3.8167,  ..., -5.7914,  5.8200, 13.2936],\n",
      "        ...,\n",
      "        [-4.0585, -4.1406, -5.1517,  ..., 10.8260, -2.4468, -2.8832],\n",
      "        [-4.4623, -3.5720, -4.7584,  ..., 10.8086, -3.5818, -3.4982],\n",
      "        [-4.4358, -3.4268, -4.4058,  ...,  9.7091, -3.3578, -3.0694]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0420, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1192, 1808, 3217,  ..., 2590,  165, 3814],\n",
      "        [5081,  321, 2389,  ..., 4465, 3061, 2836],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5081,  321, 2389,  ..., 4465, 3061, 2836],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6840, -3.7456, -3.8171,  ..., -5.7903,  5.8262, 13.2873],\n",
      "        [-2.6840, -3.7456, -3.8171,  ..., -5.7903,  5.8262, 13.2873],\n",
      "        [-2.6840, -3.7456, -3.8171,  ..., -5.7903,  5.8262, 13.2873],\n",
      "        ...,\n",
      "        [-4.7981, -4.1155, -5.1235,  ...,  9.9750, -3.3362, -3.2085],\n",
      "        [-4.2760, -3.9576, -5.4214,  ..., 11.2032, -3.5212, -3.5998],\n",
      "        [-4.5890, -3.9824, -5.5432,  ..., 11.5827, -3.3236, -3.3411]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9392, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  15, 5295, 1912,  ..., 3132, 3650, 1010],\n",
      "        [2341, 5295,  878,  ...,  843, 3500,  745],\n",
      "        [ 436, 5294,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2341, 5295,  878,  ...,  843, 3500,  745],\n",
      "        [ 436, 5294,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6847, -3.7461, -3.8174,  ..., -5.7899,  5.8310, 13.2833],\n",
      "        [-2.6847, -3.7461, -3.8174,  ..., -5.7899,  5.8310, 13.2833],\n",
      "        [-2.6847, -3.7461, -3.8174,  ..., -5.7899,  5.8310, 13.2833],\n",
      "        ...,\n",
      "        [-5.0937, -3.7123, -5.2974,  ..., 10.5746, -2.9850, -2.9203],\n",
      "        [-4.8198, -4.2717, -5.3422,  ..., 11.5652, -2.8916, -3.0502],\n",
      "        [-4.5356, -3.9240, -4.7569,  ..., 11.4042, -2.8449, -3.0751]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8220, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4809, 3068,  366,  ..., 2629, 2369, 3978],\n",
      "        [4987, 1846, 3217,  ..., 4467, 4168,  806],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4987, 1846, 3217,  ..., 4467, 4168,  806],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6856, -3.7468, -3.8175,  ..., -5.7906,  5.8332, 13.2825],\n",
      "        [-2.6856, -3.7468, -3.8175,  ..., -5.7906,  5.8332, 13.2825],\n",
      "        [-2.6856, -3.7468, -3.8175,  ..., -5.7906,  5.8332, 13.2825],\n",
      "        ...,\n",
      "        [-4.5447, -3.7086, -5.0758,  ..., 12.1350, -2.5050, -2.4723],\n",
      "        [-4.5238, -4.4141, -5.1068,  ..., 11.0486, -3.1253, -3.1963],\n",
      "        [-4.6007, -3.9610, -5.4117,  ..., 11.2370, -2.7264, -2.8947]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9343, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2022,  283, 4188,  ..., 3010, 3331, 1844],\n",
      "        [2259, 2058, 3427,  ..., 3347,  754, 1844],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2259, 2058, 3427,  ..., 3347,  754, 1844],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6865, -3.7475, -3.8177,  ..., -5.7921,  5.8347, 13.2826],\n",
      "        [-2.6865, -3.7475, -3.8177,  ..., -5.7921,  5.8347, 13.2826],\n",
      "        [-2.6865, -3.7475, -3.8177,  ..., -5.7921,  5.8347, 13.2826],\n",
      "        ...,\n",
      "        [-4.3463, -4.0109, -5.2548,  ...,  9.0805, -2.6856, -3.0066],\n",
      "        [-4.0565, -4.0211, -5.2061,  ..., 10.4695, -2.5461, -2.7665],\n",
      "        [-4.3212, -3.8862, -6.1470,  ..., 10.0958, -2.1726, -2.4347]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7911, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 321, 1054,  639,  ...,  381, 1232, 2991],\n",
      "        [3500, 4794, 2166,  ..., 1030, 4825, 3500],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3500, 4794, 2166,  ..., 1030, 4825, 3500],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6862, -3.7476, -3.8157,  ..., -5.7925,  5.8346, 13.2836],\n",
      "        [-2.6862, -3.7476, -3.8157,  ..., -5.7925,  5.8346, 13.2836],\n",
      "        [-2.6862, -3.7476, -3.8157,  ..., -5.7925,  5.8346, 13.2836],\n",
      "        ...,\n",
      "        [-2.7223, -3.9668, -5.3090,  ...,  4.3835, -2.2402, -2.5405],\n",
      "        [-4.1613, -3.7831, -5.3688,  ..., 10.0060, -3.2114, -3.3044],\n",
      "        [-4.4058, -4.3713, -5.6361,  ..., 10.7257, -3.0893, -3.4874]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8599, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2167,  593, 2753,  ..., 2193, 4983, 4712],\n",
      "        [2763, 4870, 1694,  ...,  321, 1401, 3575],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2763, 4870, 1694,  ...,  321, 1401, 3575],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6861, -3.7473, -3.8140,  ..., -5.7914,  5.8343, 13.2839],\n",
      "        [-2.6861, -3.7473, -3.8140,  ..., -5.7914,  5.8343, 13.2839],\n",
      "        [-2.6861, -3.7473, -3.8140,  ..., -5.7914,  5.8343, 13.2839],\n",
      "        ...,\n",
      "        [-4.4723, -4.1000, -5.2162,  ..., 10.8024, -2.8300, -2.8699],\n",
      "        [-4.4090, -4.3993, -5.6303,  ..., 10.4082, -3.1921, -3.2223],\n",
      "        [-4.8787, -3.6391, -4.2560,  ..., 11.3480, -2.4836, -2.0513]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8724, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5294, 5295],\n",
      "        ...,\n",
      "        [5074,  307, 1541,  ...,  740, 5097, 1001],\n",
      "        [ 752,  369, 4455,  ..., 2369, 4150, 4069],\n",
      "        [ 436,  436,  436,  ...,  436,  276,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5294, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 3668, 5295],\n",
      "        ...,\n",
      "        [ 752,  369, 4455,  ..., 2369, 4150, 4069],\n",
      "        [ 436,  436,  436,  ...,  436,  276,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6863, -3.7475, -3.8129,  ..., -5.7907,  5.8331, 13.2851],\n",
      "        [-2.6863, -3.7475, -3.8129,  ..., -5.7907,  5.8331, 13.2851],\n",
      "        [-2.6863, -3.7475, -3.8129,  ..., -5.7907,  5.8331, 13.2851],\n",
      "        ...,\n",
      "        [-4.1846, -4.4722, -4.8090,  ..., 10.2444, -1.9949, -2.2129],\n",
      "        [-2.4830,  0.9213, -4.5621,  ..., -4.4771, -4.3537, -4.4877],\n",
      "        [-4.7076, -4.3095, -5.2878,  ..., 11.5427, -3.0999, -3.2866]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7474, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5249, 4572, 2122,  ..., 4679, 1293,  513],\n",
      "        [3331, 2001, 2475,  ..., 2964, 2866, 4716],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3331, 2001, 2475,  ..., 2964, 2866, 4716],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6868, -3.7473, -3.8124,  ..., -5.7918,  5.8305, 13.2886],\n",
      "        [-2.6868, -3.7473, -3.8124,  ..., -5.7918,  5.8305, 13.2886],\n",
      "        [-2.6868, -3.7473, -3.8124,  ..., -5.7918,  5.8305, 13.2886],\n",
      "        ...,\n",
      "        [-4.3658, -3.7731, -5.3813,  ..., 10.5345, -3.4787, -3.3988],\n",
      "        [-4.0047, -3.6713, -5.1611,  ...,  9.4869, -3.7114, -3.6807],\n",
      "        [-4.6415, -3.3135, -4.7863,  ..., 11.0566, -2.9891, -3.0829]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9481, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3667, 5081, 2247,  ...,  321, 2064, 2778],\n",
      "        [4087, 1094,  965,  ..., 4825, 3480,  672],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4087, 1094,  965,  ..., 4825, 3480,  672],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6875, -3.7474, -3.8122,  ..., -5.7934,  5.8292, 13.2906],\n",
      "        [-2.6875, -3.7474, -3.8122,  ..., -5.7934,  5.8292, 13.2906],\n",
      "        [-2.6875, -3.7474, -3.8122,  ..., -5.7934,  5.8292, 13.2906],\n",
      "        ...,\n",
      "        [-4.5834, -4.0796, -5.5989,  ..., 11.8489, -3.3118, -3.2651],\n",
      "        [-5.0393, -3.7996, -5.2815,  ..., 12.6159, -2.7387, -2.8780],\n",
      "        [-3.9857, -3.6820, -5.1223,  ...,  9.6798, -2.4515, -2.6359]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9040, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 639,  114, 2313,  ..., 1401,  751, 5132],\n",
      "        [1452,  970, 1447,  ..., 3560, 4777, 1670],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1452,  970, 1447,  ..., 3560, 4777, 1670],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6883, -3.7474, -3.8122,  ..., -5.7969,  5.8286, 13.2923],\n",
      "        [-2.6883, -3.7474, -3.8122,  ..., -5.7969,  5.8286, 13.2923],\n",
      "        [-2.6883, -3.7474, -3.8122,  ..., -5.7969,  5.8286, 13.2923],\n",
      "        ...,\n",
      "        [-4.6203, -4.5953, -5.9380,  ..., 11.4369, -2.8784, -2.8496],\n",
      "        [-4.4218, -3.6293, -4.7280,  ...,  8.7137, -2.9626, -2.8947],\n",
      "        [-4.3235, -3.8431, -5.3582,  ...,  9.8447, -3.5996, -3.7527]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8196, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3331, 2057,  709,  ..., 4526, 1131, 1399],\n",
      "        [2809, 3547, 4166,  ..., 2995, 1877, 2809],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2809, 3547, 4166,  ..., 2995, 1877, 2809],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6893, -3.7475, -3.8122,  ..., -5.7990,  5.8280, 13.2932],\n",
      "        [-2.6893, -3.7475, -3.8122,  ..., -5.7990,  5.8280, 13.2932],\n",
      "        [-2.6893, -3.7475, -3.8122,  ..., -5.7990,  5.8280, 13.2932],\n",
      "        ...,\n",
      "        [-4.5347, -3.8158, -5.1394,  ..., 11.2204, -3.2650, -2.9802],\n",
      "        [-4.5815, -3.8420, -4.8486,  ..., 11.3394, -2.2675, -2.1770],\n",
      "        [-4.7143, -4.2506, -5.9056,  ..., 11.9453, -2.6767, -2.8272]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9299, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4478,  366,  321,  ..., 1888,  563,  192],\n",
      "        [ 306,  421, 2541,  ..., 3898,  563, 4650],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 306,  421, 2541,  ..., 3898,  563, 4650],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6891, -3.7479, -3.8120,  ..., -5.7998,  5.8285, 13.2922],\n",
      "        [-2.6891, -3.7479, -3.8120,  ..., -5.7998,  5.8285, 13.2922],\n",
      "        [-2.6891, -3.7479, -3.8120,  ..., -5.7998,  5.8285, 13.2922],\n",
      "        ...,\n",
      "        [-4.7313, -3.7299, -4.6323,  ..., 11.4275, -2.7231, -2.4030],\n",
      "        [-4.5397, -3.9706, -5.4148,  ..., 11.3978, -2.9817, -3.3397],\n",
      "        [-4.1508, -3.3299, -3.0600,  ...,  8.3610, -2.0008, -2.1007]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7323, grad_fn=<NllLossBackward>)\n",
      "['春晚                                                                                                                                                                                                      ', '江北北，一番风月，一枝千里。', '花李。', '月下，一番春风雨。', '夜蓉雨                                                                                                                                                                                                     ', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番番月下，一片春风。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4305, 1131, 3544,  ..., 4880, 2947, 2057],\n",
      "        [ 851, 4439, 3634,  ...,  974,  978, 3466],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 851, 4439, 3634,  ...,  974,  978, 3466],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6891, -3.7471, -3.8116,  ..., -5.8019,  5.8272, 13.2941],\n",
      "        [-2.6891, -3.7471, -3.8116,  ..., -5.8019,  5.8272, 13.2941],\n",
      "        [-2.6891, -3.7471, -3.8116,  ..., -5.8019,  5.8272, 13.2941],\n",
      "        ...,\n",
      "        [-4.7390, -3.6633, -4.5645,  ..., 11.4690, -3.7389, -3.4989],\n",
      "        [-4.8397, -4.1044, -5.2452,  ..., 11.5242, -3.4215, -3.2275],\n",
      "        [-4.5973, -3.7358, -4.8163,  ..., 12.0982, -3.3832, -3.0373]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9200, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2085, 3573, 4017,  ..., 2763, 3237,  643],\n",
      "        [4017, 4753, 3365,  ...,  681,  513, 2369],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4017, 4753, 3365,  ...,  681,  513, 2369],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6894, -3.7468, -3.8120,  ..., -5.8052,  5.8258, 13.2972],\n",
      "        [-2.6894, -3.7468, -3.8120,  ..., -5.8052,  5.8258, 13.2972],\n",
      "        [-2.6894, -3.7468, -3.8120,  ..., -5.8052,  5.8258, 13.2972],\n",
      "        ...,\n",
      "        [-4.9290, -3.9456, -5.7246,  ..., 12.8322, -3.0401, -2.9960],\n",
      "        [-5.0714, -3.9089, -4.4331,  ..., 10.5131, -2.6043, -2.4139],\n",
      "        [-4.8253, -3.7700, -4.7352,  ..., 10.7489, -2.9236, -2.7943]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9983, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1452, 2870, 3878,  ..., 2378,  574,  649],\n",
      "        [5126, 3480, 1831,  ..., 1108, 3334, 2058],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5126, 3480, 1831,  ..., 1108, 3334, 2058],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6888, -3.7469, -3.8111,  ..., -5.8085,  5.8265, 13.2982],\n",
      "        [-2.6888, -3.7469, -3.8111,  ..., -5.8085,  5.8265, 13.2982],\n",
      "        [-2.6888, -3.7469, -3.8111,  ..., -5.8085,  5.8265, 13.2982],\n",
      "        ...,\n",
      "        [-4.3709, -4.5947, -5.4085,  ...,  9.8207, -3.0874, -3.3032],\n",
      "        [-4.2294, -4.2155, -5.5815,  ..., 10.4216, -2.8717, -3.0812],\n",
      "        [-4.6506, -3.8156, -5.7688,  ..., 11.2763, -3.3922, -3.4302]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9616, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  43, 3382, 2369,  ..., 3061, 5284, 1579],\n",
      "        [1210, 4504, 4482,  ..., 2936, 1649, 5253],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1210, 4504, 4482,  ..., 2936, 1649, 5253],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6888, -3.7471, -3.8082,  ..., -5.8096,  5.8293, 13.2962],\n",
      "        [-2.6888, -3.7471, -3.8082,  ..., -5.8096,  5.8293, 13.2962],\n",
      "        [-2.6888, -3.7471, -3.8082,  ..., -5.8096,  5.8293, 13.2962],\n",
      "        ...,\n",
      "        [-3.9763, -3.3179, -5.4447,  ...,  9.7788, -3.5806, -3.8717],\n",
      "        [-4.9057, -3.7558, -5.3157,  ..., 11.5150, -2.9730, -2.7752],\n",
      "        [-4.7403, -3.7308, -4.8832,  ...,  9.5803, -2.9231, -2.9263]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8713, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2546, 3563, 2181,  ...,  277, 4265,  307],\n",
      "        [ 436, 5108, 4776,  ..., 4533, 1989, 1100],\n",
      "        [2738,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 436, 5108, 4776,  ..., 4533, 1989, 1100],\n",
      "        [2738,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6877, -3.7457, -3.8051,  ..., -5.8119,  5.8306, 13.2953],\n",
      "        [-2.6877, -3.7457, -3.8051,  ..., -5.8119,  5.8306, 13.2953],\n",
      "        [-2.6877, -3.7457, -3.8051,  ..., -5.8119,  5.8306, 13.2953],\n",
      "        ...,\n",
      "        [-4.5168, -3.7909, -5.8143,  ..., 10.0066, -3.1656, -3.0977],\n",
      "        [-4.7009, -4.0337, -5.6544,  ..., 12.2280, -3.0964, -3.3214],\n",
      "        [-4.3064, -4.0351, -5.5653,  ..., 11.2536, -3.2881, -3.3897]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8431, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5051,  740,  321,  ...,  825, 2713, 1968],\n",
      "        [3951, 5219,  961,  ...,  831, 2964, 2602],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3951, 5219,  961,  ...,  831, 2964, 2602],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6868, -3.7443, -3.8024,  ..., -5.8160,  5.8306, 13.2961],\n",
      "        [-2.6868, -3.7443, -3.8024,  ..., -5.8160,  5.8306, 13.2961],\n",
      "        [-2.6868, -3.7443, -3.8024,  ..., -5.8160,  5.8306, 13.2961],\n",
      "        ...,\n",
      "        [-4.4812, -3.9763, -5.5978,  ..., 12.0884, -3.2209, -3.3169],\n",
      "        [-4.3641, -4.0536, -4.3903,  ...,  8.8525, -3.0766, -2.4832],\n",
      "        [-5.0229, -3.7500, -4.8874,  ..., 11.6220, -2.9581, -2.7863]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9253, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [5240, 4716, 2844,  ...,   56, 3933, 1661],\n",
      "        [4526, 4346, 1116,  ...,  567, 1271,  513],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4526, 4346, 1116,  ...,  567, 1271,  513],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6861, -3.7433, -3.7987,  ..., -5.8211,  5.8302, 13.2975],\n",
      "        [-2.6861, -3.7433, -3.7987,  ..., -5.8211,  5.8302, 13.2975],\n",
      "        [-2.6861, -3.7433, -3.7987,  ..., -5.8211,  5.8302, 13.2975],\n",
      "        ...,\n",
      "        [-4.4755, -4.7475, -5.5785,  ..., 12.7843, -2.5151, -2.5395],\n",
      "        [-4.2893, -4.1193, -5.0300,  ..., 10.6638, -2.4298, -2.7164],\n",
      "        [-4.7524, -3.5931, -4.4866,  ..., 11.8276, -2.7898, -2.5072]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8125, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4052,  965, 2733,  ..., 5295, 2159, 2947],\n",
      "        [2873, 1846,   74,  ..., 5295, 2809, 4087],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2873, 1846,   74,  ..., 5295, 2809, 4087],\n",
      "        [ 436,  436,  436,  ..., 5294,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6857, -3.7427, -3.7953,  ..., -5.8249,  5.8302, 13.2988],\n",
      "        [-2.6857, -3.7427, -3.7953,  ..., -5.8249,  5.8302, 13.2988],\n",
      "        [-2.6857, -3.7427, -3.7953,  ..., -5.8249,  5.8302, 13.2988],\n",
      "        ...,\n",
      "        [-3.5452, -4.1109, -6.0558,  ...,  7.9365, -0.3534, -0.2250],\n",
      "        [-4.7375, -4.6138, -5.3802,  ...,  9.5661, -2.7878, -2.5347],\n",
      "        [-4.4710, -3.8619, -5.2293,  ..., 11.6404, -3.1716, -3.3109]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9268, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4753,    4, 4470,  ..., 4265,  403,  996],\n",
      "        [ 961, 4983, 3061,  ...,  468, 3092, 2936],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 961, 4983, 3061,  ...,  468, 3092, 2936],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6844, -3.7426, -3.7923,  ..., -5.8261,  5.8316, 13.2975],\n",
      "        [-2.6844, -3.7426, -3.7923,  ..., -5.8261,  5.8316, 13.2975],\n",
      "        [-2.6844, -3.7426, -3.7923,  ..., -5.8261,  5.8316, 13.2975],\n",
      "        ...,\n",
      "        [-4.4595, -4.3714, -5.4348,  ..., 11.5351, -3.4287, -3.6727],\n",
      "        [-4.0743, -4.1849, -5.0388,  ...,  8.2904, -1.6840, -1.7775],\n",
      "        [-4.0330, -3.9498, -6.0079,  ...,  8.6524, -3.3935, -3.4223]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8009, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2793, 2809, 4096,  ..., 1309, 4753, 1416],\n",
      "        [3417, 1245, 3951,  ..., 4200, 2219,  639],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3417, 1245, 3951,  ..., 4200, 2219,  639],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6835, -3.7427, -3.7893,  ..., -5.8261,  5.8323, 13.2966],\n",
      "        [-2.6835, -3.7427, -3.7893,  ..., -5.8261,  5.8323, 13.2966],\n",
      "        [-2.6835, -3.7427, -3.7893,  ..., -5.8261,  5.8323, 13.2966],\n",
      "        ...,\n",
      "        [-4.7231, -3.5449, -4.2202,  ..., 10.6332, -3.1970, -2.9182],\n",
      "        [-4.7145, -4.1906, -5.2905,  ..., 11.5831, -3.0411, -2.7477],\n",
      "        [-4.4183, -4.5063, -6.1130,  ..., 12.1759, -3.0952, -3.0217]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7883, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4224, 4265, 3197,  ..., 2369, 1649, 1232],\n",
      "        [2091, 3021,   35,  ..., 2836, 1693, 2161],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2091, 3021,   35,  ..., 2836, 1693, 2161],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6827, -3.7421, -3.7866,  ..., -5.8279,  5.8312, 13.2986],\n",
      "        [-2.6827, -3.7421, -3.7866,  ..., -5.8279,  5.8312, 13.2986],\n",
      "        [-2.6827, -3.7421, -3.7866,  ..., -5.8279,  5.8312, 13.2986],\n",
      "        ...,\n",
      "        [-4.4660, -3.8611, -5.1327,  ..., 10.9589, -3.2528, -3.3786],\n",
      "        [-4.2654, -4.2499, -5.7022,  ..., 11.0857, -3.1269, -3.1291],\n",
      "        [-4.3239, -3.8855, -5.6754,  ..., 11.6041, -2.9829, -2.9585]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8796, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2804, 2629, 4526,  ...,  321, 5240, 2164],\n",
      "        [ 639, 3898, 4467,  ..., 4813, 4294, 2828],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 639, 3898, 4467,  ..., 4813, 4294, 2828],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6821, -3.7415, -3.7842,  ..., -5.8310,  5.8292, 13.3017],\n",
      "        [-2.6821, -3.7415, -3.7842,  ..., -5.8310,  5.8292, 13.3017],\n",
      "        [-2.6821, -3.7415, -3.7842,  ..., -5.8310,  5.8292, 13.3017],\n",
      "        ...,\n",
      "        [-4.4703, -4.0219, -5.8097,  ..., 12.7588, -3.0845, -3.2741],\n",
      "        [-4.5402, -4.5852, -5.6191,  ..., 11.9119, -3.3013, -3.3142],\n",
      "        [-4.7347, -3.9211, -4.1779,  ..., 11.0987, -3.4098, -2.7712]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.8371, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 965, 3878, 4265,  ..., 4905, 2947, 3321],\n",
      "        [1086,  173, 4526,  ...,  825,  320, 2058],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1086,  173, 4526,  ...,  825,  320, 2058],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6818, -3.7413, -3.7820,  ..., -5.8328,  5.8271, 13.3045],\n",
      "        [-2.6818, -3.7413, -3.7820,  ..., -5.8328,  5.8271, 13.3045],\n",
      "        [-2.6818, -3.7413, -3.7820,  ..., -5.8328,  5.8271, 13.3045],\n",
      "        ...,\n",
      "        [-4.3005, -4.0927, -5.9944,  ..., 10.6763, -2.6029, -2.6790],\n",
      "        [-4.7734, -4.1656, -5.3819,  ..., 10.8587, -3.0300, -2.8656],\n",
      "        [-3.8084, -4.3031, -6.0344,  ...,  8.4212, -3.0671, -3.3338]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9226, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3959,  965, 3480,  ..., 3560, 4831, 1272],\n",
      "        [1166, 4091, 1251,  ...,  321, 4224, 1787],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1166, 4091, 1251,  ...,  321, 4224, 1787],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6818, -3.7416, -3.7801,  ..., -5.8330,  5.8267, 13.3044],\n",
      "        [-2.6818, -3.7416, -3.7801,  ..., -5.8330,  5.8267, 13.3044],\n",
      "        [-2.6818, -3.7416, -3.7801,  ..., -5.8330,  5.8267, 13.3044],\n",
      "        ...,\n",
      "        [-4.3089, -4.2774, -5.6198,  ..., 11.0011, -2.8385, -3.0545],\n",
      "        [-4.3266, -4.3103, -5.4749,  ..., 11.4374, -3.3428, -3.2241],\n",
      "        [-4.8278, -3.7164, -4.8403,  ..., 11.3467, -3.0002, -2.7967]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9034, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2763, 2602, 4166,  ..., 3008,  861,  965],\n",
      "        [2369, 3569, 3021,  ..., 1913, 4370, 4075],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2369, 3569, 3021,  ..., 1913, 4370, 4075],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6806, -3.7423, -3.7787,  ..., -5.8340,  5.8263, 13.3041],\n",
      "        [-2.6806, -3.7423, -3.7787,  ..., -5.8340,  5.8263, 13.3041],\n",
      "        [-2.6806, -3.7423, -3.7787,  ..., -5.8340,  5.8263, 13.3041],\n",
      "        ...,\n",
      "        [-4.2749, -4.4618, -5.8345,  ..., 11.3822, -2.7862, -2.7772],\n",
      "        [-4.5248, -3.8727, -5.6836,  ..., 11.7296, -2.9184, -2.8923],\n",
      "        [-4.3319, -3.8107, -5.5755,  ..., 10.0444, -3.1540, -3.0857]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8237, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1661,  832, 2089,  ..., 2915, 3573, 2778],\n",
      "        [ 451, 4348, 2828,  ..., 1427, 3500, 2022],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 451, 4348, 2828,  ..., 1427, 3500, 2022],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6798, -3.7421, -3.7777,  ..., -5.8351,  5.8248, 13.3053],\n",
      "        [-2.6798, -3.7421, -3.7777,  ..., -5.8351,  5.8248, 13.3053],\n",
      "        [-2.6798, -3.7421, -3.7777,  ..., -5.8351,  5.8248, 13.3053],\n",
      "        ...,\n",
      "        [-4.2397, -4.1103, -5.5213,  ...,  9.1542, -3.3354, -3.4057],\n",
      "        [-4.9329, -3.8664, -5.5041,  ..., 11.4974, -3.1161, -3.3730],\n",
      "        [-4.3463, -3.8033, -4.9784,  ..., 11.4335, -2.6074, -2.9304]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9362, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 835, 2608, 2779,  ..., 4168, 2582, 4487],\n",
      "        [3686, 4870, 5002,  ..., 3500,  321, 2809],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3686, 4870, 5002,  ..., 3500,  321, 2809],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6793, -3.7423, -3.7771,  ..., -5.8368,  5.8250, 13.3050],\n",
      "        [-2.6793, -3.7423, -3.7771,  ..., -5.8368,  5.8250, 13.3050],\n",
      "        [-2.6793, -3.7423, -3.7771,  ..., -5.8368,  5.8250, 13.3050],\n",
      "        ...,\n",
      "        [-4.7509, -4.5414, -5.8932,  ..., 11.6684, -2.9407, -3.1795],\n",
      "        [-5.0733, -3.6376, -5.0016,  ..., 10.1441, -2.7204, -2.6593],\n",
      "        [-4.9597, -4.2058, -5.7026,  ..., 11.9363, -3.0062, -3.0732]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8949, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2127, 1004,  380,  ..., 2773, 2793, 2947],\n",
      "        [2936,  851, 2181,  ..., 4192, 3417, 3668],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2936,  851, 2181,  ..., 4192, 3417, 3668],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6789, -3.7426, -3.7765,  ..., -5.8385,  5.8260, 13.3040],\n",
      "        [-2.6789, -3.7426, -3.7765,  ..., -5.8385,  5.8260, 13.3040],\n",
      "        [-2.6789, -3.7426, -3.7765,  ..., -5.8385,  5.8260, 13.3040],\n",
      "        ...,\n",
      "        [-3.0526, -4.0678, -5.4590,  ...,  5.9361, -2.2328, -2.1113],\n",
      "        [-4.5694, -4.1167, -5.8590,  ..., 10.6683, -2.9927, -3.1351],\n",
      "        [-4.6616, -4.4068, -5.3216,  ..., 11.1401, -2.8536, -2.7682]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7901, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1771,  965, 4346,  ..., 4471, 3087,  639],\n",
      "        [4052, 5081, 5173,  ..., 2181, 3331, 3690],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4052, 5081, 5173,  ..., 2181, 3331, 3690],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6788, -3.7433, -3.7760,  ..., -5.8398,  5.8255, 13.3049],\n",
      "        [-2.6788, -3.7433, -3.7760,  ..., -5.8398,  5.8255, 13.3049],\n",
      "        [-2.6788, -3.7433, -3.7760,  ..., -5.8398,  5.8255, 13.3049],\n",
      "        ...,\n",
      "        [-4.3280, -4.2517, -5.1995,  ..., 10.2931, -2.3873, -2.5862],\n",
      "        [-4.1798, -3.8868, -5.7435,  ...,  9.9532, -3.3469, -3.5604],\n",
      "        [-3.5300, -3.9165, -5.6012,  ...,  8.0789, -3.1792, -3.8593]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.7498, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1989, 5169,    4,  ..., 3642, 3898, 4526],\n",
      "        [ 948,  851, 1584,  ..., 4573,  321, 3068],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 948,  851, 1584,  ..., 4573,  321, 3068],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6790, -3.7441, -3.7756,  ..., -5.8408,  5.8243, 13.3068],\n",
      "        [-2.6790, -3.7441, -3.7756,  ..., -5.8408,  5.8243, 13.3068],\n",
      "        [-2.6790, -3.7441, -3.7756,  ..., -5.8408,  5.8243, 13.3068],\n",
      "        ...,\n",
      "        [-4.7238, -3.9951, -5.6858,  ..., 12.2411, -2.8931, -2.8340],\n",
      "        [-4.2907, -4.2211, -5.7259,  ..., 10.9413, -2.9637, -3.2296],\n",
      "        [-4.0797, -4.3419, -5.1283,  ..., 10.6493, -2.8339, -2.8878]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8761, grad_fn=<NllLossBackward>)\n",
      "['春晚                                                                                                                                                                                                      ', '江北北，一番风月，一枝春色。', '花李。', '月下，一番春风雨。', '夜蓉雨                                                                                                                                                                                                     ', '凉岛。', '如缈                                                                                                                                                                                                      ', '水，一番番月下，一片春风。']\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1240, 3752,   38,  ...,   71, 1661, 4266],\n",
      "        [ 572, 1042,   71,  ..., 3030, 3544, 3525],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 572, 1042,   71,  ..., 3030, 3544, 3525],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6794, -3.7449, -3.7752,  ..., -5.8409,  5.8243, 13.3073],\n",
      "        [-2.6794, -3.7449, -3.7752,  ..., -5.8409,  5.8243, 13.3073],\n",
      "        [-2.6794, -3.7449, -3.7752,  ..., -5.8409,  5.8243, 13.3073],\n",
      "        ...,\n",
      "        [-4.6702, -4.1548, -5.3294,  ...,  9.9170, -3.4780, -3.4598],\n",
      "        [-4.6512, -3.6404, -4.3758,  ..., 11.1348, -2.3530, -1.8786],\n",
      "        [-4.8812, -3.8799, -5.9248,  ..., 12.0134, -2.5890, -2.5531]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8138, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 321, 1913, 1574,  ..., 1398, 1131, 3236],\n",
      "        [2992, 4944, 1212,  ..., 4627,  129, 3236],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2992, 4944, 1212,  ..., 4627,  129, 3236],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6799, -3.7457, -3.7746,  ..., -5.8415,  5.8243, 13.3081],\n",
      "        [-2.6799, -3.7457, -3.7746,  ..., -5.8415,  5.8243, 13.3081],\n",
      "        [-2.6799, -3.7457, -3.7746,  ..., -5.8415,  5.8243, 13.3081],\n",
      "        ...,\n",
      "        [-4.5547, -4.0946, -4.6009,  ...,  9.3935, -2.6326, -2.5481],\n",
      "        [-4.5766, -4.3077, -5.5010,  ..., 11.3230, -2.9074, -2.6403],\n",
      "        [-4.7541, -4.1675, -4.6362,  ..., 10.7715, -3.5556, -3.5472]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8213, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2763,  339, 1888,  ..., 4987, 3092, 2915],\n",
      "        [1282, 1010, 3846,  ...,  832, 2058, 3670],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1282, 1010, 3846,  ...,  832, 2058, 3670],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6805, -3.7466, -3.7741,  ..., -5.8423,  5.8239, 13.3092],\n",
      "        [-2.6805, -3.7466, -3.7741,  ..., -5.8423,  5.8239, 13.3092],\n",
      "        [-2.6805, -3.7466, -3.7741,  ..., -5.8423,  5.8239, 13.3092],\n",
      "        ...,\n",
      "        [-4.3749, -3.7204, -5.5581,  ...,  9.0683, -2.9623, -3.2212],\n",
      "        [-4.3216, -4.3717, -5.4878,  ..., 10.6780, -3.2266, -3.3848],\n",
      "        [-4.1270, -3.5929, -5.0012,  ..., 10.7485, -3.4373, -3.4362]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8814, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2778, 1767, 4716,  ...,  283, 3933, 1398],\n",
      "        [ 825, 1358, 2848,  ..., 1210, 2586, 2742],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 825, 1358, 2848,  ..., 1210, 2586, 2742],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6813, -3.7472, -3.7737,  ..., -5.8435,  5.8245, 13.3096],\n",
      "        [-2.6813, -3.7472, -3.7737,  ..., -5.8435,  5.8245, 13.3096],\n",
      "        [-2.6813, -3.7472, -3.7737,  ..., -5.8435,  5.8245, 13.3096],\n",
      "        ...,\n",
      "        [-4.3346, -4.2416, -5.7488,  ..., 10.5175, -2.9307, -3.0941],\n",
      "        [-4.4543, -4.0584, -5.5381,  ..., 11.5419, -3.2850, -3.5237],\n",
      "        [-4.2855, -3.7776, -4.9661,  ...,  7.0514, -3.2851, -3.5031]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(2.0097, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [  25, 4305, 4346,  ...,  220, 3542, 2809],\n",
      "        [ 948,  806, 1413,  ..., 2425,  843, 3061],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 948,  806, 1413,  ..., 2425,  843, 3061],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6803, -3.7482, -3.7738,  ..., -5.8447,  5.8273, 13.3076],\n",
      "        [-2.6803, -3.7482, -3.7738,  ..., -5.8447,  5.8273, 13.3076],\n",
      "        [-2.6803, -3.7482, -3.7738,  ..., -5.8447,  5.8273, 13.3076],\n",
      "        ...,\n",
      "        [-4.6559, -4.0779, -5.1886,  ..., 11.0244, -3.0174, -3.0471],\n",
      "        [-4.8130, -4.9911, -5.8172,  ..., 10.6800, -2.9737, -2.9385],\n",
      "        [-4.5889, -4.0247, -5.0421,  ..., 11.7491, -3.1120, -3.3680]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8018, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4675, 5027, 1844,  ..., 2313, 1452, 4178],\n",
      "        [3763, 1877, 1844,  ..., 3283, 4679, 1917],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3763, 1877, 1844,  ..., 3283, 4679, 1917],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6798, -3.7495, -3.7740,  ..., -5.8452,  5.8297, 13.3059],\n",
      "        [-2.6798, -3.7495, -3.7740,  ..., -5.8452,  5.8297, 13.3059],\n",
      "        [-2.6798, -3.7495, -3.7740,  ..., -5.8452,  5.8297, 13.3059],\n",
      "        ...,\n",
      "        [-4.2636, -3.7650, -5.0988,  ..., 11.2111, -3.5305, -3.7091],\n",
      "        [-4.5209, -4.5732, -5.6220,  ..., 11.2194, -2.5638, -2.5632],\n",
      "        [-4.7505, -3.7219, -3.6934,  ...,  9.4744, -3.1005, -2.7645]],\n",
      "       grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.9198, grad_fn=<NllLossBackward>)\n",
      "loss: tensor(1.8344, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1081, 1940, 4987,  ...,    4,  321, 5295],\n",
      "        [4888, 2629, 4559,  ...,  740, 2164, 5295],\n",
      "        [ 436,  436,  436,  ...,  436,  436, 5294]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [4888, 2629, 4559,  ...,  740, 2164, 5295],\n",
      "        [ 436,  436,  436,  ...,  436,  436, 5294],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6761, -3.7527, -3.7751,  ..., -5.8425,  5.8352, 13.2987],\n",
      "        [-2.6761, -3.7527, -3.7751,  ..., -5.8425,  5.8352, 13.2987],\n",
      "        [-2.6761, -3.7527, -3.7751,  ..., -5.8425,  5.8352, 13.2987],\n",
      "        ...,\n",
      "        [-3.9014, -4.0703, -5.5187,  ...,  8.5153, -2.8970, -2.8717],\n",
      "        [-4.9127, -3.7960, -5.1457,  ..., 11.9224, -3.0210, -3.1204],\n",
      "        [-3.5587, -4.1463, -6.0897,  ...,  8.1064, -0.3385, -0.2287]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.7962, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2242, 5145, 3021,  ..., 3400,  509, 3544],\n",
      "        [1983,  563, 5236,  ..., 2058,   43, 3030],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1983,  563, 5236,  ..., 2058,   43, 3030],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6715, -3.7543, -3.7754,  ..., -5.8427,  5.8349, 13.2989],\n",
      "        [-2.6715, -3.7543, -3.7754,  ..., -5.8427,  5.8349, 13.2989],\n",
      "        [-2.6715, -3.7543, -3.7754,  ..., -5.8427,  5.8349, 13.2989],\n",
      "        ...,\n",
      "        [-4.3619, -4.0785, -5.7725,  ..., 10.8254, -3.2804, -3.2691],\n",
      "        [-4.1629, -4.0674, -4.1561,  ...,  9.0816, -2.8287, -3.0028],\n",
      "        [-4.5889, -3.8572, -5.1136,  ..., 11.3739, -2.9636, -2.7753]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8238, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [2915, 3321, 4087,  ...,  712, 2689, 2167],\n",
      "        [3500, 3705, 1197,  ..., 3530, 2961, 2369],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [3500, 3705, 1197,  ..., 3530, 2961, 2369],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6674, -3.7544, -3.7755,  ..., -5.8444,  5.8323, 13.3023],\n",
      "        [-2.6674, -3.7544, -3.7755,  ..., -5.8444,  5.8323, 13.3023],\n",
      "        [-2.6674, -3.7544, -3.7755,  ..., -5.8444,  5.8323, 13.3023],\n",
      "        ...,\n",
      "        [-4.0213, -4.0766, -5.3872,  ...,  9.3426, -3.5044, -3.5792],\n",
      "        [-4.5566, -4.1183, -5.7409,  ..., 11.0109, -3.2333, -3.5004],\n",
      "        [-4.3711, -4.0160, -4.9362,  ...,  8.9940, -3.5126, -3.7167]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.9839, grad_fn=<NllLossBackward>)\n",
      "input: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [ 114, 1340, 1131,  ...,  105, 1272,  244],\n",
      "        [1081, 2779, 1115,  ..., 1096,  952, 4899],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436]])\n",
      "target: tensor([[5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        [5295, 5295, 5295,  ..., 5295, 5295, 5295],\n",
      "        ...,\n",
      "        [1081, 2779, 1115,  ..., 1096,  952, 4899],\n",
      "        [ 436,  436,  436,  ...,  436,  436,  436],\n",
      "        [5293, 5293, 5293,  ..., 5293, 5293, 5293]])\n",
      "output: tensor([[-2.6641, -3.7551, -3.7757,  ..., -5.8443,  5.8308, 13.3036],\n",
      "        [-2.6641, -3.7551, -3.7757,  ..., -5.8443,  5.8308, 13.3036],\n",
      "        [-2.6641, -3.7551, -3.7757,  ..., -5.8443,  5.8308, 13.3036],\n",
      "        ...,\n",
      "        [-4.0735, -3.9080, -5.6712,  ...,  9.3267, -3.3877, -3.5725],\n",
      "        [-4.6215, -4.3142, -5.5874,  ..., 11.3512, -3.3364, -3.2364],\n",
      "        [-4.5122, -3.7233, -4.6201,  ..., 10.4286, -3.2312, -3.1714]],\n",
      "       grad_fn=<ThAddmmBackward>)\n",
      "loss: tensor(1.8456, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss_vec=train(5,data,word2id,id2word,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_vec=train(5,data,word2id,id2word,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
